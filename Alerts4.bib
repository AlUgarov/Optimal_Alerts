
@article{anderson-frey_characteristics_2019,
	title = {Characteristics of {Tornado} {Events} and {Warnings} in the {Southeastern} {United} {States}},
	volume = {34},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/34/4/waf-d-18-0211_1.xml},
	doi = {10.1175/WAF-D-18-0211.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d3184688e107"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}The southeastern United States has become a prime area of focus in tornado-related literature due, in part, to the abundance of tornadoes occurring in high-shear low-CAPE (HSLC) environments. Through this analysis of 4133 tornado events and 16 429 tornado warnings in the southeastern United States, we find that tornadoes in the Southeast do indeed have, on average, higher shear and lower CAPE than tornadoes elsewhere in the contiguous United States (CONUS). We also examine tornado warning skill in the form of probability of detection (POD; percent of tornadoes receiving warning prior to tornado occurrence) and false alarm ratio (FAR; percent of tornado warnings for which no corresponding tornado is detected), and find that, on average, POD is better and FAR is worse for tornadoes in the Southeast than for the CONUS as a whole. These measures of warning skill remain consistent even when we consider only HSLC tornadoes. The Southeast also has nearly double the CONUS percentage of deadly tornadoes, with the highest percentage of these deadly tornadoes occurring during the spring, the winter, and around local sunset. On average, however, the tornadoes with the lowest POD also tend to be those that are weakest and least likely to be deadly; for the most part, the most dangerous storms are indeed being successfully warned.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {4},
	urldate = {2021-05-04},
	journal = {Weather and Forecasting},
	author = {Anderson-Frey, Alexandra K. and Richardson, Yvette P. and Dean, Andrew R. and Thompson, Richard L. and Smith, Bryan T.},
	month = aug,
	year = {2019},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {1017--1034},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\CLRZ3ZMY\\Anderson-Frey et al. - 2019 - Characteristics of Tornado Events and Warnings in .pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\JVXJFX2Q\\waf-d-18-0211_1.html:text/html},
}

@article{lagerquist_deep_2020,
	title = {Deep {Learning} on {Three}-{Dimensional} {Multiscale} {Data} for {Next}-{Hour} {Tornado} {Prediction}},
	volume = {148},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/148/7/mwrD190372.xml},
	doi = {10.1175/MWR-D-19-0372.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d60936476e106"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}This paper describes the development of convolutional neural networks (CNN), a type of deep-learning method, to predict next-hour tornado occurrence. Predictors are a storm-centered radar image and a proximity sounding from the Rapid Refresh model. Radar images come from the Multiyear Reanalysis of Remotely Sensed Storms (MYRORSS) and Gridded NEXRAD WSR-88D Radar dataset (GridRad), both of which are multiradar composites. We train separate CNNs on MYRORSS and GridRad data, present an experiment to optimize the CNN settings, and evaluate the chosen CNNs on independent testing data. Both models achieve an area under the receiver-operating-characteristic curve (AUC) well above 0.9, which is considered to be excellent performance. The GridRad model achieves a critical success index (CSI) of 0.31, and the MYRORSS model achieves a CSI of 0.17. The difference is due primarily to event frequency (percentage of storms that are tornadic in the next hour), which is 3.52\% for GridRad but only 0.24\% for MYRORSS. The best CNN predictions (true positives and negatives) occur for strongly rotating tornadic supercells and weak nontornadic cells in mesoscale convective systems, respectively. The worst predictions (false positives and negatives) occur for strongly rotating nontornadic supercells and tornadic cells in quasi-linear convective systems, respectively. The performance of our CNNs is comparable to an operational machine-learning system for severe weather prediction, which suggests that they would be useful for real-time forecasting.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {7},
	urldate = {2021-05-04},
	journal = {Monthly Weather Review},
	author = {Lagerquist, Ryan and McGovern, Amy and Homeyer, Cameron R. and Ii, David John Gagne and Smith, Travis},
	month = jun,
	year = {2020},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {2837--2861},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\XLKTQMYB\\mwrD190372.html:text/html},
}

@article{klockow-mcclain_cartographic_2020,
	title = {Cartographic {Design} for {Improved} {Decision} {Making}: {Trade}-{Offs} in {Uncertainty} {Visualization} for {Tornado} {Threats}},
	volume = {110},
	issn = {2469-4452},
	shorttitle = {Cartographic {Design} for {Improved} {Decision} {Making}},
	url = {https://doi.org/10.1080/24694452.2019.1602467},
	doi = {10.1080/24694452.2019.1602467},
	abstract = {At present, the National Oceanic and Atmospheric Administration is developing new technologies that could offer explicit estimates of the probability that a thunderstorm could produce a tornado up to an hour ahead of the event. Such technologies could radically alter how risk spaces are represented and understood by those who must decide whether or not to take protective action. In addition, there are relatively few studies that examine mapped representations of uncertainty in weather information or the influence of this uncertainty information in weather hazard decision making. To address these gaps, this study presents research subjects with a variety of representations of uncertainty based on the precepts of cartography and information visualization. We propose and test for the existence of three geospatial framing effects that potentially influence subjective estimates of risk: distance from a hazard, warning boundary inclusion or exclusion, and symbolic color coding of uncertainty information. Using a series of computer-aided geographic experiments with a large sample (N = 5,564) of the U.S. population, we find evidence for the existence of each of the three proposed geospatial framing effects. Two of these framings are controlled by the mapmaker—in this case, the weather forecaster—and thus should be considered during the development stages of new products. We discuss the practical implications of the experimental study for current and future tornado warning practices. Key Words: cartography, risk, tornado, uncertainty, visualization.},
	number = {1},
	urldate = {2021-05-04},
	journal = {Annals of the American Association of Geographers},
	author = {Klockow-McClain, Kimberly E. and McPherson, Renee A. and Thomas, Rick P.},
	month = jan,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/24694452.2019.1602467},
	keywords = {Correction},
	pages = {314--333},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\9N454FI2\\Klockow-McClain et al. - 2020 - Cartographic Design for Improved Decision Making .pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\UYG66JEE\\24694452.2019.html:text/html},
}

@article{ripberger_measuring_2019,
	title = {Measuring {Tornado} {Warning} {Reception}, {Comprehension}, and {Response} in the {United} {States}},
	volume = {11},
	issn = {1948-8327, 1948-8335},
	url = {https://journals.ametsoc.org/view/journals/wcas/11/4/wcas-d-19-0015_1.xml},
	doi = {10.1175/WCAS-D-19-0015.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d5221176e121"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Social criteria are important to achieving the mission of the National Weather Service. Accordingly, researchers and administrators at the NWS increasingly recognize a need to supplement verification statistics with complementary data about society in performance management and evaluation. This will require significant development of new capacities to both conceptualize relevant criteria and measure them using consistent, transparent, replicable, and reliable measures that permit generalizable inference to populations of interest. In this study, we contribute to this development by suggesting three criteria that require measurement (forecast and warning reception, comprehension, and response) and demonstrating a methodology that allows us to measure these concepts in a single information domain—tornado warnings. The methodology we employ improves upon previous research in multiple ways. It provides a more generalizable approach to measurement using a temporally consistent set of survey questions that are applicable across the United States; it relies on a more robust set of psychometric tests to analytically demonstrate the reliability of the measures; and it is more transparent and replicable than previous research because the data and methods (source code) are publicly available. In addition to describing and assessing the reliability of the measures, we explore the sensitivity of the measures to geographic and demographic variation to identify significant differences that require attention in measurement. We close by discussing the implications of this study and the next steps toward development and use of social criteria in performance management and evaluation.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {4},
	urldate = {2021-05-04},
	journal = {Weather, Climate, and Society},
	author = {Ripberger, Joseph T. and Krocak, Makenzie J. and Wehde, Wesley W. and Allan, Jinan N. and Silva, Carol and Jenkins-Smith, Hank},
	month = oct,
	year = {2019},
	note = {Publisher: American Meteorological Society
Section: Weather, Climate, and Society},
	pages = {863--880},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\BEUDP8Z6\\Ripberger et al. - 2019 - Measuring Tornado Warning Reception, Comprehension.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\NW63KD5M\\wcas-d-19-0015_1.html:text/html},
}

@article{allan_oklahoma_2017,
	title = {The {Oklahoma} {Warning} {Awareness} {Scale}: {A} {Psychometric} {Analysis} of a {Brief} {Self}-{Report} {Survey} {Instrument}},
	volume = {61},
	issn = {2169-5067},
	shorttitle = {The {Oklahoma} {Warning} {Awareness} {Scale}},
	url = {https://doi.org/10.1177/1541931213601783},
	doi = {10.1177/1541931213601783},
	abstract = {Natural hazards (e.g., earthquakes, tornadoes, floods) pose many risk communication challenges for emergency managers and policy makers. Critical obstacles to risk readiness are often attributed to differences in (a) warning awareness, (b) risk understanding, and (c) behavioral responses. Although a considerable body of research has focused on risk understanding (see www.RiskLiteracy.org) there is relatively less research mapping individual differences in warning awareness and related vulnerabilities. Here, we present a psychometric study (n=254) with cross-validation, testing a two parameter polytomous logistic model of subjective warning awareness (i.e., people’s assessment of how likely they are to receive risk and hazard warnings from trusted sources). The final instrument included four items and one criterion that may be related to other important natural hazard response behaviors, providing a foundation for continuing exploration of warning awareness. Discussion focuses on potential applications of the Oklahoma Warning Awareness Scale as it pertains to natural hazards and other risks more broadly.},
	language = {en},
	number = {1},
	urldate = {2021-05-04},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Allan, Jinan N. and Ripberger, Joseph T. and Ybarra, Vincent T. and Cokely, Edward T.},
	month = sep,
	year = {2017},
	note = {Publisher: SAGE Publications Inc},
	pages = {1203--1207},
	file = {SAGE PDF Full Text:C\:\\Users\\aluga\\Zotero\\storage\\UDZM5XMK\\Allan et al. - 2017 - The Oklahoma Warning Awareness Scale A Psychometr.pdf:application/pdf},
}

@article{walters_staying_2020,
	title = {Staying {Safe} in a {Tornado}: {A} {Qualitative} {Inquiry} into {Public} {Knowledge}, {Access}, and {Response} to {Tornado} {Warnings}},
	volume = {35},
	issn = {1520-0434, 0882-8156},
	shorttitle = {Staying {Safe} in a {Tornado}},
	url = {https://journals.ametsoc.org/view/journals/wefo/35/1/WAF-D-19-0090.1.xml},
	doi = {10.1175/WAF-D-19-0090.1.35.1.test},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d136034e102"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Tornadoes in the southeastern United States continue to cause substantial injury, death, and destruction. The present study seeks to 1) understand inadequate warning access, less understanding, and/or less likelihood of responding to tornado warnings; 2) examine public attitudes about NWS communications; and 3) explore the perceptions of NWS personnel regarding public response to tornado warnings, factors that might influence response, and how their perceptions impact their communication. Participants include a purposive sample of NWS forecasters in Tennessee ({\textless}em{\textgreater}n{\textless}/em{\textgreater} = 11) and residents ({\textless}em{\textgreater}n{\textless}/em{\textgreater} = 45) who were identified as having low access to, low knowledge of, or an unsafe response to tornado warnings in a previous study. A qualitative approach with semistructured interviews was used. Findings indicated that most participants had at least one warning source. Barriers to warning access included electricity outages, rurality, lack of storm radio, heavy sleeping, and hearing impairments. Most participants had knowledge of NWS guidelines for safe shelter seeking but still engaged in behaviors considered unsafe. Proximity, personal experience, and influence of family and friends emerged as influencers of response to warnings. NWS personnel perceived that proximity played a significant role in shelter-seeking behavior as well as the need for confirmation. Poor access to safe shelter arose as a major concern for NWS personnel, specifically mobile home residents. Messaging and specificity in warnings to evoke safe shelter-seeking behavior surfaced as critical issues for NWS personnel. Implications for education and policy changes to enhance public safety and improve public health are noted.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {1},
	urldate = {2021-05-04},
	journal = {Weather and Forecasting},
	author = {Walters, Jayme E. and Mason, Lisa Reyes and Ellis, Kelsey and Winchester, Betsy},
	month = feb,
	year = {2020},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {67--81},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\4RN6BX96\\Walters et al. - 2020 - Staying Safe in a Tornado A Qualitative Inquiry i.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\2XJIAGQD\\WAF-D-19-0090.1.html:text/html},
}

@article{liu_how_2019,
	title = {How {Mobile} {Home} {Residents} {Understand} and {Respond} to {Tornado} {Warnings}},
	volume = {11},
	issn = {1948-8327, 1948-8335},
	url = {https://journals.ametsoc.org/view/journals/wcas/11/3/wcas-d-17-0080_1.xml},
	doi = {10.1175/WCAS-D-17-0080.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d5168462e97"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Mobile home residents experience higher fatality rates from tornadoes than “fixed home” residents. Yet, research on how mobile home residents understand and respond to tornado warnings is lacking. Such research can help meteorologists and their partners better communicate tornado risk. We conducted four surveys with residents of the southeastern United States. This region has the highest concentration of tornado fatalities and killer tornadoes, in part because of the high density of mobile homes. Findings reveal that today’s tornado warning system inadequately prepares mobile home residents to respond safely to tornadoes. The study offers recommendations for how to improve tornado communication for mobile and fixed home residents.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {3},
	urldate = {2021-05-04},
	journal = {Weather, Climate, and Society},
	author = {Liu, Brooke Fisher and Egnoto, Michael and Lim, JungKyu Rhys},
	month = jul,
	year = {2019},
	note = {Publisher: American Meteorological Society
Section: Weather, Climate, and Society},
	pages = {521--534},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\AXN2VFAG\\Liu et al. - 2019 - How Mobile Home Residents Understand and Respond t.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\NB96VE3T\\wcas-d-17-0080_1.html:text/html},
}

@article{jauernic_tornado_2017,
	title = {Tornado {Warning} {Response} and {Perceptions} among {Undergraduates} in {Nebraska}},
	volume = {9},
	issn = {1948-8327, 1948-8335},
	url = {https://journals.ametsoc.org/view/journals/wcas/9/2/wcas-d-16-0031_1.xml},
	doi = {10.1175/WCAS-D-16-0031.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d5374238e81"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Few studies show how university students perceive and respond to tornado warnings. Lacking in the literature are investigations of what influences perceptions of tornado risk among this population and how these perceptions may influence actions. Through an online survey of 640 undergraduates enrolled at a large university in Nebraska, significant relationships were found between student demographics, perceptions, and response actions. Tornado mythology relevant to the local city influenced perceptions so that students felt the city was less at risk than surrounding rural land. Confirming risk before sheltering remained popular, with some students choosing to never seek shelter during a warning. International students were more likely to initially seek shelter during a warning but had difficulty interpreting warning polygons or accurately choosing the best safety actions. Tornado-related education resulted in international students being more likely to have safety plans and shelter in more appropriate locations. Most domestic students correctly identified safe areas in which to shelter, but fewer knew the precise meaning of a tornado warning polygon. Parents/guardians and the school were the most popular tornado knowledge sources for domestic students, while friends and self-education were popular with international students. Respondents seemed willing to learn more about tornadoes and perceived a lack of tornado-related resources available on campus. This implies that more thorough tornado education and information dissemination on university campuses is warranted. Faster personalization of risk, dispelling local myths, and educating those new to tornado-prone locations should be emphasized.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {2},
	urldate = {2021-05-04},
	journal = {Weather, Climate, and Society},
	author = {Jauernic, Sabrina T. and Broeke, Matthew S. Van Den},
	month = apr,
	year = {2017},
	note = {Publisher: American Meteorological Society
Section: Weather, Climate, and Society},
	pages = {125--139},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\GCRDLFPD\\Jauernic and Broeke - 2017 - Tornado Warning Response and Perceptions among Und.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\F254GPFE\\wcas-d-16-0031_1.html:text/html},
}

@article{durran_can_2020,
	title = {Can the {Issuance} of {Hazardous}-{Weather} {Warnings} {Inform} the {Attribution} of {Extreme} {Events} to {Climate} {Change}?},
	volume = {101},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/101/8/bamsD200026.xml},
	doi = {10.1175/BAMS-D-20-0026.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d120383809e61"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}When extreme weather occurs, the question often arises whether the event was produced by climate change. Two types of errors are possible when attempting to answer this question. One type of error is underestimating the role of climate change, thereby failing to properly alert the public and appropriately stimulate efforts at adaptation and mitigation. The second type of error is overestimating the role of climate change, thereby elevating climate anxiety and potentially derailing important public discussions with false alarms. Long before societal concerns about global warming became widespread, meteorologists were addressing essentially the same trade-off when faced with a binary decision of whether to issue a warning for hazardous weather. Here we review forecast–verification statistics such as the probability of detection (POD) and the false alarm ratio (FAR) for hazardous-weather warnings and examine their potential application to extreme-event attribution in connection with climate change. Empirical and theoretical evidence suggests that adjusting tornado-warning thresholds in an attempt to reduce FAR produces even larger reductions in POD. Similar tradeoffs between improving FAR and degrading POD are shown to apply using a rubric for the attribution of extreme high temperatures to climate change. Although there are obviously significant differences between the issuance of hazardous-weather warnings and the attribution of extreme events to global warming, the experiences of the weather forecasting community can provide qualitative guidance for those attempting to set practical thresholds for extreme-event attribution in a changing climate.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {8},
	urldate = {2021-05-04},
	journal = {Bulletin of the American Meteorological Society},
	author = {Durran, Dale R.},
	month = sep,
	year = {2020},
	note = {Publisher: American Meteorological Society
Section: Bulletin of the American Meteorological Society},
	pages = {E1452--E1463},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\6JAM6KPT\\Durran - 2020 - Can the Issuance of Hazardous-Weather Warnings Inf.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\PYU2BZAR\\bamsD200026.html:text/html},
}

@article{simmons_wsr-88d_2005,
	title = {{WSR}-{88D} {Radar}, {Tornado} {Warnings}, and {Tornado} {Casualties}},
	volume = {20},
	issn = {0882-8156},
	url = {https://journals.ametsoc.org/waf/article/20/3/301/38735/WSR-88D-Radar-Tornado-Warnings-and-Tornado},
	doi = {10.1175/WAF857.1},
	language = {en},
	number = {3},
	urldate = {2020-10-21},
	journal = {Weather and Forecasting},
	author = {Simmons, Kevin M. and Sutter, Daniel},
	month = jun,
	year = {2005},
	note = {Number: 3
Publisher: American Meteorological Society},
	pages = {301--310},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\QTACQGRD\\Simmons and Sutter - 2005 - WSR-88D Radar, Tornado Warnings, and Tornado Casua.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\F52HW8IP\\38735.html:text/html},
}

@article{simmons_false_2009,
	title = {False {Alarms}, {Tornado} {Warnings}, and {Tornado} {Casualties}},
	volume = {1},
	issn = {1948-8327},
	url = {https://journals.ametsoc.org/wcas/article/1/1/38/750/False-Alarms-Tornado-Warnings-and-Tornado},
	doi = {10.1175/2009WCAS1005.1},
	language = {en},
	number = {1},
	urldate = {2020-10-21},
	journal = {Weather, Climate, and Society},
	author = {Simmons, Kevin M. and Sutter, Daniel},
	month = oct,
	year = {2009},
	note = {Number: 1
Publisher: American Meteorological Society},
	pages = {38--53},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\WWSWLTSR\\Simmons and Sutter - 2009 - False Alarms, Tornado Warnings, and Tornado Casual.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\L3Z84E9E\\750.html:text/html},
}

@unpublished{wehde_public_2019,
	type = {unpublished manuscript},
	title = {Public {Willingness} to {Pay} for {Continuous} and {Probabilistic} {Hazard} {Information}},
	author = {Wehde, Wesley and Ripberger, Joseph},
	year = {2019},
}

@article{ripberger_measuring_2019-1,
	title = {Measuring {Tornado} {Warning} {Reception}, {Comprehension}, and {Response} in the {United} {States}},
	volume = {11},
	issn = {1948-8327, 1948-8335},
	url = {https://journals.ametsoc.org/view/journals/wcas/11/4/wcas-d-19-0015_1.xml},
	doi = {10.1175/WCAS-D-19-0015.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d374e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Social criteria are important to achieving the mission of the National Weather Service. Accordingly, researchers and administrators at the NWS increasingly recognize a need to supplement verification statistics with complementary data about society in performance management and evaluation. This will require significant development of new capacities to both conceptualize relevant criteria and measure them using consistent, transparent, replicable, and reliable measures that permit generalizable inference to populations of interest. In this study, we contribute to this development by suggesting three criteria that require measurement (forecast and warning reception, comprehension, and response) and demonstrating a methodology that allows us to measure these concepts in a single information domain—tornado warnings. The methodology we employ improves upon previous research in multiple ways. It provides a more generalizable approach to measurement using a temporally consistent set of survey questions that are applicable across the United States; it relies on a more robust set of psychometric tests to analytically demonstrate the reliability of the measures; and it is more transparent and replicable than previous research because the data and methods (source code) are publicly available. In addition to describing and assessing the reliability of the measures, we explore the sensitivity of the measures to geographic and demographic variation to identify significant differences that require attention in measurement. We close by discussing the implications of this study and the next steps toward development and use of social criteria in performance management and evaluation.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {4},
	urldate = {2021-01-11},
	journal = {Weather, Climate, and Society},
	author = {Ripberger, Joseph T. and Krocak, Makenzie J. and Wehde, Wesley W. and Allan, Jinan N. and Silva, Carol and Jenkins-Smith, Hank},
	month = oct,
	year = {2019},
	note = {Number: 4
Publisher: American Meteorological Society
Section: Weather, Climate, and Society},
	pages = {863--880},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\C3FM636F\\Ripberger et al. - 2019 - Measuring Tornado Warning Reception, Comprehension.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\EQADU5ET\\wcas-d-19-0015_1.html:text/html},
}

@article{hoekstra_social_2011,
	title = {A social perspective of warn on forecast: ideal tornado warning lead time and the general public’s perceptions of weather risks},
	volume = {3},
	shorttitle = {A social perspective of warn on forecast},
	journal = {Weather Clim Soc},
	author = {Hoekstra, Stephanie and Butterworth, Rachel and Kim Klockow, Dr and Brotzge, Jerry and Erickson, Somer},
	year = {2011},
	note = {Publisher: Citeseer},
	pages = {128--140},
	file = {Full Text:C\:\\Users\\aluga\\Zotero\\storage\\P5YHAQ3Q\\Hoekstra et al. - 2011 - A social perspective of warn on forecast ideal to.pdf:application/pdf},
}

@article{miran_effect_2018,
	title = {The effect of providing probabilistic information about a tornado threat on people’s protective actions},
	volume = {94},
	issn = {1573-0840},
	url = {https://doi.org/10.1007/s11069-018-3418-5},
	doi = {10.1007/s11069-018-3418-5},
	abstract = {National Weather Service issues deterministic warnings in a tornado event. An alternative system is being researched at National Severe Storms Laboratory to issue Probabilistic Hazard Information (PHI). This study investigated how providing the uncertainty information about the tornado occurrence through PHI changes people’s protective actions. In an experiment, visual displays of the probabilistic information and deterministic warnings were presented to fifty participants to report their expected protective actions in different scenarios. It was found that the percentage of people who expected to immediately take shelter right after receiving the weather information increased exponentially as their proximity to the threat decreased. When there was more chance that the information about occurrence of a particular tornado was false rather than true, in scenarios that the likelihood of the threat occurrence was less than 50\%, providing it through PHI lowered the percentage of people who immediately took shelter. The ordinal logistic regression models showed that the probability of taking protective actions significantly changes by providing the uncertainty information when people have less than 20 min lead time before getting impacted by the threat. When the lead time is less than 10 min, the probability of immediately taking shelter increases to 94 from 71\%, and when the lead time is more than 10 but less than 20 min, that probability increases from 53 to 70\%, if they are provided with the probabilistic information. Presenting the likelihood of any tornado formation in the area did not have significant effect on the people’s protective actions.},
	language = {en},
	number = {2},
	urldate = {2021-01-11},
	journal = {Natural Hazards},
	author = {Miran, Seyed M. and Ling, Chen and Gerard, Alan and Rothfusz, Lans},
	month = nov,
	year = {2018},
	note = {Number: 2},
	pages = {743--758},
	file = {Springer Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\FR3BLGSY\\Miran et al. - 2018 - The effect of providing probabilistic information .pdf:application/pdf},
}

@article{mozumder_household_2015,
	title = {Household {Preferences} for a {Hurricane} {Mitigation} {Fund} in {Florida}},
	volume = {16},
	copyright = {© 2014 American Society of Civil Engineers},
	issn = {1527-6996},
	url = {https://ascelibrary.org/doi/abs/10.1061/%28ASCE%29NH.1527-6996.0000170},
	doi = {10.1061/(ASCE)NH.1527-6996.0000170},
	abstract = {In this study, household preferences in terms of willingness to pay for financing a hurricane mitigation fund in the State of Florida were investigated. Survey results indicate that more than one-fourth of homeowners would be willing to pay to finance a mitigation fund. The willingness to pay (WTP) is driven by household income, risk perceptions, and support to specific mitigation measures such as rating home structures and funding the insurance system. Household WTP estimates were also presented. With an annual household contribution of \$43–\$45, the State of Florida could raise more than \$300 million for a hurricane mitigation fund. This annual contribution is more than the \$250 million that the My Safe Florida Home (MSFH) Program spent in 2007 to 2009. A highly conservative WTP estimates (\$7.77/year\$7.77/year{\textless}math display="inline" overflow="scroll"{\textgreater}{\textless}mrow{\textgreater}{\textless}mi{\textgreater}\${\textless}/mi{\textgreater}{\textless}mn{\textgreater}7.77{\textless}/mn{\textgreater}{\textless}mo stretchy="false"{\textgreater}/{\textless}/mo{\textgreater}{\textless}mi{\textgreater}year{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater}) suggest that Florida could collect almost \$55.5 million per year to fund a hurricane mitigation program similar to the MSFH program. The program could help in delivering salient risk information and incentivizing effective mitigation measures for homeowners living in vulnerable areas in Florida as an essential component of disaster risk reduction.},
	language = {EN},
	number = {3},
	urldate = {2021-01-11},
	journal = {Natural Hazards Review},
	author = {Mozumder, Pallab and Chowdhury, Arindam Gan and Vásquez, William F. and Flugman, Evan},
	month = aug,
	year = {2015},
	note = {Number: 3
Publisher: American Society of Civil Engineers},
	keywords = {Hurricane, Predisaster risk reduction, Risk communication, Risk mitigation},
	pages = {04014031},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\MCXYBKKM\\(ASCE)NH.1527-6996.html:text/html},
}

@article{lazo_valuing_2011,
	title = {Valuing improved hurricane forecasts},
	volume = {111},
	doi = {10.1016/j.econlet.2010.12.012},
	journal = {Economics Letters},
	author = {Lazo, Jeffrey and Waldman, Donald},
	month = jan,
	year = {2011},
	pages = {43--46},
}

@article{lazo_300_2009,
	title = {300 {BILLION} {SERVED}: {Sources}, {Perceptions}, {Uses}, and {Values} of {Weather} {Forecasts}},
	volume = {90},
	issn = {0003-0007},
	shorttitle = {300 {BILLION} {SERVED}},
	url = {https://www.jstor.org/stable/26220993},
	abstract = {Abstract Understanding the public’s sources, perceptions, uses, and values of weather forecasts is integral to providing those forecasts in the most societally beneficial manner. To begin developing this knowledge, we conducted a nationwide survey with more than 1,500 respondents to assess 1) where, when, and how often they obtain weather forecasts; 2) how they perceive forecasts; 3) how they use forecasts; and 4) the value they place on current forecast information. Our results indicate that the average U.S. adult obtains forecasts 115 times per month, which totals to more than 300 billion forecasts per year by the U.S. public. Overall, we find that respondents are highly satisfied with forecasts and have decreasing confidence in forecasts as lead time increases. Respondents indicated that they use forecasts across a range of decision-making contexts. Moreover, nearly three-quarters stated that they usually or always use forecasts simply to know what the weather will be like. Using a simplified valuation approach, we estimate the value of current weather forecast information to be approximately \$286 per U.S. household per year, or \$31.5 billion total per year value to U.S. households. This compares favorably with total U.S. public and private sector meteorology costs of \$5.1 billion a year. To better support the provision of societally beneficial weather information, we advocate for well-designed periodic evaluations of the public’s sources, perceptions, uses, and values of weather forecasts. These should include investigations of other important topics such as interpretations of hazardous weather warnings and presentation of uncertainty information.},
	number = {6},
	urldate = {2021-01-11},
	journal = {Bulletin of the American Meteorological Society},
	author = {Lazo, Jeffrey K. and Morss, Rebecca E. and Demuth, Julie L.},
	year = {2009},
	note = {Number: 6
Publisher: American Meteorological Society},
	pages = {785--798},
}

@article{morss_communicating_2008,
	title = {Communicating {Uncertainty} in {Weather} {Forecasts}: {A} {Survey} of the {U}.{S}. {Public}},
	volume = {23},
	issn = {1520-0434, 0882-8156},
	shorttitle = {Communicating {Uncertainty} in {Weather} {Forecasts}},
	url = {https://journals.ametsoc.org/view/journals/wefo/23/5/2008waf2007088_1.xml},
	doi = {10.1175/2008WAF2007088.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d2501e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Weather forecasts are inherently uncertain, and meteorologists have information about weather forecast uncertainty that is not readily available to most forecast users. Yet effectively communicating forecast uncertainty to nonmeteorologists remains challenging. Improving forecast uncertainty communication requires research-based knowledge that can inform decisions on what uncertainty information to communicate, when, and how to do so. To help build such knowledge, this article explores the public’s perspectives on everyday weather forecast uncertainty and uncertainty information using results from a nationwide survey. By contributing to the fundamental understanding of laypeople’s views on forecast uncertainty, the findings can inform both uncertainty communication and related research.{\textless}/p{\textgreater}{\textless}p{\textgreater}The article uses empirical data from a nationwide survey of the U.S. public to investigate beliefs commonly held among meteorologists and to explore new topics. The results show that when given a deterministic temperature forecast, most respondents expected the temperature to fall within a range around the predicted value. In other words, most people inferred uncertainty into the deterministic forecast. People’s preferences for deterministic versus nondeterministic forecasts were examined in two situations; in both, a significant majority of respondents liked weather forecasts that expressed uncertainty, and many preferred such forecasts to single-valued forecasts. The article also discusses people’s confidence in different types of forecasts, their interpretations of the probability of precipitation forecasts, and their preferences for how forecast uncertainty is conveyed. Further empirical research is needed to study the article’s findings in other contexts and to continue exploring perception, interpretation, communication, and use of weather forecast uncertainty.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {5},
	urldate = {2021-01-11},
	journal = {Weather and Forecasting},
	author = {Morss, Rebecca E. and Demuth, Julie L. and Lazo, Jeffrey K.},
	month = oct,
	year = {2008},
	note = {Number: 5
Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {974--991},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\CBND8IWR\\Morss et al. - 2008 - Communicating Uncertainty in Weather Forecasts A .pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\TD9ZUU8M\\2008waf2007088_1.html:text/html},
}

@article{bauer_quiet_2015,
	title = {The quiet revolution of numerical weather prediction},
	volume = {525},
	copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14956},
	doi = {10.1038/nature14956},
	abstract = {Advances in numerical weather prediction represent a quiet revolution because they have resulted from a steady accumulation of scientific knowledge and technological advances over many years that, with only a few exceptions, have not been associated with the aura of fundamental physics breakthroughs. Nonetheless, the impact of numerical weather prediction is among the greatest of any area of physical science. As a computational problem, global weather prediction is comparable to the simulation of the human brain and of the evolution of the early Universe, and it is performed every day at major operational centres across the world.},
	language = {en},
	number = {7567},
	urldate = {2021-01-11},
	journal = {Nature},
	author = {Bauer, Peter and Thorpe, Alan and Brunet, Gilbert},
	month = sep,
	year = {2015},
	note = {Number: 7567
Publisher: Nature Publishing Group},
	pages = {47--55},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\TPQ8S89C\\Bauer et al. - 2015 - The quiet revolution of numerical weather predicti.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\98LWL7EV\\nature14956.html:text/html},
}

@article{joslyn_communicating_2010,
	title = {Communicating forecast uncertainty: public perception of weather forecast uncertainty},
	volume = {17},
	copyright = {Copyright © 2010 Royal Meteorological Society},
	issn = {1469-8080},
	shorttitle = {Communicating forecast uncertainty},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/met.190},
	doi = {https://doi.org/10.1002/met.190},
	abstract = {The general public understands that there is uncertainty inherent in deterministic forecasts as well as understanding some of the factors that increase uncertainty. This was determined in an online survey of 1340 residents of Washington and Oregon, USA. Understanding was probed using questions that asked participants what they expected to observe when given a deterministic forecast with a specified lead time, for a particular weather parameter, during a particular time of year. It was also probed by asking participants to estimate the number of observations, out of 100, that they expected to fall within specified ranges around the deterministic forecast. Almost all respondents (99.99\%) anticipated some uncertainty in the deterministic forecast. Furthermore, their answers suggested that they expected greater uncertainty for longer lead times when the forecasted value deviated from climatic norms. Perhaps most noteworthy was that they expected specific forecast biases (e.g. over-forecasting of extremes), most of which were not borne out by an analysis of local National Weather Service verification data. In summary, users had well-formed uncertainty expectations suggesting that they are prepared to understand explicit uncertainty forecasts for a wide range of parameters. Indeed, explicit uncertainty estimates may be necessary to overcome some of the anticipated forecast biases that may be affecting the usefulness of existing weather forecasts. Despite the fact that these bias expectations are largely unjustified, they could lead to adjustment of forecasts that could in turn have serious negative consequences for users, especially with respect to extreme weather warnings. Copyright © 2010 Royal Meteorological Society},
	language = {en},
	number = {2},
	urldate = {2021-01-11},
	journal = {Meteorological Applications},
	author = {Joslyn, Susan and Savelli, Sonia},
	year = {2010},
	note = {Number: 2
\_eprint: https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/met.190},
	keywords = {decision-making, forecast biases, probabilistic forecasts},
	pages = {180--195},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\IXN8G8XA\\Joslyn and Savelli - 2010 - Communicating forecast uncertainty public percept.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\CPI4QBNS\\met.html:text/html},
}

@article{morss_examining_2010,
	title = {Examining the use of weather forecasts in decision scenarios: results from a {US} survey with implications for uncertainty communication},
	volume = {17},
	copyright = {Copyright © 2010 Royal Meteorological Society},
	issn = {1469-8080},
	shorttitle = {Examining the use of weather forecasts in decision scenarios},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/met.196},
	doi = {https://doi.org/10.1002/met.196},
	abstract = {The hydrometeorological community has limited understanding of how people interpret forecast information and use it in decision making, hampering effective forecast communication. This article addresses these issues in the context of weather prediction, focusing especially on forecast uncertainty. It does so using empirical data from decision scenario questions asked in a nationwide US survey. Respondents were asked their probabilistic threshold for taking action to protect against potential rain or frost. They were then asked to make yes/no protective decisions in a potential reservoir flooding or fruit frost scenario given different forecasts. The results indicate that people have different probabilistic thresholds for taking protective action and that context and presentation influence forecast use. The results also suggest that many people infer uncertainty into deterministic forecasts, and that many respondents were able to interpret probabilistic forecasts of the type presented well enough to use them in the decision questions. Further, the analysis suggests that most respondents did not make decisions according to the simplest form of the cost-loss decision model. The analysis also examines relationships between respondents' information use and other aspects of their perceptions and interpretations of forecast uncertainty, including their interpretations of probability of precipitation. The findings add to fundamental knowledge about people's interpretations and use of weather forecasts, especially forecasts that explicitly convey uncertainty, and provide a starting point for future related work using survey and experimental approaches. Copyright © 2010 Royal Meteorological Society},
	language = {en},
	number = {2},
	urldate = {2021-01-11},
	journal = {Meteorological Applications},
	author = {Morss, Rebecca E. and Lazo, Jeffrey K. and Demuth, Julie L.},
	year = {2010},
	note = {Number: 2
\_eprint: https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/met.196},
	keywords = {flooding, forecast interpretation, frost, probability of precipitation, quantitative precipitation forecasts, temperature forecasts},
	pages = {149--162},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\29J6B9LB\\Morss et al. - 2010 - Examining the use of weather forecasts in decision.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\N9NNFZW3\\met.html:text/html},
}

@article{leclerc_cry_2015,
	title = {The {Cry} {Wolf} {Effect} and {Weather}-{Related} {Decision} {Making}},
	volume = {35},
	copyright = {© 2015 Society for Risk Analysis},
	issn = {1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/risa.12336},
	doi = {https://doi.org/10.1111/risa.12336},
	abstract = {Despite improvements in forecasting extreme weather events, noncompliance with weather warnings among the public remains a problem. Although there are likely many reasons for noncompliance with weather warnings, one important factor might be people's past experiences with false alarms. The research presented here explores the role of false alarms in weather-related decision making. Over a series of trials, participants used an overnight low temperature forecast and advice from a decision aid to decide whether to apply salt treatment to a town's roads to prevent icy conditions or take the risk of withholding treatment, which resulted in a large penalty when freezing temperatures occurred. The decision aid gave treatment recommendations, some of which were false alarms, i.e., treatment was recommended but observed temperatures were above freezing. The rate at which the advice resulted in false alarms was manipulated between groups. Results suggest that very high and very low false alarm rates led to inferior decision making, but that lowering the false alarm rate slightly did not significantly affect compliance or decision quality. However, adding a probabilistic uncertainty estimate in the forecasts improved both compliance and decision quality. These findings carry implications about how weather warnings should be communicated to the public.},
	language = {en},
	number = {3},
	urldate = {2021-01-11},
	journal = {Risk Analysis},
	author = {LeClerc, Jared and Joslyn, Susan},
	year = {2015},
	note = {Number: 3
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/risa.12336},
	keywords = {Cognitive psychology, decision making, false alarm effect, risk communication},
	pages = {385--395},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\3F4L6V2D\\LeClerc and Joslyn - 2015 - The Cry Wolf Effect and Weather-Related Decision M.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\QSKFN66P\\risa.html:text/html},
}

@article{drobot_us_2014,
	title = {U.{S}. {Public} {Preferences} for {Weather} and {Road} {Condition} {Information}},
	volume = {95},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/95/6/bams-d-12-00112.1.xml},
	doi = {10.1175/BAMS-D-12-00112.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}p{\textgreater}In 2008, the American Meteorological Society (AMS) Board on Enterprise Planning (BEP) established the Committee on Mobile Observations to discuss the application and utilization of mobile weather and road condition data in the context of supporting the weather and transportation communities and how these data could be used to improve safety and mobility across the nation's surface transportation system. The goal of the committee is to articulate a clear vision for mobile data that captures the immense opportunities for these data to improve road weather services and transportation safety and mobility. The Committee on Mobile Observations is engaged in numerous activities to accomplish its goal, which includes a nationwide survey of the traveling public to obtain better information on their preferences for and interests in obtaining weather and road condition information, their willingness to share vehicle data, and their willingness to pay for enhanced services. This paper outlines the results of the survey. Working through Survey Sampling International, the survey obtained 1627 responses. Results show that people are strongly interested in obtaining road weather information, though they remain wary of sharing data, and they are disinclined to pay for the data. Stratifications note some regional differences in the level of interest in data, as well as dependencies between the amount of information desired, and the willingness to pay for it and to share vehicle information.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {6},
	urldate = {2021-01-11},
	journal = {Bulletin of the American Meteorological Society},
	author = {Drobot, Sheldon and Anderson, Amanda R. S. and Burghardt, Crystal and Pisano, Paul},
	month = jun,
	year = {2014},
	note = {Number: 6
Publisher: American Meteorological Society
Section: Bulletin of the American Meteorological Society},
	pages = {849--859},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\4SJWI7I8\\Drobot et al. - 2014 - U.S. Public Preferences for Weather and Road Condi.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\XSWDXSUQ\\bams-d-12-00112.1.html:text/html;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\C8ADIHKH\\bams-d-12-00112.1.html:text/html},
}

@article{yuan_assessment_2016,
	title = {Assessment of the benefits of the {Chinese} {Public} {Weather} {Service}},
	volume = {23},
	copyright = {© 2015 The Authors. Meteorological Applications published by John Wiley \& Sons Ltd on behalf of the Royal Meteorological Society.},
	issn = {1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/met.1539},
	doi = {https://doi.org/10.1002/met.1539},
	abstract = {The present study aims to understand the public opinion on the Chinese Public Weather Service and evaluate its benefits. Statistics based on a nationwide survey conducted in China in 2006 show that the receipt and perception of weather information vary across different ages and groups. People obtain weather information from various sources (television ranks first); younger generations favour new media. There is a high demand for information services related to severe weather and short-range weather, which have the largest impact on daily lives and professional needs. The respondents' satisfaction with the current weather service and forecast accuracy are very high, although the accuracy of weather forecasts requires improvements. The benefits of the Chinese Public Weather Service and cost–benefit ratios are evaluated via direct, indirect and reverse willingness-to-pay evaluation models. For the entire country, the benefit of the Chinese Public Weather Service is estimated to be at least 46.482 billion Chinese Yuan (CNY), which accounted for 0.22\% of the Chinese gross domestic product (GDP) in 2006; the national cost–benefit ratio is 1:26. The regional cost–benefit ratios of the Chinese Public Weather Service exhibit a wide range from 1:2 to 1:81 over different provincial-level regions. The cost–benefit ratios are much higher in economically developed areas (Central and East China) than in economically underdeveloped areas (Northwest China). The social development level, especially certain aspects of primary industry and transportation, is closely related to the cost–benefit ratio of the Chinese Public Weather Service. These findings can assist the China Meteorological Administration and its supervised meteorological bureaus in providing a weather service that meets the public needs effectively.},
	language = {en},
	number = {1},
	urldate = {2021-01-11},
	journal = {Meteorological Applications},
	author = {Yuan, Huiling and Sun, Min and Wang, Yuan},
	year = {2016},
	note = {Number: 1
\_eprint: https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/met.1539},
	keywords = {benefit assessment, Chinese Public Weather Service, cost–benefit ratio, willingness to pay},
	pages = {132--139},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\BM6RB2BD\\Yuan et al. - 2016 - Assessment of the benefits of the Chinese Public W.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\7S8V5IPI\\met.html:text/html},
}

@article{sutter_state_2016,
	title = {State of {Knowledge} of {Economic} {Value} of {Current} and {Improved} {Hurricane} {Forecasts}},
	volume = {11},
	issn = {2194-5861, 1932-9156},
	url = {https://www.degruyter.com/view/journals/jbvela/11/1/article-p45.xml},
	doi = {10.1515/jbvela-2015-0015},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d269e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}This paper surveys the literature on the value of current and potentially improved hurricane forecasts from the National Hurricane Center. Research on the societal impacts of hurricanes demonstrates that forecasts are likely generating substantial benefits to society in a variety of uses, including saving lives in the U. S. and across the Carribean and Eastern Pacific, reducing the cost of evacuations, improving supply chain management, and in the transportation and energy production and distribution sectors. The existing literature, however, fails generally to quantify the benefits with rigor sufficient for an academic quality benefit-cost analysis of hurricane forecasts. The paper offers several suggestions for future research to more precisely estimate the benefits attributable to current or improved forecasts.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en},
	number = {1},
	urldate = {2021-01-11},
	journal = {Journal of Business Valuation and Economic Loss Analysis},
	author = {Sutter, Daniel and Ewing, Bradley T.},
	month = jun,
	year = {2016},
	note = {Number: 1
Publisher: De Gruyter
Section: Journal of Business Valuation and Economic Loss Analysis},
	pages = {45--64},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\6DWDRYEL\\article-p45.html:text/html},
}

@article{foley_comparison_2021,
	title = {Comparison of {Single}-{Valued} {Forecasts} in a {User}-{Oriented} {Framework}},
	volume = {35},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/35/3/waf-d-19-0248.1.xml},
	doi = {10.1175/WAF-D-19-0248.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d1205e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}We compare single-valued forecasts from a consensus of numerical weather prediction models to forecasts from a single model across a range of user decision thresholds and sensitivities, using the relative economic value framework, and present this comparison in a new graphical format. With the help of a simple linear error model, we obtain theoretical results and perform synthetic calculations to gain insights into how the results relate to the characteristics of the different forecast systems. We find that multimodel consensus forecasts are more beneficial for users interested in decisions near the climatological mean, due to their reduced spread of errors compared to the constituent models. Single model forecasts may present greater benefit for users sensitive to extreme events if the forecasts have smaller conditional biases than the consensus forecasts and hence better resolution of such events. The results support use of consensus averaging approaches for single-valued forecast services in typical conditions. However, it is hard to cater for all user sensitivities in more extreme conditions. This underscores the importance of providing probability-based services for unusual conditions.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {3},
	urldate = {2021-01-11},
	journal = {Weather and Forecasting},
	author = {Foley, Michael and Loveday, Nicholas},
	month = jan,
	year = {2021},
	note = {Number: 3
Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {1067--1080},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\HAU82MXY\\waf-d-19-0248.1.html:text/html},
}

@article{drost_severe_2016,
	title = {Severe {Weather} {Warning} {Communication}: {Factors} {Impacting} {Audience} {Attention} and {Retention} of {Information} during {Tornado} {Warnings}},
	volume = {8},
	issn = {1948-8327, 1948-8335},
	shorttitle = {Severe {Weather} {Warning} {Communication}},
	url = {https://journals.ametsoc.org/view/journals/wcas/8/4/wcas-d-15-0035_1.xml},
	doi = {10.1175/WCAS-D-15-0035.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d1338e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Weather hazards in the United States inflict both personal and economic tolls on the public. Communicating warnings about weather hazards is an important duty of TV weathercasters. Televised weather warnings are typically conveyed through live radar, live coverage, and warning scrolls. However, these traditional approaches may not be entirely effective given the limited attention some members of the public pay to these warnings. A study comparing individual responses to a traditional warning, an animated warning, and an audio warning was undertaken to evaluate the impact of delivery methods on viewer attention, retention, and preferences during viewing of severe weather warnings. A Tobii T60 eye tracker was used to document visual interactions with on-screen warnings and surveys were used to collect evidence of warning retention and preference. Demographic variables were also collected to describe the study population. Results indicate that viewers of the animated warning retained more pertinent information about the tornado warning than viewers of the traditional warning, and retention during the traditional warning was equivalent to that of the audio warning. In addition, gaze patterns for the traditional warning were much more diffuse than for the animated warning, suggesting that attention was more focused on the animation than the live video. In addition, modifications to reduce visual complexity of traditional warnings may positively impact viewer attention to individual warning elements. Future studies will consider the effectiveness of a hybrid warning containing both traditional and animated components. The current research study can be used to advance current severe weather warning communication techniques and increase public awareness during severe weather events.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {4},
	urldate = {2021-01-11},
	journal = {Weather, Climate, and Society},
	author = {Drost, Robert and Casteel, Mark and Libarkin, Julie and Thomas, Stephen and Meister, Matt},
	month = oct,
	year = {2016},
	note = {Number: 4
Publisher: American Meteorological Society
Section: Weather, Climate, and Society},
	pages = {361--372},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\BUDP7QRT\\Drost et al. - 2016 - Severe Weather Warning Communication Factors Impa.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\S4YED6L5\\wcas-d-15-0035_1.html:text/html},
}

@article{rothfusz_facets_2018,
	title = {{FACETs}: {A} {Proposed} {Next}-{Generation} {Paradigm} for {High}-{Impact} {Weather} {Forecasting}},
	volume = {99},
	issn = {0003-0007, 1520-0477},
	shorttitle = {{FACETs}},
	url = {https://journals.ametsoc.org/view/journals/bams/99/10/bams-d-16-0100.1.xml},
	doi = {10.1175/BAMS-D-16-0100.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d1957e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Recommendations by the National Research Council (NRC), the National Institute of Standards and Technology (NIST), and Weather-Ready Nation workshop participants have encouraged the National Oceanic and Atmospheric Administration (NOAA) and the broader weather enterprise to explore and expand the use of probabilistic information to convey weather forecast uncertainty. Forecasting a Continuum of Environmental Threats (FACETs) is a concept being explored by NOAA to address those recommendations and also potentially shift the National Weather Service (NWS) from (primarily) teletype-era, deterministic watch–warning products to high-resolution, probabilistic hazard information (PHI) spanning periods from days (and longer) to within minutes of high-impact weather and water events. FACETs simultaneously i) considers a reinvention of the NWS hazard forecasting and communication paradigm so as to deliver multiscale, user-specific probabilistic guidance from numerical weather prediction ensembles and ii) provides a comprehensive framework to organize the physical, social, and behavioral sciences, the technology, and the practices needed to achieve that reinvention. The first applications of FACETs have focused on thunderstorm phenomena, but the FACETs concept is envisioned to extend to the attributes of any environmental hazards that can be described probabilistically (e.g., winter, tropical, and aviation weather). This paper introduces the FACETs vision, the motivation for its creation, the research and development under way to explore that vision, its relevance to operational forecasting and society, and possible strategies for implementation.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {10},
	urldate = {2021-01-11},
	journal = {Bulletin of the American Meteorological Society},
	author = {Rothfusz, Lans P. and Schneider, Russell and Novak, David and Klockow-McClain, Kimberly and Gerard, Alan E. and Karstens, Chris and Stumpf, Gregory J. and Smith, Travis M.},
	month = oct,
	year = {2018},
	note = {Number: 10
Publisher: American Meteorological Society
Section: Bulletin of the American Meteorological Society},
	pages = {2025--2043},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\GZUBQZFI\\Rothfusz et al. - 2018 - FACETs A Proposed Next-Generation Paradigm for Hi.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\K2DZWEQD\\bams-d-16-0100.1.html:text/html},
}

@article{nguyen_analysing_2015,
	title = {Analysing motives behind willingness to pay for improving early warning services for tropical cyclones in {Vietnam}},
	volume = {22},
	issn = {1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/met.1441},
	doi = {https://doi.org/10.1002/met.1441},
	abstract = {Pressure on government budgets has made it more important to quantify the value of public goods, e.g. tropical cyclone warning services, to society as a whole. Based on a stated preference survey, in which respondents could indicate the amount of their willingness to pay (WTP), this study elicited values for an improved cyclone warning service in Vietnam. To examine motives or reasons behind respondents' WTP, respondents were requested to allocate 10 points among different types of values, including self-interest motivated value (termed use value), and values with respect to the interests of others (altruistic value) and future generations (bequest value). The more influential the value, the higher the point is scored. Use value, which was scored the highest mean point of 4.1 out of 10, is the most important motive for valuing improvements in cyclone warning services. Altruistic and bequest values were given similar points, approximately 2.9 and 3.0, respectively. This study empirically demonstrates that respondents hold not only self-interest motivated value, but also altruistic and bequest values. Given the importance of non-use values, i.e. altruistic and bequest values, economic assessments focusing on only use value would underestimate the benefits of an improved cyclone warning service to society.},
	language = {en},
	number = {2},
	urldate = {2021-01-11},
	journal = {Meteorological Applications},
	author = {Nguyen, Thanh Cong and Robinson, Jackie},
	year = {2015},
	note = {Number: 2
\_eprint: https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/met.1441},
	keywords = {willingness to pay, altruistic value, bequest value, developing countries, non-use values, tropical cyclone warning services, Vietnam},
	pages = {187--197},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\XL66R6BW\\Nguyen and Robinson - 2015 - Analysing motives behind willingness to pay for im.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\E4D5IQ6S\\met.html:text/html},
}

@article{ahsan_preferences_2020,
	title = {Preferences for improved early warning services among coastal communities at risk in cyclone prone south-west region of {Bangladesh}},
	volume = {5},
	issn = {2590-0617},
	url = {http://www.sciencedirect.com/science/article/pii/S2590061720300028},
	doi = {10.1016/j.pdisas.2020.100065},
	abstract = {Cyclone early warning systems are the primary sources of information that enable people to develop a preparedness strategy to mitigate the hazards of cyclones to lives and livelihoods. In Bangladesh, cyclone early warnings have significantly decreased the number of cyclone related fatalities over the last two decades. Nevertheless, several challenges remain for existing early warning services (EWS), urging for both technical and non-technical improvements in the said services. Given limited financial resources, the economic efficiency assessment of the improvement is highly important. Therefore, this study aims to estimate the willingness to pay (WTP) for improved warning services by considering the at-risk households' trade-off between proposed improved EWS and existing EWS in coastal Bangladesh. Applying systematic random sampling, 490 respondent households were selected from Khulna, Satkhira, and Barguna districts, with whom a choice experiment (CE) was performed. The CE was designed by incorporating impact-based scenarios for improved EWS. As analytical tools, Conditional and Mixed-Logistic regression models were used that derived the WTP for improved EWS attributes. Empirical results show that the WTP of an at-risk household for improved EWS was estimated at Bangladeshi Taka BDT 468 (≈ US\$ 5.57) per year, implying respondents were ready to pay for the improvement of the warning attributes, including precise information of the cyclones landfall time with possible impacts, more frequent radio forecasts, and voice messages in the local dialects over mobile phones. A revenue stream for improved EWS was developed, implying investments in EWS would be a no-regrets approach. This study concludes with four policy recommendations on mitigating the existing challenges for improving EWS in Bangladesh.},
	language = {en},
	urldate = {2021-01-11},
	journal = {Progress in Disaster Science},
	author = {Ahsan, Md. Nasif and Khatun, Amina and Islam, Md. Sariful and Vink, Karina and Ohara, Miho and Fakhruddin, Bapon S. H. M.},
	month = jan,
	year = {2020},
	keywords = {Bangladesh, Choice experiment, Cyclone, Disaster risk, Early warning, Willingness-to-pay},
	pages = {100065},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\KIIK25JV\\Ahsan et al. - 2020 - Preferences for improved early warning services am.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\3QRCZI7L\\S2590061720300028.html:text/html},
}

@article{amegnaglo_contingent_2017,
	title = {Contingent valuation study of the benefits of seasonal climate forecasts for maize farmers in the {Republic} of {Benin}, {West} {Africa}},
	volume = {6},
	doi = {10.1016/j.cliser.2017.06.007},
	abstract = {This study aims to assess the economic benefits of seasonal climate forecasts in West Africa based on a random survey of 354 maize farmers and to use the contingent valuation method. Results indicate that farmers need accurate seasonal climate forecasts between 1 and 2months before the onset of rains. The most desirable dissemination channels are radio, local elders, local farmer meetings and extension agents. The most likely used farming strategies are change of: planting date, crop acreage, crop variety, and production intensification. The vast majority of farmers are willing to pay for seasonal climate forecasts, and the average annual economic value of seasonal climate forecasts are about USD 5492 for the 354 sampled farmers and USD 66.5million dollar at the national level. Furthermore, benefits of seasonal climate forecasts are likely to increase with better access to farmer based organisation, to extension services, to financial services, to modern communication tools, intensity of use of fertilizer and with larger farm sizes. Seasonal climate forecasts are a source of improvement of farmers’ performance and the service should be integrated in extension programmes and in national agricultural development agenda.},
	journal = {Climate Services},
	author = {Amegnaglo, Cocou and Anaman, Kwabena and Mensah-Bonsu, Akwasi and Onumah, Edwards and Gero, Fulbert},
	month = jun,
	year = {2017},
}

@article{ouedraogo_farmers_2018,
	title = {Farmers’ {Willingness} to {Pay} for {Climate} {Information} {Services}: {Evidence} from {Cowpea} and {Sesame} {Producers} in {Northern} {Burkina} {Faso}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Farmers’ {Willingness} to {Pay} for {Climate} {Information} {Services}},
	url = {https://www.mdpi.com/2071-1050/10/3/611},
	doi = {10.3390/su10030611},
	abstract = {Climate information is recognized as a powerful tool to reduce the effect of climate risk and uncertainty on crop production and increase the resilience and the adaptive capacity of farmers in semi-arid zones. This paper estimates farmers’ willingness to pay (WTP) for climate information within cowpea and sesame value chains in Northern Burkina Faso. The study used the contingent valuation method for a monetary valuation of farmers’ preferences for climate information. Data were collected using a structured questionnaire from 170 farmers. The study found that 63\% of respondents were willing to pay for climate information services (CIS) such as seasonal climate forecast (SCF), decadal climate information (10-DCI), daily climate information (1-DCI) and agro-advisories. The predicted value for the WTP was XOF 3496 for SCF, XOF 1066 for 10-DCI, XOF 1985 for 1-DCI and XOF 1628 for agro-advisories. The study also showed that several socioeconomic and motivation factors have greater influence on farmers’ WTP for CIS. These included the gender, age, education of the farm head and the awareness of farm head to climate information. The outcomes of this paper should support policy makers to better design an efficient mechanism for the dissemination of climate information to improve the adaptive capacity of farmers to climate risks in Burkina Faso.},
	language = {en},
	number = {3},
	urldate = {2021-01-11},
	journal = {Sustainability},
	author = {Ouédraogo, Mathieu and Barry, Silamana and Zougmoré, Robert B. and Partey, Samuel Tetteh and Somé, Leopold and Baki, Gregoire},
	month = mar,
	year = {2018},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {adaptation, agriculture, climate risk management, West Africa},
	pages = {611},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\N9YY2CUZ\\Ouédraogo et al. - 2018 - Farmers’ Willingness to Pay for Climate Informatio.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\DC8K9ZSW\\htm.html:text/html},
}

@article{lazo_household_2010,
	title = {Household {Evacuation} {Decision} {Making} and the {Benefits} of {Improved} {Hurricane} {Forecasting}: {Developing} a {Framework} for {Assessment}},
	volume = {25},
	issn = {1520-0434, 0882-8156},
	shorttitle = {Household {Evacuation} {Decision} {Making} and the {Benefits} of {Improved} {Hurricane} {Forecasting}},
	url = {https://journals.ametsoc.org/view/journals/wefo/25/1/2009waf2222310_1.xml},
	doi = {10.1175/2009WAF2222310.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d718e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Hurricane warnings are the primary sources of information that enable the public to assess the risk and develop responses to threats from hurricanes. These warnings have significantly reduced the number of hurricane-related fatalities in the last several decades. Further investment in the science and implementation of the warning system is a primary mission of the National Weather Service and its partners. It is important that the weather community understand the public’s preferences and values for such investments; yet, there is little empirical information on the use of forecasts in evacuation decision making, the economic value of current forecasts, or the potential use or value for improvements in hurricane forecasts. Such information is needed to evaluate whether improved forecast provision and dissemination offer more benefit to society than alternative public investments.{\textless}/p{\textgreater}{\textless}p{\textgreater}Fundamental aspects of households’ perceptions of hurricane forecasts and warnings and their potential uses of and values for improved hurricane forecast information are examined. The study was designed in part to examine the viability of survey research methods for exploring evacuation decision making and for eliciting values for improved hurricane forecasts and warnings. First, aspects that affect households’ stated likelihood of evacuation are explored, because informing such decisions is one of the primary purposes of hurricane forecasts and warnings. Then, stated-choice valuation methods are used to analyze choices between potential forecast-improvement programs and the accuracy of existing forecasts. From this, the willingness to pay (WTP) for improved forecasts is derived from survey respondents.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {1},
	urldate = {2021-01-11},
	journal = {Weather and Forecasting},
	author = {Lazo, Jeffrey K. and Waldman, Donald M. and Morrow, Betty Hearn and Thacher, Jennifer A.},
	month = feb,
	year = {2010},
	note = {Number: 1
Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {207--219},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\LC34AM7J\\Lazo et al. - 2010 - Household Evacuation Decision Making and the Benef.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\Q8QUKWFG\\2009waf2222310_1.html:text/html},
}

@article{soares_assessing_2018,
	title = {Assessing the value of seasonal climate forecasts for decision-making},
	volume = {9},
	copyright = {© 2018 The Authors. WIREs Climate Change published by Wiley Periodicals, Inc.},
	issn = {1757-7799},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcc.523},
	doi = {https://doi.org/10.1002/wcc.523},
	abstract = {Seasonal climate forecasts (SCF) can support decision-making and thus help society cope with and prepare for climate variability and change. The demand for understanding the value and benefits of using SCF in decision-making processes can be associated with different logics. Two of these would be the need to justify public and private investment in the provision of SCF and demonstrating the gains and benefits of using SCF in specific decision-making contexts. This paper reviews the main factors influencing how SCF is (or can be) valued in supporting decision-making and the main methods and metrics currently used to perform such valuations. Our review results in four key findings: (a) there is a current emphasis on economic ex ante studies and the quantification of SCF value; (b) there are fundamental differences in how the value of SCF is defined and estimated across methods and approaches; (c) most valuation methods are unable to capture the differential benefits and risks of using SCF across spatiotemporal scales and groups; and (d) there is limited involvement of the decision-makers in the valuation process. The paper concludes by providing some guiding principles towards more effective valuations of SCF, notably the need for a wider diversity and integration of methodological approaches. These should particularly embrace ex-post, qualitative, and participatory approaches which allow co-evaluation with decision-makers so that more comprehensive and equitable SCF valuations can be developed in future. This article is categorized under: Vulnerability and Adaptation to Climate Change {\textgreater} Institutions for Adaptation},
	language = {en},
	number = {4},
	urldate = {2021-01-11},
	journal = {WIREs Climate Change},
	author = {Soares, Marta Bruno and Daly, Meaghan and Dessai, Suraje},
	year = {2018},
	note = {Number: 4
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wcc.523},
	keywords = {assessing value of climate information, climate services, seasonal climate forecasts, valuation methods, value of climate information for decision-making},
	pages = {e523},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\TRZMIMA2\\Soares et al. - 2018 - Assessing the value of seasonal climate forecasts .pdf:application/pdf},
}

@article{vaughan_evaluating_2019,
	title = {Evaluating agricultural weather and climate services in {Africa}: {Evidence}, methods, and a learning agenda},
	volume = {10},
	issn = {1757-7780, 1757-7799},
	shorttitle = {Evaluating agricultural weather and climate services in {Africa}},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/wcc.586},
	doi = {10.1002/wcc.586},
	abstract = {Weather and climate services (WCS) are expected to improve the capacity of Africa's agricultural sector to manage the risks of climate variability and change. Despite this, a lack of evidence prevents a realistic analysis of whether such services are delivering on their potential. This paper reviews 66 studies that have evaluated outcomes and/or impacts of agricultural WCS in Africa, highlighting areas that have received relatively more attention as well as persistent gaps. While the evaluation of WCS outcomes is relatively straightforward, estimates of the number of people who access and use these services are uneven (covering a small number of communities in 23 of 54 African countries) and highly variable (with access estimates ranging from {\textasciitilde}2 to 86\%, depending on the service and the population). Meanwhile, 22 documents estimate the impact of WCS with respect to yields and/or income. Developed with a variety of methods, these estimates are also wide ranging and illustrate how impact is conditioned on a number of characteristics of the service, the user, and the context in which both operate. The paper uses lessons developed through this review to develop a “learning agenda,” or evidencebuilding roadmap, to establish priorities that can guide work to improve the design, delivery, and impact of agricultural WCS in Africa. Priority learning areas include activities that can strengthen the evidence of access, use, and impacts of WCS, along with those that can advance the use and usability of evidence so as to improve the design and targeting of WCS services.},
	language = {en},
	number = {4},
	urldate = {2021-01-11},
	journal = {WIREs Climate Change},
	author = {Vaughan, Catherine and Hansen, James and Roudier, Philippe and Watkiss, Paul and Carr, Edward},
	month = jul,
	year = {2019},
	note = {Number: 4},
	file = {Vaughan et al. - 2019 - Evaluating agricultural weather and climate servic.pdf:C\:\\Users\\aluga\\Zotero\\storage\\J9EGD8HM\\Vaughan et al. - 2019 - Evaluating agricultural weather and climate servic.pdf:application/pdf},
}

@article{coleman_history_2011,
	title = {The {History} (and {Future}) of {Tornado} {Warning} {Dissemination} in the {United} {States}},
	volume = {92},
	url = {https://journals.ametsoc.org/view/journals/bams/92/5/2010bams3062_1.xml},
	doi = {10.1175/2010BAMS3062.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}p{\textgreater}Since the successful tornado forecast at Tinker AFB in 1948 paved the way for the issuance of tornado warnings, the science of tornado detection and forecasting has advanced greatly. However, tornado warnings must be disseminated to the public to be of any use. The Texas tornado warning conferences in 1953 began to develop the framework for a modern tornado warning system and included radar detection of tornadoes, a spotter network, and improved communications between the U.S. Weather Bureau, spotters, and public officials, allowing more timely warnings and dissemination of those warnings to the public.{\textless}/p{\textgreater}{\textless}p{\textgreater}Commercial radio and television are a main source of warnings for many, and the delivery methods on TV have changed much since 1960. NOAA Weather Radio (NWR) was launched after the 1974 Super Outbreak of tornadoes, with the most important feature being the tone alert that allowed receivers to alert people even when the radio broadcast was turned off. Today, NWR reaches most of the U.S. population, and Specific Area Message Encoding technology has improved its warning precision. Outdoor warning sirens, originally designed for use in enemy attack, were made available for use during tornado warnings around 1970.{\textless}/p{\textgreater}{\textless}p{\textgreater}“Storm based” warnings, adopted by the National Weather Service in 2007, replaced countybased warnings and greatly reduce the warning area. As communications advances continue, tornado warnings will eventually be delivered to precise locations, using GPS and other location technology, through cellular telephones, outdoor sirens, e-mails, and digital television, in addition to NWR.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {5},
	urldate = {2021-01-11},
	journal = {Bulletin of the American Meteorological Society},
	author = {Coleman, Timothy A. and Knupp, Kevin R. and Spann, James and Elliott, J. B. and Peters, Brian E.},
	month = may,
	year = {2011},
	note = {Number: 5
Publisher: American Meteorological Society
Section: Bulletin of the American Meteorological Society},
	pages = {567--582},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\VBRGSANZ\\Coleman et al. - 2011 - The History (and Future) of Tornado Warning Dissem.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\C7HHWVB3\\2010bams3062_1.html:text/html;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\UAQQQ3JN\\2010bams3062_1.html:text/html},
}

@article{lazo_costs_2010,
	title = {The {Costs} and {Losses} of {Integrating} {Social} {Sciences} and {Meteorology}},
	volume = {2},
	url = {https://journals.ametsoc.org/view/journals/wcas/2/3/2010wcas1086_1.xml},
	doi = {10.1175/2010WCAS1086.1},
	abstract = {"The Costs and Losses of Integrating Social Sciences and Meteorology" published on Jul 2010 by American Meteorological Society.},
	language = {EN},
	number = {3},
	urldate = {2021-01-11},
	journal = {Weather, Climate, and Society},
	author = {Lazo, Jeffrey K.},
	month = jul,
	year = {2010},
	note = {Number: 3
Publisher: American Meteorological Society
Section: Weather, Climate, and Society},
	pages = {171--173},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\DCBDLGAH\\2010wcas1086_1.html:text/html},
}

@article{lim_double_2017,
	title = {Double danger in the double wide: {Dimensions} of poverty, housing quality and tornado impacts},
	volume = {65},
	issn = {0166-0462},
	shorttitle = {Double danger in the double wide},
	url = {http://www.sciencedirect.com/science/article/pii/S0166046216300333},
	doi = {10.1016/j.regsciurbeco.2017.04.003},
	abstract = {Tornadoes are the most frequent of the natural hazards in the United States, causing significant yearly human and economic losses. Given the potential destructive power of tornado events and their largely unpredictable nature, it is important to identify the major determinants of vulnerability. To date, only a limited number of studies have empirically investigated the determinants of tornado-induced deaths. Based on a conceptual framework where risk is considered to be a function of physically defined natural hazards and socially constructed vulnerability, we extend previous empirical studies by examining a wider range of potential socio-economic, governmental, and housing factors that determine tornado-induced fatalities. Using detailed county-level data for years 1980–2014, we find that counties with higher per capita income and per capita government spending on public safety and welfare have fewer deaths, whereas counties with greater income disparity are more vulnerable to tornadoes. We explore which aspects of poverty seem most associated with fatalities. Housing quality (measured by mobile homes as a proportion of housing units) is a critical factor in explaining tornado-induced fatalities.},
	language = {en},
	urldate = {2021-01-11},
	journal = {Regional Science and Urban Economics},
	author = {Lim, Jungmin and Loveridge, Scott and Shupp, Robert and Skidmore, Mark},
	month = jul,
	year = {2017},
	keywords = {Development, Housing, Local government, Natural disasters, Poverty, Tornado},
	pages = {1--15},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\LFDT47XP\\Lim et al. - 2017 - Double danger in the double wide Dimensions of po.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\4FYQKLKP\\S0166046216300333.html:text/html},
}

@article{miller_not-so-marginal_2018,
	title = {The {Not}-{So}-{Marginal} {Value} of {Weather} {Warning} {Systems}},
	volume = {10},
	issn = {1948-8327, 1948-8335},
	url = {https://journals.ametsoc.org/view/journals/wcas/10/1/wcas-d-16-0093_1.xml},
	doi = {10.1175/WCAS-D-16-0093.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d2948e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Knowing the benefits of creating or expanding programs is important for determining optimal levels of investment. Yet estimates of the benefits of weather warning systems are sparse, perhaps because there is often no clear counterfactual of how individuals would have fared without a particular warning system. This paper enriches the literature and informs policy decisions by using conditional variation in the initial broadcast dates of the National Oceanic and Atmospheric Administration’s Weather Radio All Hazards (NWR) transmitters to produce both cross-sectional and fixed effects estimates of the causal impact of expanding the NWR transmitter network. Results suggest that from 1970 to 2014, expanding NWR coverage to a previously untreated county was associated with an almost 40\% reduction in injuries and as much as a 50\% reduction in fatalities. The benefits associated with further expansion of this system have likely declined over time.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {1},
	urldate = {2021-01-11},
	journal = {Weather, Climate, and Society},
	author = {Miller, Benjamin M.},
	month = jan,
	year = {2018},
	note = {Number: 1
Publisher: American Meteorological Society
Section: Weather, Climate, and Society},
	pages = {89--101},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\CDHHG8TH\\Miller - 2018 - The Not-So-Marginal Value of Weather Warning Syste.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\MDMZV7AZ\\wcas-d-16-0093_1.html:text/html},
}

@article{sutter_people_2010,
	title = {Do people respond to low probability risks? {Evidence} from tornado risk and manufactured homes},
	volume = {40},
	issn = {1573-0476},
	shorttitle = {Do people respond to low probability risks?},
	url = {https://doi.org/10.1007/s11166-010-9087-8},
	doi = {10.1007/s11166-010-9087-8},
	abstract = {Whether people perceive and respond to low-probability natural hazards is a research question of considerable policy relevance. We obtain evidence by considering the response of housing choice to tornado risk for manufactured homes. The vulnerability of manufactured housing, combined with its growing share of the U.S. housing market, has led to proposed mandates for community shelters in mobile home parks. Expected utility theory, however, predicts that households should account for tornado risk in their housing choice. We test for an effect of tornado risk on manufactured housing demand using cross-sectional state data, as well as counties in three tornado prone states. We find that people do respond to tornado risk; our estimates indicate that each expected annual state tornado death per million residents reduces demand for manufactured homes by about 3\%. The estimated quantity effect is consistent with the market studies of the price elasticity of manufactured homes.},
	language = {en},
	number = {2},
	urldate = {2021-01-11},
	journal = {Journal of Risk and Uncertainty},
	author = {Sutter, Daniel and Poitras, Marc},
	month = apr,
	year = {2010},
	note = {Number: 2},
	pages = {181--196},
	file = {Springer Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\BL9GC27W\\Sutter and Poitras - 2010 - Do people respond to low probability risks Eviden.pdf:application/pdf},
}

@article{simmons_preparing_2014,
	title = {Preparing for {Danger}: {On} the {Impact} of {Tornado} {Watches} on {Tornado} {Casualties} - {International} {Journal} of {Mass} {Emergencies} and {Disasters}},
	volume = {32},
	url = {http://www.ijmed.org/articles/647/},
	number = {1},
	urldate = {2021-01-11},
	journal = {International Journal of Mass Emergencies and Disasters},
	author = {Simmons, Kevin M. and Sutter, Daniel},
	year = {2014},
	note = {Number: 1},
	pages = {1--25},
	file = {Preparing for Danger\: On the Impact of Tornado Watches on Tornado Casualties - International Journal of Mass Emergencies and Disasters:C\:\\Users\\aluga\\Zotero\\storage\\P9E3DF2Q\\647.html:text/html},
}

@article{tesfaye_estimating_2019,
	title = {Estimating the economic value of climate services for strengthening resilience of smallholder farmers to climate risks in {Ethiopia}: {A} choice experiment approach},
	volume = {162},
	issn = {0921-8009},
	shorttitle = {Estimating the economic value of climate services for strengthening resilience of smallholder farmers to climate risks in {Ethiopia}},
	url = {http://www.sciencedirect.com/science/article/pii/S0921800918318925},
	doi = {10.1016/j.ecolecon.2019.04.019},
	abstract = {This study estimated the economic value of agricultural climate services for strengthening the resilience of smallholder farmers to climate variability and risks in Ethiopia. Using a choice experiment approach, the study introduced a hypothetical package of improved climate services to 600 randomly selected smallholder farmers in three districts across three different agro-ecological zones in the Oromia Regional State. A generalized multinomial logit (G-MNL) model was used to estimate preferred attributes of climate services and willingness-to-pay (WTP) values. The results show that the preferred bundle of improved climate services among smallholder farmers was one that could be communicated in short text message system, provided along with credit facility, and market information and one that favors participatory decision making by smallholders. The results further reveal that the WTP value exhibited high implicit price for participatory decision-making. The study sheds light on important characteristics of agricultural climate services that may improve their acceptability and usability among smallholders. It also highlights the importance of packaging additional services including digital and ICT-based solutions, financial and market information along with climate services to promote demand-driven last mile delivery systems. Engaging smallholder farmers in a participatory manner in the decision-making process can help them make informed decision.},
	language = {en},
	urldate = {2021-01-11},
	journal = {Ecological Economics},
	author = {Tesfaye, Abonesh and Hansen, James and Kassie, Girma Tesfahun and Radeny, Maren and Solomon, Dawit},
	month = aug,
	year = {2019},
	keywords = {Choice Experiment, Climate Services, Climate Variability and Risks, Ethiopia, G-MNL Model, Smallholder Farmers, Willingness to Pay},
	pages = {157--168},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\6MLAIS3W\\Tesfaye et al. - 2019 - Estimating the economic value of climate services .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\ABPUK3CB\\S0921800918318925.html:text/html},
}

@incollection{carson_incentive_2011,
	title = {Incentive and {Information} {Properties} of {Preference} {Questions}: {Commentary} and {Extensions}},
	volume = {37},
	shorttitle = {Incentive and {Information} {Properties} of {Preference} {Questions}},
	abstract = {This chapter is both a commentary on and extension of the Carson and Groves (2007) (hereafter CG) article reprinted in this volume. The substantial attention the paper has received has been enormously gratifying. Reception of CG has largely been positive with little if any substantive criticism directed toward it; and, there are many papers now being presented at conferences that are testing or relying on various aspects of it. Our remarks are organized into a series of short sections. The first points out that the main purpose of CG was to extend the revealed preference paradigm to cover some types of survey responses. The second notes that CG provides the theoretical foundation that some critics of contingent valuation (CV) had argued was missing. The third takes the concepts of â€œhypotheticalâ€ and â€œhypothetical biasâ€ head on and argues that these concepts are, for the most part, ill-defined or simply wrong and have done enormous damage to clear and careful thinking about the nature of the response to stated preference questions. The fourth examines the properties of cheap talk which is often proposed as a way to reduced hypothetical bias. The fifth provides some elaboration on CG and the issue of how to interpret information extracted from preferences questions. The sixth poses an answer to the often asked question: Is a single binary discrete choice (SBC) question always the best elicitation format for a researcher to use? The seventh provides some elaboration on the payment card elicitation format, which in recent years has seen resurgence. The eighth turns to an examination of some of the properties of the now widely used discrete choice experiment. The ninth considers the usefulness of economic experiments to help determine the performance of preference elicitation formats. The last section addresses the relationship between CG and the behavioralist critique of neoclassical economics with a focus on the different-answers-to-the-same-underly},
	booktitle = {Environmental and {Resource} {Economics}},
	author = {Carson, Richard and Groves, Theodore},
	month = jan,
	year = {2011},
	note = {Journal Abbreviation: Environmental and Resource Economics},
	pages = {181--210},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\6PEY9SMN\\Carson and Groves - 2011 - Incentive and Information Properties of Preference.pdf:application/pdf},
}

@article{carson_incentive_2007,
	title = {Incentive and informational properties of preference questions},
	volume = {37},
	issn = {1573-1502},
	url = {https://doi.org/10.1007/s10640-007-9124-5},
	doi = {10.1007/s10640-007-9124-5},
	abstract = {Surveys are frequently used by businesses and governments to elicit information about the public’s preferences. They have become the most common way to gather preference information regarding goods, that are not (or are not yet) bought or sold in markets. In this paper we apply the standard neoclassical economic framework to generate predictions about how rational agents would answer such survey questions, which in turn implies how such survey data should be interpreted. In some situations, the standard economic model would be expected to have no predictive power. For situations where it does have predictive power, we compare different survey formats with respect to: (a) the information that the question itself reveals to the respondent, (b) the strategic incentives the respondent faces in answering the question, and (c) the information revealed by the respondent’s answer.},
	language = {en},
	number = {1},
	urldate = {2021-01-11},
	journal = {Environmental and Resource Economics},
	author = {Carson, Richard T. and Groves, Theodore},
	month = may,
	year = {2007},
	note = {Number: 1},
	pages = {181--210},
	file = {Springer Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\5MY2BSH2\\Carson and Groves - 2007 - Incentive and informational properties of preferen.pdf:application/pdf},
}

@article{carson_consequentiality_2014,
	title = {Consequentiality: {A} {Theoretical} and {Experimental} {Exploration} of a {Single} {Binary} {Choice}},
	volume = {1},
	issn = {2333-5955},
	shorttitle = {Consequentiality},
	url = {https://www.journals.uchicago.edu/doi/full/10.1086/676450},
	doi = {10.1086/676450},
	abstract = {Researchers, using contingent valuation (CV) to value changes in nonmarket goods, typically believe respondents always answer questions truthfully or they answer truthfully only when it is in their interest to do so. The second position, while consistent with economic theory, implies that interpreting survey responses depends critically on the incentive structure provided. We derive simple tests capable of distinguishing the two views. Our theoretical model for examining the incentive structure of a single binary choice relaxes the usual expected utility assumption. We test our theory using a field experiment involving voting to provide a public good. Experimental results are consistent theoretical predictions and cast doubt on the relevance of a large experimental literature using inconsequential questions and non-incentive-compatible mechanisms to make inferences about CV. The framework put forth should help in understanding the role played by theoretical conditions for preference elicitation and lend insight into the hypothetical bias literature.},
	number = {1/2},
	urldate = {2021-01-11},
	journal = {Journal of the Association of Environmental and Resource Economists},
	author = {Carson, Richard T. and Groves, Theodore and List, John A.},
	month = mar,
	year = {2014},
	note = {Number: 1/2
Publisher: The University of Chicago Press},
	pages = {171--207},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\U7HDHAHL\\Carson et al. - 2014 - Consequentiality A Theoretical and Experimental E.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\B9FS535P\\676450.html:text/html},
}

@article{johnston_contemporary_2017,
	title = {Contemporary {Guidance} for {Stated} {Preference} {Studies}},
	volume = {4},
	issn = {2333-5955},
	url = {https://www.journals.uchicago.edu/doi/abs/10.1086/691697},
	doi = {10.1086/691697},
	abstract = {This article proposes contemporary best-practice recommendations for stated preference (SP) studies used to inform decision making, grounded in the accumulated body of peer-reviewed literature. These recommendations consider the use of SP methods to estimate both use and non-use (passive-use) values, and cover the broad SP domain, including contingent valuation and discrete choice experiments. We focus on applications to public goods in the context of the environment and human health but also consider ways in which the proposed recommendations might apply to other common areas of application. The recommendations recognize that SP results may be used and reused (benefit transfers) by governmental agencies and nongovernmental organizations, and that all such applications must be considered. The intended result is a set of guidelines for SP studies that is more comprehensive than that of the original National Oceanic and Atmospheric Administration (NOAA) Blue Ribbon Panel on contingent valuation, is more germane to contemporary applications, and reflects the two decades of research since that time. We also distinguish between practices for which accumulated research is sufficient to support recommendations and those for which greater uncertainty remains. The goal of this article is to raise the quality of SP studies used to support decision making and promote research that will further enhance the practice of these studies worldwide.},
	number = {2},
	urldate = {2021-01-11},
	journal = {Journal of the Association of Environmental and Resource Economists},
	author = {Johnston, Robert J. and Boyle, Kevin J. and Adamowicz, Wiktor (Vic) and Bennett, Jeff and Brouwer, Roy and Cameron, Trudy Ann and Hanemann, W. Michael and Hanley, Nick and Ryan, Mandy and Scarpa, Riccardo and Tourangeau, Roger and Vossler, Christian A.},
	month = feb,
	year = {2017},
	note = {Number: 2
Publisher: The University of Chicago Press},
	pages = {319--405},
	file = {Full Text:C\:\\Users\\aluga\\Zotero\\storage\\L4VXE3YG\\Johnston et al. - 2017 - Contemporary Guidance for Stated Preference Studie.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\JJA867MZ\\691697.html:text/html},
}

@article{bishop_putting_2017,
	title = {Putting a value on injuries to natural assets: {The} {BP} oil spill},
	volume = {356},
	copyright = {Copyright © 2017, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	shorttitle = {Putting a value on injuries to natural assets},
	url = {https://science.sciencemag.org/content/356/6335/253},
	doi = {10.1126/science.aam8124},
	abstract = {When large-scale accidents cause catastrophic damage to natural or cultural resources, government and industry are faced with the challenge of assessing the extent of damages and the magnitude of restoration that is warranted. Although market transactions for privately owned assets provide information about how valuable they are to the people involved, the public services of natural assets are not exchanged on markets; thus, efforts to learn about people's values involve either untestable assumptions about how other things people do relate to these services or empirical estimates based on responses to stated-preference surveys. Valuation based on such surveys has been criticized because the respondents are not engaged in real transactions. Our research in the aftermath of the 2010 BP Deepwater Horizon oil spill addresses these criticisms using the first, nationally representative, stated-preference survey that tests whether responses are consistent with rational economic choices that are expected with real transactions. Our results confirm that the survey findings are consistent with economic decisions and would support investing at least \$17.2 billion to prevent such injuries in the future to the Gulf of Mexico's natural resources.
Stated-preference research supports \$17.2B in protections
Stated-preference research supports \$17.2B in protections},
	language = {en},
	number = {6335},
	urldate = {2021-01-12},
	journal = {Science},
	author = {Bishop, Richard C. and Boyle, Kevin J. and Carson, Richard T. and Chapman, David and Hanemann, W. Michael and Kanninen, Barbara and Kopp, Raymond J. and Krosnick, Jon A. and List, John and Meade, Norman and Paterson, Robert and Presser, Stanley and Smith, V. Kerry and Tourangeau, Roger and Welsh, Michael and Wooldridge, Jeffrey M. and DeBell, Matthew and Donovan, Colleen and Konopka, Matthew and Scherer, Nora},
	month = apr,
	year = {2017},
	pmid = {28428387},
	note = {Number: 6335
Publisher: American Association for the Advancement of Science
Section: Policy Forum},
	pages = {253--254},
	file = {Full Text:C\:\\Users\\aluga\\Zotero\\storage\\FIBGJ9PI\\Bishop et al. - 2017 - Putting a value on injuries to natural assets The.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\T6MXGDPW\\253.html:text/html},
}

@article{egan_three_2015,
	title = {Three reasons to use annual payments in contingent valuation surveys: {Convergent} validity, discount rates, and mental accounting},
	volume = {72},
	shorttitle = {Three reasons to use annual payments in contingent valuation surveys},
	url = {https://ideas.repec.org/a/eee/jeeman/v72y2015icp123-136.html},
	abstract = {We present three arguments for using ongoing annual payments in contingent valuation (CV) surveys that estimate the benefit of a long-lasting environmental improvement. First, by matching the duration of the payments with the duration of the environmental benefits, survey respondents are spared from performing complicated present value calculations. Second, willingness to pay (WTP) estimates from CV surveys that include ongoing annual payments best match WTP estimates obtained using travel cost surveys. Third, respondents are less likely to face binding mental budget constraints with ongoing annual payments than with a larger one-time payment. In addition, respondents’ discount rates may be estimated by collecting non-hypothetical, individual time preference data as part of the valuation survey.},
	language = {en},
	number = {C},
	urldate = {2021-01-12},
	journal = {Journal of Environmental Economics and Management},
	author = {Egan, Kevin J. and Corrigan, Jay R. and Dwyer, Daryl F.},
	year = {2015},
	note = {Number: C
Publisher: Elsevier},
	keywords = {Contingent valuation, Convergent validity, Discounting, Time frame, Time horizon, Wetlands, Willingness to pay},
	pages = {123--136},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\2N7XP657\\v72y2015icp123-136.html:text/html},
}

@book{arrow_report_1993,
	title = {Report of the {NOAA} panel on {Contingent} {Valuation}},
	volume = {58},
	abstract = {How to conduct a proper contingent valuation study. Reccomendations},
	author = {Arrow, Kenneth and Solow, Robert and Portney, Paul and Leamer, Edward and Radner, Roy and Schuman, Howard},
	month = jan,
	year = {1993},
	note = {Journal Abbreviation: Federal Register
Publication Title: Federal Register},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\5P8LZ7DS\\Arrow et al. - 1993 - Report of the NOAA panel on Contingent Valuation.pdf:application/pdf},
}

@article{millner_what_2009,
	title = {What {Is} the {True} {Value} of {Forecasts}?},
	volume = {1},
	issn = {1948-8327, 1948-8335},
	url = {https://journals.ametsoc.org/view/journals/wcas/1/1/2009wcas1001_1.xml},
	doi = {10.1175/2009WCAS1001.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d8e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Understanding the economic value of weather and climate forecasts is of tremendous practical importance. Traditional models that have attempted to gauge forecast value have focused on a best-case scenario, in which forecast users are assumed to be statistically sophisticated, hyperrational decision makers with perfect knowledge and understanding of forecast performance. These models provide a normative benchmark for assessing forecast value, but say nothing about the value that actual forecast users realize. Real forecast users are subject to a variety of behavioral effects and informational constraints that violate the assumptions of normative models. In this paper, one of the normative assumptions about user behavior is relaxed—users are no longer assumed to be in possession of a perfect statistical understanding of forecast performance. In the case of a cost–loss decision, it is shown that a model of users’ forecast use choices based on the psychological theory of reinforcement learning leads to a behavioral adjustment factor that lowers the relative value score that the user achieves. The dependence of this factor on the user’s decision parameters (the ratio of costs to losses) and the forecast skill is deduced. Differences between the losses predicted by the behavioral and normative models are greatest for users with intermediate cost–loss ratios, and when forecasts have intermediate skill. The relevance of the model as a tool for directing user education initiatives is briefly discussed, and a direction for future research is proposed.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {1},
	urldate = {2021-01-12},
	journal = {Weather, Climate, and Society},
	author = {Millner, Antony},
	month = oct,
	year = {2009},
	note = {Number: 1
Publisher: American Meteorological Society
Section: Weather, Climate, and Society},
	pages = {22--37},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\Z9N6PQR7\\Millner - 2009 - What Is the True Value of Forecasts.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\P229ASFC\\2009wcas1001_1.html:text/html},
}

@techreport{uccellini_report_2017,
	title = {Report to {Congress}: {Tornado} {Warning} {Improvement} and {Extension} {Program} {Plan}},
	url = {https://repository.library.noaa.gov/view/noaa/22035},
	urldate = {2021-01-12},
	author = {Uccellini, Louis and Volz, Stephen and Jacobs, Neil},
	year = {2017},
	file = {Report to Congress\: Tornado Warning Improvement and Extension Program Plan:C\:\\Users\\aluga\\Zotero\\storage\\MRV7486H\\22035.html:text/html},
}

@article{krzysztofowicz_forecast_1991,
	title = {Forecast {Sufficiency} {Characteristic}: {Construction} and {Application}},
	volume = {7},
	issn = {0169-2070},
	shorttitle = {Forecast {Sufficiency} {Characteristic}},
	url = {http://search.proquest.com/docview/56460289?pq-origsite=summon},
	abstract = {The binary relation of sufficiency induces a quasi order among alternative forecast systems, consistent with their order in terms of economic values, yet independent of the prior distribution and the loss function. This invariance across decision problems makes the sufficiency relation an attractive tool for comparing forecasts serving multiple users. The existence of the sufficiency relation between discrete probabilistic forecasts of binary events may be verified graphically by plotting Forecast Sufficiency Characteristics (FSC). The article presents a general algorithm for constructing FSC and illustrates the concept with an application to real meteorolgic forecasts.},
	language = {English},
	number = {1},
	urldate = {2021-01-13},
	journal = {International Journal of Forecasting},
	author = {Krzysztofowicz, Roman and Long, Dou},
	year = {1991},
	note = {Number: 1
Num Pages: 7},
	keywords = {Bayesian Analysis: General (C11), Forecast, Forecasting Models, Forecasts, Simulation Methods (C53)},
	pages = {39--45},
}

@article{katz_qualityvalue_1990,
	title = {Quality/value relationships for imperfect weather forecasts in a prototype multistage decision-making model},
	volume = {9},
	copyright = {Copyright © 1990 John Wiley \& Sons, Ltd.},
	issn = {1099-131X},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/for.3980090107},
	doi = {https://doi.org/10.1002/for.3980090107},
	abstract = {Some theoretical results concerning the nature of the relationship between the scientific quality and economic value of imperfect weather forecasts are obtained. A prototype multistage decision-making model is considered, involving only two possible actions and two possible states of weather. This particular form of model is motivated by a real-world application known as the fruit-frost problem. For an infinite-horizon, discounted version of this model it is shown that economic value remains zero below a forecast quality threshold and then rises monotonically but nonlinearly above this threshold. In particular, the relative sensitivity of economic value to changes in the quality of forecasts increases as perfect information is approached. This curve is compared with quality/value relationships that have been obtained for other versions of the model; namely, a single-stage model and a multistage, finite-horizon model.},
	language = {en},
	number = {1},
	urldate = {2021-01-13},
	journal = {Journal of Forecasting},
	author = {Katz, Richard W. and Murphy, Allan H.},
	year = {1990},
	note = {Number: 1
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/for.3980090107},
	keywords = {Dynamic programming, Markov decision process, Value of information, Weather forecasts},
	pages = {75--86},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\HFGV5YGS\\Katz and Murphy - 1990 - Qualityvalue relationships for imperfect weather .pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\8BFJG34K\\for.html:text/html},
}

@article{regnier_dynamic_2006,
	title = {A {Dynamic} {Decision} {Model} {Applied} to {Hurricane} {Landfall}},
	volume = {21},
	copyright = {Copyright American Meteorological Society Oct 2006},
	issn = {08828156},
	url = {http://search.proquest.com/docview/196334558/abstract/81FCE1E03019448APQ/1},
	abstract = {The decision to prepare for an oncoming hurricane is typically framed as a static cost:loss problem, based on a strike-probability forecast. The value of waiting for updated forecasts is therefore neglected. In this paper, the problem is reframed as a sequence of interrelated decisions that more accurately represents the situation faced by a decision maker monitoring an evolving tropical cyclone. A key feature of the decision model is that the decision maker explicitly anticipates and plans for future forecasts whose accuracy improves as lead time declines. A discrete Markov model of hurricane travel is derived from historical tropical cyclone tracks and combined with the dynamic decision model to estimate the additional value that can be extracted from existing forecasts by anticipating updated forecasts, rather than incurring an irreversible preparation cost based on the instantaneous strike probability. The value of anticipating forecasts depends on the specific alternatives and cost profile of each decision maker, but conceptual examples for targets at Norfolk, Virginia, and Galveston, Texas, yield expected savings ranging up to 8\% relative to repeated static decisions. In real-time decision making, forecasts of improving information quality could be used in combination with strike-probability forecasts to evaluate the trade-off between lead time and forecast accuracy, estimate the value of waiting for improving forecasts, and thereby reduce the frequency of false alarms. [PUBLICATION ABSTRACT]},
	language = {English},
	number = {5},
	urldate = {2021-01-13},
	journal = {Weather and Forecasting},
	author = {Regnier, Eva and Harr, Patrick A.},
	month = oct,
	year = {2006},
	note = {Number: 5
Num Pages: 17
Place: Boston, United States
Publisher: American Meteorological Society},
	keywords = {Cyclones, Decision making models, Hurricanes, Meteorology, Weather forecasting},
	pages = {764--780},
	file = {Full Text Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\CUFH49KC\\1.html:text/html},
}

@article{kramer_valuing_1997,
	title = {Valuing a {Global} {Environmental} {Good}: {U}.{S}. {Residents}' {Willingness} to {Pay} to {Protect} {Tropical} {Rain} {Forests}},
	volume = {73},
	issn = {0023-7639},
	shorttitle = {Valuing a {Global} {Environmental} {Good}},
	url = {http://search.proquest.com/docview/56706346?pq-origsite=summon},
	abstract = {Although contingent valuation is the most common technique for valuing nonmarket environmental resources, rarely has it been applied to global environmental goods. This study uses contingent valuation in a national survey to assess the value U.S. residents place on tropical rain forest protection. On average, respondents were willing to make a one-time payment of approximately \$21-31 per household to protect an additional 5 percent of tropical forests. Although respondents were able to give consistent responses across two different contingent valuation formats, focus groups were unwilling or unable to allocate their aggregate rainforest valuations across or among regions or specific rain forests.},
	language = {English},
	number = {2},
	urldate = {2021-01-13},
	journal = {Land Economics},
	author = {Kramer, Randall A. and Mercer, D. Evan},
	year = {1997},
	note = {Number: 2
Num Pages: 15},
	keywords = {Willingness to Pay, Contingent Valuation, Forest, Northern America, Recreational Aspects of Natural Resources (Q26), Renewable Resources and Conservation: Forestry (Q23), Resources, U.S.},
	pages = {196--210},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\KEP33CM9\\Kramer and Mercer - 1997 - Valuing a Global Environmental Good U.S. Resident.pdf:application/pdf},
}

@article{hite_willingness_2002,
	title = {Willingness to {Pay} for {Water} {Quality} {Improvements}: {The} {Case} of {Precision} {Application} {Technology}},
	volume = {27},
	issn = {1068-5502},
	shorttitle = {Willingness to {Pay} for {Water} {Quality} {Improvements}},
	url = {http://search.proquest.com/docview/56153770?pq-origsite=summon},
	abstract = {A contingent valuation survey conducted in Mississippi is used to assess public willingness to pay for reductions in agricultural nonpoint pollution. The analysis focuses on implementation of a policy to provide farmers with precision application equipment to reduce nutrient runoff. Findings suggest public support exists for such policies. This study also finds that inclusion of debriefing questions can be used to refine willingness-to-pay estimates in contingent valuation studies. A nonparametric scope test suggests respondents are sensitive to level of runoff reduction and associated water-quality benefits.},
	language = {English},
	number = {2},
	urldate = {2021-01-13},
	journal = {Journal of Agricultural and Resource Economics},
	author = {Hite, Diane and Hudson, Darren and Intarapapong, Walaiporn},
	year = {2002},
	note = {Number: 2
Num Pages: 17},
	keywords = {Willingness to Pay, Contingent Valuation, Northern America, Recreational Aspects of Natural Resources (Q26), U.S., Pollution, Renewable Resources and Conservation: Water (Q25), Water},
	pages = {433--449},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\YAAL9IME\\Hite et al. - 2002 - Willingness to Pay for Water Quality Improvements.pdf:application/pdf},
}

@article{hoekstra_preliminary_2011,
	title = {A {Preliminary} {Look} at the {Social} {Perspective} of {Warn}-on-{Forecast}: {Preferred} {Tornado} {Warning} {Lead} {Time} and the {General} {Public}’s {Perceptions} of {Weather} {Risks}},
	volume = {3},
	issn = {1948-8327, 1948-8335},
	shorttitle = {A {Preliminary} {Look} at the {Social} {Perspective} of {Warn}-on-{Forecast}},
	url = {https://journals.ametsoc.org/view/journals/wcas/3/2/2011wcas1076_1.xml},
	doi = {10.1175/2011WCAS1076.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d353e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Tornado warnings are currently issued an average of 13 min in advance of a tornado and are based on a warn-on-detection paradigm. However, computer model improvements may allow for a new warning paradigm, warn-on-forecast, to be established in the future. This would mean that tornado warnings could be issued one to two hours in advance, prior to storm initiation. In anticipation of the technological innovation, this study inquires whether the warn-on-forecast paradigm for tornado warnings may be preferred by the public (i.e., individuals and households). The authors sample is drawn from visitors to the National Weather Center in Norman, Oklahoma. During the summer and fall of 2009, surveys were distributed to 320 participants to assess their understanding and perception of weather risks and preferred tornado warning lead time. Responses were analyzed according to several different parameters including age, region of residency, educational level, number of children, and prior tornado experience. A majority of the respondents answered many of the weather risk questions correctly. They seemed to be familiar with tornado seasons; however, they were unaware of the relative number of fatalities caused by tornadoes and several additional weather phenomena each year in the United States. The preferred lead time was 34.3 min according to average survey responses. This suggests that while the general public may currently prefer a longer average lead time than the present system offers, the preference does not extend to the 1–2-h time frame theoretically offered by the warn-on-forecast system. When asked what they would do if given a 1-h lead time, respondents reported that taking shelter was a lesser priority than when given a 15-min lead time, and fleeing the area became a slightly more popular alternative. A majority of respondents also reported the situation would feel less life threatening if given a 1-h lead time. These results suggest that how the public responds to longer lead times may be complex and situationally dependent, and further study must be conducted to ascertain the users for whom the longer lead times would carry the most value. These results form the basis of an informative stated-preference approach to predicting public response to long (\&gt;1 h) warning lead times, using public understanding of the risks posed by severe weather events to contextualize lead-time demand.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {2},
	urldate = {2021-01-13},
	journal = {Weather, Climate, and Society},
	author = {Hoekstra, S. and Klockow, K. and Riley, R. and Brotzge, J. and Brooks, H. and Erickson, S.},
	month = apr,
	year = {2011},
	note = {Number: 2
Publisher: American Meteorological Society
Section: Weather, Climate, and Society},
	pages = {128--140},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\X652F78J\\Hoekstra et al. - 2011 - A Preliminary Look at the Social Perspective of Wa.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\38AQK3CB\\2011wcas1076_1.html:text/html},
}

@techreport{lazo_economic_2002,
	title = {Economic {Value} of {Current} and {Improved} {Weather} {Forecasts} in the {U}.{S}. {Household} {Sector}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.170.7648&rep=rep1&type=pdf},
	institution = {Office of Policy and Strategic Planning},
	author = {Lazo, Jeffrey K. and Chestnut, Lauraine G.},
	year = {2002},
	file = {Citeseer - Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\BVF3LKL8\\Weiher et al. - 2002 - Sc10050 Economic Value of Current and Improved Wea.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\3HCHC4XE\\summary.html:text/html},
}

@book{ericsson_protocol_1984,
	address = {Cambridge, MA, US},
	series = {Protocol analysis:  {Verbal} reports as data},
	title = {Protocol analysis:  {Verbal} reports as data},
	isbn = {978-0-262-55012-3},
	shorttitle = {Protocol analysis},
	abstract = {While psychologists have often employed the technique of protocol analysis—or the use of the subject's own verbal reports as data—in exploring cognitive processes, the nature and reliability of the method have been poorly understood. This book finally puts protocol analysis on firm ground by examining its underlying assumptions, techniques, and limitations. It addresses such key questions as what sorts of reports about what sorts of mental events are reliable; what the role of the investigator's interpretations should be in helping to understand such data; and what mental events cannot be explained by protocols.  The authors describe a general theory of cognitive processes and structure in the form of an information processing model, which, they argue, accounts for verbalization and verbal reports. Major issues surrounding the use and validity of verbal reports are taken up, and empirical studies are discussed within the framework of the model. While "Protocol Analysis" focuses on reports of cognitive processes, the concepts and models it employs can be extended to such areas of verbal behavior as psychophysics, survey design, and measurement of personality traits. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {The MIT Press},
	author = {Ericsson, K. Anders and Simon, Herbert A.},
	year = {1984},
	note = {Pages: 426},
	keywords = {Cognitive Processes, Measurement, Oral Communication, Self-Report},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\GC2WI23U\\1985-97337-000.html:text/html},
}

@book{dillman_internet_2008,
	address = {Hoboken, N.J},
	edition = {3rd edition},
	title = {Internet, {Mail}, and {Mixed}-{Mode} {Surveys}: {The} {Tailored} {Design} {Method}},
	isbn = {978-0-471-69868-5},
	shorttitle = {Internet, {Mail}, and {Mixed}-{Mode} {Surveys}},
	abstract = {A complete, start-to-finish guide for every researcher to successfully plan and conduct Internet, mail, and telephone surveys, Internet, Mail, and Mixed-Mode Surveys: The Tailored Design Method, Third Edition presents a succinct review of survey research methods, equipping you to increase the validity and reliability, as well as response rates, of your surveys. Now thoroughly updated and revised with information about all aspects of survey research?grounded in the most current research?the new edition provides practical ?how-to? guidelines on optimally using the Internet, mail, and phone channels to your advantage.},
	language = {English},
	publisher = {Wiley},
	author = {Dillman, Don A. and Smyth, Jolene D. and Christian, Leah Melani},
	month = oct,
	year = {2008},
}

@article{katz_qualityvalue_1987,
	title = {Quality/{Value} {Relationship} for {Imperfect} {Information} in the {Umbrella} {Problem}},
	volume = {41},
	issn = {0003-1305},
	url = {https://amstat.tandfonline.com/doi/abs/10.1080/00031305.1987.10475475},
	doi = {10.1080/00031305.1987.10475475},
	abstract = {The so-called umbrella problem (or cost-loss ratio situation), in which an individual must decide whether to take an umbrella in the face of uncertainty concerning whether it will rain today, is sometimes used as a textbook example of decision making under uncertainty. This problem is extended to provide a simple demonstration of the way in which the economic value of imperfect information changes as its quality increases.},
	number = {3},
	urldate = {2021-02-22},
	journal = {The American Statistician},
	author = {Katz, Richard W. and Murphy, Allan H.},
	month = aug,
	year = {1987},
	note = {Number: 3
Publisher: Taylor \& Francis},
	pages = {187--189},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\RTFMZJW3\\00031305.1987.html:text/html},
}

@article{senkbeil_ethnic_2014,
	title = {Ethnic and {Racial} {Differences} in {Tornado} {Hazard} {Perception}, {Preparedness}, and {Shelter} {Lead} {Time} in {Tuscaloosa}},
	volume = {66},
	issn = {0033-0124},
	url = {https://doi.org/10.1080/00330124.2013.826562},
	doi = {10.1080/00330124.2013.826562},
	abstract = {The 27 April 2011 EF4 Tuscaloosa tornado directly impacted more than 50,000 residents, causing forty-five fatalities within the city and sixty-five in total. It was a rare urban tornado with varying impacts on the three major ethnic and racial groups within the city. A hybrid survey and interview of open-ended and closed questions was conducted with 211 Tuscaloosa area residents in a two-week period after the tornado. Results indicate significant differences in risk perception, preparedness, and shelter lead time among the three ethnic and racial groups. Furthermore, results were still significant for perception after controlling for the effects of age, education, and experience.},
	number = {4},
	urldate = {2021-05-05},
	journal = {The Professional Geographer},
	author = {Senkbeil, Jason C. and Scott, David A. and Guinazu-Walker, Pilar and Rockman, Meganne S.},
	month = oct,
	year = {2014},
	note = {Number: 4
Publisher: Routledge
\_eprint: https://doi.org/10.1080/00330124.2013.826562},
	keywords = {ethnicity, etnicidad, percepción, perception, preparación, preparedness, refugio, shelter, tornado, 准备, 感知, 族裔, 避难, 龙捲风},
	pages = {610--620},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\S3EZYJSU\\Senkbeil et al. - 2014 - Ethnic and Racial Differences in Tornado Hazard Pe.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\EMC23UQT\\00330124.2013.html:text/html},
}

@article{hoekstra_preliminary_2011-1,
	title = {A {Preliminary} {Look} at the {Social} {Perspective} of {Warn}-on-{Forecast}: {Preferred} {Tornado} {Warning} {Lead} {Time} and the {General} {Public}’s {Perceptions} of {Weather} {Risks}},
	volume = {3},
	issn = {1948-8327, 1948-8335},
	shorttitle = {A {Preliminary} {Look} at the {Social} {Perspective} of {Warn}-on-{Forecast}},
	url = {https://journals.ametsoc.org/view/journals/wcas/3/2/2011wcas1076_1.xml},
	doi = {10.1175/2011WCAS1076.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d5822806e146"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Tornado warnings are currently issued an average of 13 min in advance of a tornado and are based on a warn-on-detection paradigm. However, computer model improvements may allow for a new warning paradigm, warn-on-forecast, to be established in the future. This would mean that tornado warnings could be issued one to two hours in advance, prior to storm initiation. In anticipation of the technological innovation, this study inquires whether the warn-on-forecast paradigm for tornado warnings may be preferred by the public (i.e., individuals and households). The authors sample is drawn from visitors to the National Weather Center in Norman, Oklahoma. During the summer and fall of 2009, surveys were distributed to 320 participants to assess their understanding and perception of weather risks and preferred tornado warning lead time. Responses were analyzed according to several different parameters including age, region of residency, educational level, number of children, and prior tornado experience. A majority of the respondents answered many of the weather risk questions correctly. They seemed to be familiar with tornado seasons; however, they were unaware of the relative number of fatalities caused by tornadoes and several additional weather phenomena each year in the United States. The preferred lead time was 34.3 min according to average survey responses. This suggests that while the general public may currently prefer a longer average lead time than the present system offers, the preference does not extend to the 1–2-h time frame theoretically offered by the warn-on-forecast system. When asked what they would do if given a 1-h lead time, respondents reported that taking shelter was a lesser priority than when given a 15-min lead time, and fleeing the area became a slightly more popular alternative. A majority of respondents also reported the situation would feel less life threatening if given a 1-h lead time. These results suggest that how the public responds to longer lead times may be complex and situationally dependent, and further study must be conducted to ascertain the users for whom the longer lead times would carry the most value. These results form the basis of an informative stated-preference approach to predicting public response to long (\&gt;1 h) warning lead times, using public understanding of the risks posed by severe weather events to contextualize lead-time demand.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {2},
	urldate = {2021-05-05},
	journal = {Weather, Climate, and Society},
	author = {Hoekstra, S. and Klockow, K. and Riley, R. and Brotzge, J. and Brooks, H. and Erickson, S.},
	month = apr,
	year = {2011},
	note = {Number: 2
Publisher: American Meteorological Society
Section: Weather, Climate, and Society},
	pages = {128--140},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\QEFYWI26\\Hoekstra et al. - 2011 - A Preliminary Look at the Social Perspective of Wa.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\W9HWWB9D\\2011wcas1076_1.html:text/html},
}

@article{miller_not-so-marginal_2018-1,
	title = {The {Not}-{So}-{Marginal} {Value} of {Weather} {Warning} {Systems}},
	volume = {10},
	issn = {1948-8327, 1948-8335},
	url = {https://journals.ametsoc.org/view/journals/wcas/10/1/wcas-d-16-0093_1.xml},
	doi = {10.1175/WCAS-D-16-0093.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d5254609e79"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Knowing the benefits of creating or expanding programs is important for determining optimal levels of investment. Yet estimates of the benefits of weather warning systems are sparse, perhaps because there is often no clear counterfactual of how individuals would have fared without a particular warning system. This paper enriches the literature and informs policy decisions by using conditional variation in the initial broadcast dates of the National Oceanic and Atmospheric Administration’s Weather Radio All Hazards (NWR) transmitters to produce both cross-sectional and fixed effects estimates of the causal impact of expanding the NWR transmitter network. Results suggest that from 1970 to 2014, expanding NWR coverage to a previously untreated county was associated with an almost 40\% reduction in injuries and as much as a 50\% reduction in fatalities. The benefits associated with further expansion of this system have likely declined over time.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {1},
	urldate = {2021-09-19},
	journal = {Weather, Climate, and Society},
	author = {Miller, Benjamin M.},
	month = jan,
	year = {2018},
	note = {Number: 1
Publisher: American Meteorological Society
Section: Weather, Climate, and Society},
	pages = {89--101},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\SXRMWXED\\Miller - 2018 - The Not-So-Marginal Value of Weather Warning Syste.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\8VIPXZPI\\wcas-d-16-0093_1.html:text/html},
}

@article{miller_eliciting_2005,
	title = {Eliciting {Informative} {Feedback}: {The} {Peer}-{Prediction} {Method}},
	volume = {51},
	issn = {0025-1909},
	shorttitle = {Eliciting {Informative} {Feedback}},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0379},
	doi = {10.1287/mnsc.1050.0379},
	abstract = {Many recommendation and decision processes depend on eliciting evaluations of opportunities, products, and vendors. A scoring system is devised that induces honest reporting of feedback. Each rater merely reports a signal, and the system applies proper scoring rules to the implied posterior beliefs about another rater’s report. Honest reporting proves to be a Nash equilibrium. The scoring schemes can be scaled to induce appropriate effort by raters and can be extended to handle sequential interaction and continuous signals. We also address a number of practical implementation issues that arise in settings such as academic reviewing and online recommender and reputation systems.},
	number = {9},
	urldate = {2021-03-08},
	journal = {Management Science},
	author = {Miller, Nolan and Resnick, Paul and Zeckhauser, Richard},
	month = sep,
	year = {2005},
	note = {Number: 9
Publisher: INFORMS},
	pages = {1359--1373},
}

@article{johnson_efficiency_1990,
	title = {Efficiency {Despite} {Mutually} {Payoff}-{Relevant} {Private} {Information}: {The} {Finite} {Case}},
	volume = {58},
	issn = {0012-9682},
	shorttitle = {Efficiency {Despite} {Mutually} {Payoff}-{Relevant} {Private} {Information}},
	url = {https://www.jstor.org/stable/2938354},
	doi = {10.2307/2938354},
	abstract = {Individuals have or observe partly private information. They independently choose acts, possibly including messages. The center may also act. Individuals' utilities may depend on all acts and information, including others' private information. Are there incentives depending only on public information that make desired behavior a Bayesian equilibrium? Assume incentive payments are separable and fully transferable. Appropriate incentives exist either if the center's information--perhaps solely messages--depends stochastically, however slightly, on all relevant private information, or if individuals' relative valuations of acts, however divergent, are not too dissimilarly affected by different states of nature. More generally, we give necessary and sufficient conditions for existence whenever the strategy profile asks agents to reveal all private knowledge relevant to their beliefs about the center's information. We also develop equivalences on the possible values of private information--concepts of similarity of agent types--that are key to resolving existence questions without such responsiveness or requiring budget balance.},
	number = {4},
	urldate = {2021-03-08},
	journal = {Econometrica},
	author = {Johnson, Scott and Pratt, John W. and Zeckhauser, Richard J.},
	year = {1990},
	note = {Number: 4
Publisher: [Wiley, Econometric Society]},
	pages = {873--900},
}

@article{frey_towards_2017,
	title = {Towards an {Economics} of {Awards}},
	volume = {31},
	copyright = {© 2015 John Wiley \& Sons Ltd},
	issn = {1467-6419},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/joes.12127},
	doi = {https://doi.org/10.1111/joes.12127},
	abstract = {Awards are a widespread phenomenon. They cater to the fundamental desire for social recognition and serve as a valuable incentive to influence behaviour. The study of awards such as medals, prizes and titles has in recent years gained momentum in economics, complementing the longstanding focus on material incentives. To evaluate the effectiveness of awards as a motivator is difficult as the effect of awards must be separated from the fact that awards are meant to be given to the best. We show how research on awards has advanced over the last couple of years, thus providing points of departure for future work.},
	language = {en},
	number = {1},
	urldate = {2021-03-08},
	journal = {Journal of Economic Surveys},
	author = {Frey, Bruno S. and Gallus, Jana},
	year = {2017},
	note = {Number: 1
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/joes.12127},
	keywords = {Awards, Esteem, Incentives, Monetary rewards, Motivation, Performance},
	pages = {190--200},
}

@article{winkler_quantification_1967,
	title = {The {Quantification} of {Judgment}: {Some} {Methodological} {Suggestions}},
	volume = {62},
	issn = {0162-1459},
	shorttitle = {The {Quantification} of {Judgment}},
	url = {https://www.jstor.org/stable/2283764},
	doi = {10.2307/2283764},
	abstract = {The personalistic theory of probability prescribes that a person should use personal probability assessments in decision-making and that these assessments should correspond with his judgments. Since the judgments exist solely in the assessor's mind, there is no way to prove whether or not this requirement is satisfied. De Finetti has proposed the development of methods which should oblige the assessor to make his assessments correspond with his judgments. An ideal Assessor is hypothesized and his behavior is investigated under a number of such methods (including those suggested by de Finetti and others). The implications of these methods for the theory of personal probability are discussed. Finally, although the present interest is primarily normative, the practicability of the methods is also discussed.},
	number = {320},
	urldate = {2021-03-08},
	journal = {Journal of the American Statistical Association},
	author = {Winkler, Robert L.},
	year = {1967},
	note = {Number: 320
Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {1105--1120},
}

@inproceedings{agarwal_peer_2017,
	address = {New York, NY, USA},
	series = {{EC} '17},
	title = {Peer {Prediction} with {Heterogeneous} {Users}},
	isbn = {978-1-4503-4527-9},
	url = {https://doi.org/10.1145/3033274.3085127},
	doi = {10.1145/3033274.3085127},
	abstract = {Peer prediction mechanisms incentivize agents to truthfully report their signals, in the absence of a verification mechanism, by comparing their reports with those of their peers. Prior work in this area is essentially restricted to the case of homogeneous agents, whose signal distributions are identical. This is limiting in many domains, where we would expect agents to differ in taste, judgment and reliability. Although the Correlated Agreement (CA) mechanism [30] can be extended to handle heterogeneous agents, the new challenge is with the efficient estimation of agent signal types. We solve this problem by clustering agents based on their reporting behavior, proposing a mechanism that works with clusters of agents and designing algorithms that learn such a clustering. In this way, we also connect peer prediction with the Dawid and Skene [5] literature on latent types. We retain the robustness against coordinated misreports of the CA mechanism, achieving an approximate incentive guarantee of ε-informed truthfulness. We show on real data that this incentive approximation is reasonable in practice, and even with a small number of clusters.},
	urldate = {2021-03-26},
	booktitle = {Proceedings of the 2017 {ACM} {Conference} on {Economics} and {Computation}},
	publisher = {Association for Computing Machinery},
	author = {Agarwal, Arpit and Mandal, Debmalya and Parkes, David C. and Shah, Nisarg},
	month = jun,
	year = {2017},
	keywords = {clustering, information elicitation, peer prediction, tensor decomposition},
	pages = {81--98},
}

@article{radanovic_incentives_2014,
	title = {Incentives for {Truthful} {Information} {Elicitation} of {Continuous} {Signals}},
	volume = {28},
	copyright = {Copyright (c)},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/8797},
	language = {en},
	number = {1},
	urldate = {2021-03-27},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Radanovic, Goran and Faltings, Boi},
	month = jun,
	year = {2014},
	note = {Number: 1},
	keywords = {Peer Prediction},
}

@misc{team_analysis_2015,
	type = {Text},
	title = {Analysis of {Emerging} {Reputation} and {Funding} {Mechanisms} in the {Context} of {Open} {Science} 2.0},
	url = {https://ec.europa.eu/jrc/en/publication/analysis-emerging-reputation-and-funding-mechanisms-context-open-science-20},
	abstract = {Analysis of Emerging Reputation and Funding Mechanisms in the Context of Open Science 2.0},
	language = {en},
	urldate = {2021-03-27},
	journal = {EU Science Hub - European Commission},
	author = {team, FPFIS},
	month = may,
	year = {2015},
}

@inproceedings{gao_trick_2014,
	address = {New York, NY, USA},
	series = {{EC} '14},
	title = {Trick or treat: putting peer prediction to the test},
	isbn = {978-1-4503-2565-3},
	shorttitle = {Trick or treat},
	url = {https://doi.org/10.1145/2600057.2602865},
	doi = {10.1145/2600057.2602865},
	abstract = {Collecting truthful subjective information from multiple individuals is an important problem in many social and online systems. While peer prediction mechanisms promise to elicit truthful information by rewarding participants with carefully constructed payments, they also admit uninformative equilibria where coordinating participants provide no useful information. To understand how participants behave towards such mechanisms in practice, we conduct the first controlled online experiment of a peer prediction mechanism, engaging the participants in a multiplayer, real-time and repeated game. Using a hidden Markov model to capture players' strategies from their actions, our results show that participants successfully coordinate on uninformative equilibria and the truthful equilibrium is not focal, even when some uninformative equilibria do not exist or are undesirable. In contrast, most players are consistently truthful in the absence of peer prediction, suggesting that these mechanisms may be harmful when truthful reporting has similar cost to strategic behavior.},
	urldate = {2021-03-26},
	booktitle = {Proceedings of the fifteenth {ACM} conference on {Economics} and computation},
	publisher = {Association for Computing Machinery},
	author = {Gao, Xi Alice and Mao, Andrew and Chen, Yiling and Adams, Ryan Prescott},
	month = jun,
	year = {2014},
	keywords = {peer prediction, hidden markov models, online behavioral experiment},
	pages = {507--524},
}

@article{alfaro_incentives_2016,
	title = {Incentives for {Truthful} {Evaluations}.},
	volume = {abs/1608.07886},
	url = {http://arxiv.org/abs/1608.07886},
	journal = {CoRR},
	author = {Alfaro, Luca de},
	year = {2016},
}

@article{de_alfaro_incentives_2016,
	title = {Incentives for {Truthful} {Peer} {Grading}},
	url = {http://arxiv.org/abs/1604.03178},
	abstract = {Peer grading systems work well only if users have incentives to grade truthfully. An example of non-truthful grading, that we observed in classrooms, consists in students assigning the maximum grade to all submissions. With a naive grading scheme, such as averaging the assigned grades, all students would receive the maximum grade. In this paper, we develop three grading schemes that provide incentives for truthful peer grading. In the first scheme, the instructor grades a fraction p of the submissions, and penalizes students whose grade deviates from the instructor grade. We provide lower bounds on p to ensure truthfulness, and conclude that these schemes work only for moderate class sizes, up to a few hundred students. To overcome this limitation, we propose a hierarchical extension of this supervised scheme, and we show that it can handle classes of any size with bounded (and little) instructor work, and is therefore applicable to Massive Open Online Courses (MOOCs). Finally, we propose unsupervised incentive schemes, in which the student incentive is based on statistical properties of the grade distribution, without any grading required by the instructor. We show that the proposed unsupervised schemes provide incentives to truthful grading, at the price of being possibly unfair to individual students.},
	urldate = {2021-03-27},
	journal = {arXiv:1604.03178 [cs]},
	author = {de Alfaro, Luca and Shavlovsky, Michael and Polychronopoulos, Vassilis},
	month = apr,
	year = {2016},
	note = {arXiv: 1604.03178},
	keywords = {Computer Science - Computer Science and Game Theory},
	annote = {Comment: 26 pages},
}

@article{radanovic_incentives_2016,
	title = {Incentives for {Effort} in {Crowdsourcing} {Using} the {Peer} {Truth} {Serum}},
	volume = {7},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/2856102},
	doi = {10.1145/2856102},
	abstract = {Crowdsourcing is widely proposed as a method to solve a large variety of judgment tasks, such as classifying website content, peer grading in online courses, or collecting real-world data. As the data reported by workers cannot be verified, there is a tendency to report random data without actually solving the task. This can be countered by making the reward for an answer depend on its consistency with answers given by other workers, an approach called peer consistency. However, it is obvious that the best strategy in such schemes is for all workers to report the same answer without solving the task. Dasgupta and Ghosh [2013] show that, in some cases, exerting high effort can be encouraged in the highest-paying equilibrium. In this article, we present a general mechanism that implements this idea and is applicable to most crowdsourcing settings. Furthermore, we experimentally test the novel mechanism, and validate its theoretical properties.},
	number = {4},
	urldate = {2021-03-27},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	author = {Radanovic, Goran and Faltings, Boi and Jurca, Radu},
	month = mar,
	year = {2016},
	note = {Number: 4},
	keywords = {peer prediction, Crowdsourcing, mechanism design},
	pages = {48:1--48:28},
}

@inproceedings{witkowski_peer_2012,
	address = {New York, NY, USA},
	series = {{EC} '12},
	title = {Peer prediction without a common prior},
	isbn = {978-1-4503-1415-2},
	url = {https://doi.org/10.1145/2229012.2229085},
	doi = {10.1145/2229012.2229085},
	abstract = {Reputation mechanisms at online opinion forums, such as Amazon Reviews, elicit ratings from users about their experience with different products. Crowdsourcing applications, such as image tagging on Amazon Mechanical Turk, elicit votes from users as to whether or not a job was duly completed. An important property in both settings is that the feedback received from users (agents) is truthful. The peer prediction method introduced by Miller et al. [2005] is a prominent theoretical mechanism for the truthful elicitation of reports. However, a significant obstacle to its application is that it critically depends on the assumption of a common prior amongst both the agents and the mechanism. In this paper, we develop a peer prediction mechanism for settings where the agents hold subjective and private beliefs about the state of the world and the likelihood of a positive signal given a particular state. Our shadow peer prediction mechanism exploits temporal structure in order to elicit two reports, a belief report and then a signal report, and it provides strict incentives for truthful reporting as long as the effect an agent's signal has on her posterior belief is bounded away from zero. Alternatively, this technical requirement on beliefs can be dispensed with by a modification in which the second report is a belief report rather than a signal report.},
	urldate = {2021-03-26},
	booktitle = {Proceedings of the 13th {ACM} {Conference} on {Electronic} {Commerce}},
	publisher = {Association for Computing Machinery},
	author = {Witkowski, Jens and Parkes, David C.},
	month = jun,
	year = {2012},
	keywords = {information elicitation, peer prediction, mechanism design},
	pages = {964--981},
}

@article{schotter_belief_2014,
	title = {Belief {Elicitation} in the {Laboratory}},
	volume = {6},
	url = {https://doi.org/10.1146/annurev-economics-080213-040927},
	doi = {10.1146/annurev-economics-080213-040927},
	abstract = {One constraint we face as economists is not being able to observe all the relevant variables required to test our theories or make policy prescriptions. Laboratory techniques allow us to convert many variables (such as beliefs) that are unobservable in the field into observables. This article presents a survey of the literature on belief elicitation in laboratory experimental economics. We discuss several techniques available to elicit beliefs in an incentive-compatible manner and the problems involved in their use. We then look at how successful these techniques have been when employed in laboratory studies. We find that despite some problems, beliefs elicited in the laboratory are meaningful (i.e., they are generally used as the basis for behavior), and the process of eliciting beliefs seems not to be too intrusive. One hope for the future is that by eliciting beliefs, we may be able to develop better theories of belief formation.},
	number = {1},
	urldate = {2021-03-27},
	journal = {Annual Review of Economics},
	author = {Schotter, Andrew and Trevino, Isabel},
	year = {2014},
	note = {Number: 1
\_eprint: https://doi.org/10.1146/annurev-economics-080213-040927},
	pages = {103--128},
}

@inproceedings{witkowski_proper_2017,
	address = {San Francisco, California, USA},
	series = {{AAAI}'17},
	title = {Proper proxy scoring rules},
	abstract = {Proper scoring rules can be used to incentivize a forecaster to truthfully report her private beliefs about the probabilities of future events and to evaluate the relative accuracy of forecasters. While standard scoring rules can score forecasts only once the associated events have been resolved, many applications would benefit from instant access to proper scores. In forecast aggregation, for example, it is known that using weighted averages, where more weight is put on more accurate forecasters, outperforms simple averaging of forecasts. We introduce proxy scoring rules, which generalize proper scoring rules and, given access to an appropriate proxy, allow for immediate scoring of probabilistic forecasts. In particular, we suggest a proxy-scoring generalization of the popular quadratic scoring rule, and characterize its incentive and accuracy evaluation properties theoretically. Moreover, we thoroughly evaluate it experimentally using data from a large real world geopolitical forecasting tournament, and show that it is competitive with proper scoring rules when the number of questions is small.},
	urldate = {2021-03-26},
	booktitle = {Proceedings of the {Thirty}-{First} {AAAI} {Conference} on {Artificial} {Intelligence}},
	publisher = {AAAI Press},
	author = {Witkowski, Jens and Atanasov, Pavel and Ungar, Lyle H. and Krause, Andreas},
	month = feb,
	year = {2017},
	pages = {743--749},
}

@article{vaughan_making_2018,
	title = {Making {Better} {Use} of the {Crowd}: {How} {Crowdsourcing} {Can} {Advance} {Machine} {Learning} {Research}},
	volume = {18},
	issn = {1533-7928},
	shorttitle = {Making {Better} {Use} of the {Crowd}},
	url = {http://jmlr.org/papers/v18/17-234.html},
	number = {193},
	urldate = {2021-03-27},
	journal = {Journal of Machine Learning Research},
	author = {Vaughan, Jennifer Wortman},
	year = {2018},
	note = {Number: 193},
	pages = {1--46},
}

@article{kong_information_2019,
	title = {An {Information} {Theoretic} {Framework} {For} {Designing} {Information} {Elicitation} {Mechanisms} {That} {Reward} {Truth}-telling},
	volume = {7},
	issn = {2167-8375},
	url = {https://doi.org/10.1145/3296670},
	doi = {10.1145/3296670},
	abstract = {In the setting where information cannot be verified, we propose a simple yet powerful information theoretical framework—the Mutual Information Paradigm—for information elicitation mechanisms. Our framework pays every agent a measure of mutual information between her signal and a peer’s signal. We require that the mutual information measurement has the key property that any “data processing” on the two random variables will decrease the mutual information between them. We identify such information measures that generalize Shannon mutual information. Our Mutual Information Paradigm overcomes the two main challenges in information elicitation without verification: (1) how to incentivize high-quality reports and avoid agents colluding to report random or identical responses; (2) how to motivate agents who believe they are in the minority to report truthfully. Aided by the information measures, we found (1) we use the paradigm to design a family of novel mechanisms where truth-telling is a dominant strategy and pays better than any other strategy profile (in the multi-question, detail free, minimal setting where the number of questions is large); (2) we show the versatility of our framework by providing a unified theoretical understanding of existing mechanisms—Bayesian Truth Serum Prelec (2004) and Dasgupta and Ghosh (2013)—by mapping them into our framework such that theoretical results of those existing mechanisms can be reconstructed easily. We also give an impossibility result that illustrates, in a certain sense, the the optimality of our framework.},
	number = {1},
	urldate = {2021-03-27},
	journal = {ACM Transactions on Economics and Computation},
	author = {Kong, Yuqing and Schoenebeck, Grant},
	month = jan,
	year = {2019},
	note = {Number: 1},
	keywords = {mechanism design, crowdsourcing, information theory, Peer prediction},
	pages = {2:1--2:33},
}

@inproceedings{jurca_collusion-resistant_2007,
	address = {New York, NY, USA},
	series = {{EC} '07},
	title = {Collusion-resistant, incentive-compatible feedback payments},
	isbn = {978-1-59593-653-0},
	url = {https://doi.org/10.1145/1250910.1250940},
	doi = {10.1145/1250910.1250940},
	abstract = {Online reputation mechanisms need honest feedback to function effectively. Self-interested agents report the truth only when explicit rewards offset the potential gains obtained from lying. Feedback payment schemes (monetary rewardsfor submitted feedback) can make truth-telling rational based on the correlation between the reports of different buyers. In this paper we investigate incentive-compatible payment mechanisms that are also resistant to collusion: groups of agents cannot collude on a lying strategy without suffering monetary losses. We analyze several scenarios, where, for example, some or all of the agents collude. For each scenario we investigate both existential and implementation problems. Throughout the paper we use automated mechanism design to compute the best possible mechanism for a given setting.},
	urldate = {2021-03-26},
	booktitle = {Proceedings of the 8th {ACM} conference on {Electronic} commerce},
	publisher = {Association for Computing Machinery},
	author = {Jurca, Radu and Faltings, Boi},
	month = jun,
	year = {2007},
	keywords = {mechanism design, collusion resistance, incentive compatibility, reputation mechanisms},
	pages = {200--209},
}

@article{laffont_mechanism_2000,
	title = {Mechanism {Design} with {Collusion} and {Correlation}},
	volume = {68},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/2999429},
	abstract = {In a public good environment with positively correlated types, we characterize optimal mechanisms when agents have private information and can enter collusive agreements. First, we prove a weak-collusion-proof principle according to which there is no restriction for the principal in offering weak-collusion-proof mechanisms. Second, with this principle, we characterize the set of allocations that satisfy individual and coalitional incentive constraints. The optimal weakly collusion-proof mechanism calls for distortions away from first-best efficiency obtained without collusion. Allowing collusion restores continuity between the correlated and the uncorrelated environments. When the correlation becomes almost perfect, first-best efficiency is approached. Finally, the optimal collusion-proof mechanism is strongly ratifiable.},
	number = {2},
	urldate = {2021-03-27},
	journal = {Econometrica},
	author = {Laffont, Jean-Jacques and Martimort, David},
	year = {2000},
	note = {Number: 2
Publisher: [Wiley, Econometric Society]},
	pages = {309--342},
}

@article{brier_verification_1950,
	title = {{VERIFICATION} {OF} {FORECASTS} {EXPRESSED} {IN} {TERMS} {OF} {PROBABILITY}},
	volume = {78},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/78/1/1520-0493_1950_078_0001_vofeit_2_0_co_2.xml},
	doi = {10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d524e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}No Abstract Available.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {1},
	urldate = {2021-03-27},
	journal = {Monthly Weather Review},
	author = {Brier, Glenn W.},
	month = jan,
	year = {1950},
	note = {Number: 1
Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {1--3},
}

@techreport{jia_herding_2020,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Herding in {Probabilistic} {Forecasts}},
	url = {https://papers.ssrn.com/abstract=3674961},
	abstract = {Decision and policy makers often ask experts to forecast a future state. Experts, however, can be biased. In the economics and psychology literature, one extensively studied behavioral bias is called herding. Under strong levels of herding, it is generally known that disclosure of public information may lower forecasting accuracy. This result, however, has been derived only for point forecasts. In this paper, we consider probabilistic forecasts under herding and show that the negative externality of public information no longer holds. Furthermore, we show that the experts report too similar locations and inflate the variance of their forecasts due to herding. In addition to reacting to new information as expected, probabilistic forecasts contain more information about the experts’ full beliefs and interpersonal structure. This facilitates model estimation. To this end, we consider a one-shot setting with one forecast per expert and show that our model is identifiable up to an infinite number of solutions based on point forecasts, but up to two solutions based on probabilistic forecasts. We then provide a Bayesian estimation procedure for these two solutions and apply it to economic forecasting data collected by the European Central Bank. We find that, on average, the experts invest around 15\% of their efforts into making similar forecasts. The level of herding shows an increasing trend from 1999 to 2007 but drops sharply during the financial crisis of 2007-2008, and then rises again until 2019.},
	language = {en},
	number = {ID 3674961},
	urldate = {2021-03-30},
	institution = {Social Science Research Network},
	author = {Jia, Yanwei and Keppo, Jussi and Satopää, Ville},
	month = aug,
	year = {2020},
	doi = {10.2139/ssrn.3674961},
	note = {Issue: ID 3674961},
	keywords = {Asymmetric Information Game, Bayesian Statistics, Economic Forecasting, Public Disclosure},
}

@article{schotter_belief_2014-1,
	title = {Belief {Elicitation} in the {Laboratory}},
	volume = {6},
	url = {https://ideas.repec.org/a/anr/reveco/v6y2014p103-128.html},
	abstract = {One constraint we face as economists is not being able to observe all the relevant variables required to test our theories or make policy prescriptions. Laboratory techniques allow us to convert many variables (such as beliefs) that are unobservable in the field into observables. This article presents a survey of the literature on belief elicitation in laboratory experimental economics. We discuss several techniques available to elicit beliefs in an incentive-compatible manner and the problems involved in their use. We then look at how successful these techniques have been when employed in laboratory studies. We find that despite some problems, beliefs elicited in the laboratory are meaningful (i.e., they are generally used as the basis for behavior), and the process of eliciting beliefs seems not to be too intrusive. One hope for the future is that by eliciting beliefs, we may be able to develop better theories of belief formation.},
	language = {en},
	number = {1},
	urldate = {2021-03-30},
	journal = {Annual Review of Economics},
	author = {Schotter, Andrew and Trevino, Isabel},
	year = {2014},
	note = {Number: 1
Publisher: Annual Reviews},
	keywords = {decision theory, experiments},
	pages = {103--128},
}

@article{azoulay_toward_2018,
	title = {Toward a more scientific science},
	volume = {361},
	copyright = {Copyright © 2018 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. http://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/361/6408/1194},
	doi = {10.1126/science.aav2484},
	abstract = {Climb atop shoulders and wait for funerals. That, suggested Newton and then Planck, is how science advances (more or less). We've come far since then, but many notions about how people and practices, policies, and resources influence the course of science are still more rooted in traditions and intuitions than in evidence. We can and must do better, lest we resign ourselves to “intuition-based policy” when making decisions and investments aimed at driving scientific progress. Science invited experts to highlight key aspects of the scientific enterprise that are steadily yielding to empirical investigation—and to explain how Newton and Planck got it right (and Einstein got it wrong). —Brad Wible},
	language = {en},
	number = {6408},
	urldate = {2021-03-30},
	journal = {Science},
	author = {Azoulay, Pierre and Graff-Zivin, Joshua and Uzzi, Brian and Wang, Dashun and Williams, Heidi and Evans, James A. and Jin, Ginger Zhe and Lu, Susan Feng and Jones, Benjamin F. and Börner, Katy and Lakhani, Karim R. and Boudreau, Kevin J. and Guinan, Eva C.},
	month = sep,
	year = {2018},
	pmid = {30237341},
	note = {Number: 6408
Publisher: American Association for the Advancement of Science
Section: Policy Forum},
	pages = {1194--1197},
}

@article{dasgupta_simple_1987,
	title = {The {Simple} {Economics} of {Research} {Portfolios}},
	volume = {97},
	issn = {0013-0133},
	url = {https://www.jstor.org/stable/2232925},
	doi = {10.2307/2232925},
	number = {387},
	urldate = {2021-03-30},
	journal = {The Economic Journal},
	author = {Dasgupta, Partha and Maskin, Eric},
	year = {1987},
	note = {Number: 387
Publisher: [Royal Economic Society, Wiley]},
	pages = {581--595},
}

@article{armantier_eliciting_2013,
	title = {Eliciting beliefs: {Proper} scoring rules, incentives, stakes and hedging},
	volume = {62},
	issn = {0014-2921},
	shorttitle = {Eliciting beliefs},
	url = {https://www.sciencedirect.com/science/article/pii/S001429211300041X},
	doi = {10.1016/j.euroecorev.2013.03.008},
	abstract = {Proper Scoring Rules (PSRs) are popular incentivized mechanisms to elicit an agent's beliefs. This paper combines theory and experiment to characterize how PSRs bias reported beliefs when (i) the PSR payments are increased, (ii) the agent has a financial stake in the event she is predicting, and (iii) the agent can hedge her prediction by taking an additional action. In contrast with previous literature, the PSR biases are characterized for all PSRs and all risk averse agents. Our results reveal complex distortions of reported beliefs, thereby raising concerns about the ability of PSRs to recover truthful beliefs in general decision-making environments.},
	language = {en},
	urldate = {2021-03-30},
	journal = {European Economic Review},
	author = {Armantier, Olivier and Treich, Nicolas},
	month = aug,
	year = {2013},
	keywords = {Belief elicitation, Experimental economics, Scoring rules},
	pages = {17--40},
}

@article{gneiting_strictly_2007,
	title = {Strictly {Proper} {Scoring} {Rules}, {Prediction}, and {Estimation}},
	volume = {102},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/016214506000001437},
	doi = {10.1198/016214506000001437},
	abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distributionF if he or she issues the probabilistic forecast F, rather than G ≠ F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster to make careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed. We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
	number = {477},
	urldate = {2021-03-30},
	journal = {Journal of the American Statistical Association},
	author = {Gneiting, Tilmann and Raftery, Adrian E.},
	month = mar,
	year = {2007},
	note = {Number: 477
Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/016214506000001437},
	keywords = {Bayes factor, Bregman divergence, Brier score, Coherent, Continuous ranked probability score, Cross-validation, Entropy, Kernel score, Loss function, Minimum contrast estimation, Negative definite function, Prediction interval, Predictive distribution, Quantile forecast, Scoring rule, Skill score, Strictly proper, Utility function},
	pages = {359--378},
}

@article{huck_players_2002,
	title = {Do players correctly estimate what others do?: {Evidence} of conservatism in beliefs},
	volume = {47},
	issn = {0167-2681},
	shorttitle = {Do players correctly estimate what others do?},
	url = {https://www.sciencedirect.com/science/article/pii/S0167268101001706},
	doi = {10.1016/S0167-2681(01)00170-6},
	abstract = {In a simple experimental environment a group of subjects was asked to give estimates of a second group’s choice frequencies in a set of lottery-choice tasks. The results show that subjects in the first group are on average able to correctly predict the option that is chosen with higher frequency by the second group, but the predictions are systematically inaccurate in that they are distorted toward the uniform prior. Two mechanisms to elicit the expectations were used in the experiment, a quadratic scoring rule and a bidding mechanism. Aggregate results being similar under both mechanisms, the use of the former mechanism consistently yields more accurate predictions.},
	language = {en},
	number = {1},
	urldate = {2021-03-30},
	journal = {Journal of Economic Behavior \& Organization},
	author = {Huck, Steffen and Weizsäcker, Georg},
	month = jan,
	year = {2002},
	note = {Number: 1},
	keywords = {Beliefs, Elicitation, Experiments, Prediction accuracy},
	pages = {71--85},
}

@article{hyndman_convergence_2012,
	title = {Convergence: {An} {Experimental} {Study} of {Teaching} and {Learning} in {Repeated} {Games}},
	volume = {10},
	issn = {1542-4766},
	shorttitle = {Convergence},
	url = {https://doi.org/10.1111/j.1542-4774.2011.01063.x},
	doi = {10.1111/j.1542-4774.2011.01063.x},
	abstract = {Nash equilibrium can be interpreted as a steady state where players hold correct beliefs about the other players’ behavior and act rationally. We experimentally examine the process that leads to this steady state. Our results indicate that some players emerge as teachers—those subjects who, by their actions, try to influence the beliefs of their opponent and lead the way to a more favorable outcome—and that the presence of teachers appears to facilitate convergence to Nash equilibrium. In addition to our experiments, we examine games, with different properties, from other experiments and show that teaching plays an important role in these games. We also report results from treatments in which teaching is made more difficult. In these treatments, convergence rates go down and any convergence that does occur is delayed.},
	number = {3},
	urldate = {2021-03-30},
	journal = {Journal of the European Economic Association},
	author = {Hyndman, Kyle and Ozbay, Erkut Y. and Schotter, Andrew and Ehrblatt, Wolf Ze’ev},
	month = jun,
	year = {2012},
	note = {Number: 3},
	pages = {573--604},
}

@article{karni_mechanism_2009,
	title = {A {Mechanism} for {Eliciting} {Probabilities}},
	volume = {77},
	copyright = {© 2009 The Econometric Society},
	issn = {1468-0262},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA7833},
	doi = {https://doi.org/10.3982/ECTA7833},
	abstract = {This paper describes a direct revelation mechanism for eliciting agents' subjective probabilities. The game induced by the mechanism has a dominant strategy equilibrium in which the players reveal their subjective probabilities.},
	language = {en},
	number = {2},
	urldate = {2021-03-30},
	journal = {Econometrica},
	author = {Karni, Edi},
	year = {2009},
	note = {Number: 2
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.3982/ECTA7833},
	keywords = {direct revelation mechanism, Probability elicitation},
	pages = {603--606},
}

@article{harrison_eliciting_2014,
	title = {Eliciting subjective probabilities with binary lotteries},
	volume = {101},
	issn = {0167-2681},
	url = {https://www.sciencedirect.com/science/article/pii/S016726811400050X},
	doi = {10.1016/j.jebo.2014.02.011},
	abstract = {We evaluate a binary lottery procedure for inducing risk neutral behavior in a subjective belief elicitation task. Prior research has shown this procedure to robustly induce risk neutrality when subjects are given a single risk task defined over objective probabilities. Drawing a sample from the same subject population, we find evidence that the binary lottery procedure also induces linear utility in a subjective probability elicitation task using the Quadratic Scoring Rule. We also show that the binary lottery procedure can induce direct revelation of subjective probabilities in subjects with popular non-expected utility preference representations that satisfy weak conditions.},
	language = {en},
	urldate = {2021-03-30},
	journal = {Journal of Economic Behavior \& Organization},
	author = {Harrison, Glenn W. and Martínez-Correa, Jimmy and Swarthout, J. Todd},
	month = may,
	year = {2014},
	keywords = {Experimental economics, Binary lottery procedure, Risk neutrality, Subjective probability elicitation},
	pages = {128--140},
}

@article{offerman_truth_2009,
	title = {A {Truth} {Serum} for {Non}-{Bayesians}: {Correcting} {Proper} {Scoring} {Rules} for {Risk} {Attitudes}*},
	volume = {76},
	issn = {0034-6527},
	shorttitle = {A {Truth} {Serum} for {Non}-{Bayesians}},
	url = {https://doi.org/10.1111/j.1467-937X.2009.00557.x},
	doi = {10.1111/j.1467-937X.2009.00557.x},
	abstract = {Proper scoring rules provide convenient and highly efficient tools for incentive-compatible elicitations of subjective beliefs. As traditionally used, however, they are valid only under expected value maximization. This paper shows how they can be generalized to modern (“non-expected utility”) theories of risk and ambiguity, yielding mutual benefits: users of scoring rules can benefit from the empirical realism of non-expected utility, and analysts of ambiguity attitudes can benefit from efficient measurements using proper scoring rules. An experiment demonstrates the feasibility of our generalization.},
	number = {4},
	urldate = {2021-03-30},
	journal = {The Review of Economic Studies},
	author = {Offerman, Theo and Sonnemans, Joep and Van De Kuilen, Gijs and Wakker, Peter P.},
	month = oct,
	year = {2009},
	note = {Number: 4},
	pages = {1461--1489},
}

@article{offerman_whats_2004,
	title = {What’s {Causing} {Overreaction}? {An} {Experimental} {Investigation} of {Recency} and the {Hot}-hand {Effect}},
	volume = {106},
	issn = {1467-9442},
	shorttitle = {What’s {Causing} {Overreaction}?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0347-0520.2004.t01-1-00376.x},
	doi = {https://doi.org/10.1111/j.0347-0520.2004.t01-1-00376.x},
	abstract = {A substantial body of empirical literature provides evidence of overreaction in markets. Past losers outperform past winners in stock markets as well as in sports markets. Two hypotheses are consistent with this observation. The recency hypothesis states that traders overweight recent information; they are too optimistic about winners and too pessimistic about losers. According to the hot-hand hypothesis, traders try to discover trends in the past record of a firm or a team, and thereby overestimate the autocorrelation in the series. An experimental design allows us to distinguish between these hypotheses. The evidence is consistent with the hot-hand hypothesis.},
	language = {en},
	number = {3},
	urldate = {2021-03-30},
	journal = {The Scandinavian Journal of Economics},
	author = {Offerman, Theo and Sonnemans, Joep},
	year = {2004},
	note = {Number: 3
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.0347-0520.2004.t01-1-00376.x},
	keywords = {experiments, C91, D84, G12, hot hand, Overreaction, recency, scoring rule},
	pages = {533--554},
}

@article{selten_axiomatic_1998,
	title = {Axiomatic {Characterization} of the {Quadratic} {Scoring} {Rule}},
	volume = {1},
	issn = {1573-6938},
	url = {https://doi.org/10.1023/A:1009957816843},
	doi = {10.1023/A:1009957816843},
	abstract = {In the evaluation of experiments often the problem arises of how to compare the predictive success of competing probabilistic theories. The quadratic scoring rule can be used for this purpose. Originally, this rule was proposed as an incentive compatible elicitation method for probabilistic expert judgments. It is shown that up to a positive linear transformation, the quadratic scoring rule is characterized by four desirable properties.},
	language = {en},
	number = {1},
	urldate = {2021-03-30},
	journal = {Experimental Economics},
	author = {Selten, Reinhard},
	month = jun,
	year = {1998},
	note = {Number: 1},
	pages = {43--61},
}

@article{rutstrom_stated_2009,
	title = {Stated beliefs versus inferred beliefs: {A} methodological inquiry and experimental test},
	volume = {67},
	issn = {0899-8256},
	shorttitle = {Stated beliefs versus inferred beliefs},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825609000591},
	doi = {10.1016/j.geb.2009.04.001},
	abstract = {Belief elicitation in game experiments may be problematic if it changes game play. We experimentally verify that belief elicitation can alter paths of play in a two-player repeated asymmetric matching pennies game. Importantly, this effect occurs only during early periods and only for players with strongly asymmetric payoffs, consistent with a cognitive/affective effect on priors that may serve as a substitute for experience. These effects occur with a common scoring rule elicitation procedure, but not with simpler (unmotivated) statements of expected choices of opponents. Scoring rule belief elicitation improves the goodness of fit of structural models of belief learning, and prior beliefs implied by such models are both stronger and more realistic when beliefs are elicited than when they are not. We also find that “inferred beliefs” (beliefs estimated from past observed actions of opponents) can predict observed actions better than the “stated beliefs” from scoring rule belief elicitation.},
	language = {en},
	number = {2},
	urldate = {2021-03-30},
	journal = {Games and Economic Behavior},
	author = {Rutström, E. Elisabet and Wilcox, Nathaniel T.},
	month = nov,
	year = {2009},
	note = {Number: 2},
	keywords = {Experimental methods, Inferred beliefs, Repeated games, Stated beliefs},
	pages = {616--632},
}

@article{mann_power_2016,
	title = {The power of prediction markets},
	volume = {538},
	url = {http://www.nature.com/news/the-power-of-prediction-markets-1.20820},
	doi = {10.1038/538308a},
	abstract = {Scientists are beginning to understand why these ‘mini Wall Streets’ work so well at forecasting election results — and how they sometimes fail.},
	language = {en},
	number = {7625},
	urldate = {2021-03-30},
	journal = {Nature News},
	author = {Mann, Adam},
	month = oct,
	year = {2016},
	note = {Number: 7625
Section: News Feature},
	pages = {308},
}

@misc{good_judgment_project_ifpscsv_2016,
	title = {ifps.csv},
	url = {https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/BPCDH5/L8WZEF},
	doi = {10.7910/DVN/BPCDH5/L8WZEF},
	abstract = {Psychologists typically measure beliefs and preferences using self-reports, whereas economists are much more likely to infer them from behavior. Prediction markets appear to be a victory for the economic approach, having yielded more accurate probability estimates than opinion polls or experts for a wide variety of events, all without ever asking for self-reported beliefs. We conduct the most direct comparison to date of prediction markets to simple self-reports using a within-subject design. Our participants traded on the likelihood of geopolitical events. Each time they placed a trade, they ﬁrst had to report their belief that the event would occur on a 0–100 scale. When previously validated aggregation algorithms were applied to self-reported beliefs, they were at least as accurate as prediction-market prices in predicting a wide range of geopolitical events. Furthermore, the combination of approaches was signiﬁcantly more accurate than prediction-market prices alone, indicating that self-reports contained information that the market did not eﬃciently aggregate. Combining measurement techniques across behavioral and social sciences may have greater beneﬁts than previously thought.},
	language = {en},
	urldate = {2021-03-30},
	publisher = {Harvard Dataverse},
	author = {{Good Judgment Project}},
	year = {2016},
}

@article{atanasov_distilling_2015,
	title = {Distilling the {Wisdom} of {Crowds}: {Prediction} {Markets} versus {Prediction} {Polls}},
	volume = {2015},
	issn = {0065-0668},
	shorttitle = {Distilling the {Wisdom} of {Crowds}},
	url = {https://journals.aom.org/doi/abs/10.5465/ambpp.2015.15192abstract},
	doi = {10.5465/ambpp.2015.15192abstract},
	abstract = {Crowd prediction methods offer the promised to collect valuable, widely dispersed information in organizations. To the extent that information is a source of power, crowdsourcing democratizes organizational governance. We report the results of the first large-scale, long-term, experimental test of crowd prediction methods. More than 2,400 participants made forecasts on 261 world events over two forecasting seasons, each lasting more than 9 months. Forecasters in prediction markets made trades about future events in a continuous double auction. Those in prediction polls submitted explicit probability judgments, independently or in teams. Probability values were aggregated statistically. In Study 1, which used full random assignment, prediction markets were more accurate than the unweighted mean of forecasts from prediction polls. However, team prediction polls aggregated with algorithms featuring decay, weighting and recalibration outperformed prediction markets by 12\% in terms of Brier score. This pattern persisted in Study 2, and was stable across scoring rules. Prediction polls’ advantage was largest at the start of long-duration questions. Prediction polls with proper scoring, algorithmic aggregation and teaming offer an attractive method for distilling crowd wisdom.},
	number = {1},
	urldate = {2021-03-30},
	journal = {Academy of Management Proceedings},
	author = {Atanasov, Pavel and Rescober, Philip and Stone, Eric and Swift, Samuel A and Servan-Schreiber, Emile and Tetlock, Philip E. and Ungar, Lyle and Mellers, Barbara},
	month = jan,
	year = {2015},
	note = {Number: 1
Publisher: Academy of Management},
	pages = {15192},
}

@misc{noauthor_evaluating_2021,
	title = {Evaluating replicability of laboratory experiments in economics {\textbar} {Science}},
	url = {https://science.sciencemag.org/content/351/6280/1433},
	urldate = {2021-03-30},
	month = mar,
	year = {2021},
}

@article{camerer_evaluating_2016,
	title = {Evaluating replicability of laboratory experiments in economics},
	volume = {351},
	copyright = {Copyright © 2016, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/351/6280/1433},
	doi = {10.1126/science.aaf0918},
	abstract = {Another social science looks at itself
Experimental economists have joined the reproducibility discussion by replicating selected published experiments from two top-tier journals in economics. Camerer et al. found that two-thirds of the 18 studies examined yielded replicable estimates of effect size and direction. This proportion is somewhat lower than unaffiliated experts were willing to bet in an associated prediction market, but roughly in line with expectations from sample sizes and P values.
Science, this issue p. 1433
The replicability of some scientific findings has recently been called into question. To contribute data about replicability in economics, we replicated 18 studies published in the American Economic Review and the Quarterly Journal of Economics between 2011 and 2014. All of these replications followed predefined analysis plans that were made publicly available beforehand, and they all have a statistical power of at least 90\% to detect the original effect size at the 5\% significance level. We found a significant effect in the same direction as in the original study for 11 replications (61\%); on average, the replicated effect size is 66\% of the original. The replicability rate varies between 67\% and 78\% for four additional replicability indicators, including a prediction market measure of peer beliefs.
By several metrics, economics experiments do replicate, although not as often as predicted.
By several metrics, economics experiments do replicate, although not as often as predicted.},
	language = {en},
	number = {6280},
	urldate = {2021-03-30},
	journal = {Science},
	author = {Camerer, Colin F. and Dreber, Anna and Forsell, Eskil and Ho, Teck-Hua and Huber, Jürgen and Johannesson, Magnus and Kirchler, Michael and Almenberg, Johan and Altmejd, Adam and Chan, Taizan and Heikensten, Emma and Holzmeister, Felix and Imai, Taisuke and Isaksson, Siri and Nave, Gideon and Pfeiffer, Thomas and Razen, Michael and Wu, Hang},
	month = mar,
	year = {2016},
	pmid = {26940865},
	note = {Number: 6280
Publisher: American Association for the Advancement of Science
Section: Report},
	pages = {1433--1436},
}

@article{andersen_estimating_2014,
	title = {Estimating subjective probabilities},
	volume = {48},
	issn = {1573-0476},
	url = {https://doi.org/10.1007/s11166-014-9194-z},
	doi = {10.1007/s11166-014-9194-z},
	abstract = {Subjective probabilities play a central role in many economic decisions and act as an immediate confound of inferences about behavior, unless controlled for. Several procedures to recover subjective probabilities have been proposed, but in order to recover the correct latent probability one must either construct elicitation mechanisms that control for risk aversion, or construct elicitation mechanisms which undertake “calibrating adjustments” to elicited reports. We illustrate how the joint estimation of risk attitudes and subjective probabilities can provide the calibration adjustments that theory calls for. We illustrate this approach using data from a controlled experiment with real monetary consequences to the subjects. This allows the observer to make inferences about the latent subjective probability, under virtually any well-specified model of choice under subjective risk, while still employing relatively simple elicitation mechanisms.},
	language = {en},
	number = {3},
	urldate = {2021-03-30},
	journal = {Journal of Risk and Uncertainty},
	author = {Andersen, Steffen and Fountain, John and Harrison, Glenn W. and Rutström, E. Elisabet},
	month = jun,
	year = {2014},
	note = {Number: 3},
	pages = {207--229},
}

@article{bickel_comparisons_2007,
	title = {Some {Comparisons} among {Quadratic}, {Spherical}, and {Logarithmic} {Scoring} {Rules}},
	volume = {4},
	issn = {1545-8490},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/deca.1070.0089},
	doi = {10.1287/deca.1070.0089},
	abstract = {Strictly proper scoring rules continue to play an important role in probability assessment. Although many such rules have been developed, relatively little guidance exists as to which rule is the most appropriate. In this paper, we discuss two important properties of quadratic, spherical, and logarithmic scoring rules. From an ex post perspective, we compare their rank order properties and conclude that both quadratic and spherical scoring perform poorly in this regard, relative to logarithmic. Second, from an ex ante perspective, we demonstrate that in many situations, logarithmic scoring is the method least affected by a nonlinear utility function. These results suggest that logarithmic scoring is superior when rank order results are important and/or when the assessor has a nonlinear utility function. In addition to these results, and perhaps more important, we demonstrate that nonlinear utility induces relatively little deviation from the optimal assessment under an assumption of risk neutrality. These results provide both comfort and guidance to those who would like to use scoring rules as part of the assessment process.},
	number = {2},
	urldate = {2021-03-30},
	journal = {Decision Analysis},
	author = {Bickel, J. Eric},
	month = jun,
	year = {2007},
	note = {Number: 2
Publisher: INFORMS},
	pages = {49--65},
}

@article{watson_molecular_1953,
	title = {Molecular {Structure} of {Nucleic} {Acids}: {A} {Structure} for {Deoxyribose} {Nucleic} {Acid}},
	volume = {171},
	copyright = {1953 Nature Publishing Group},
	issn = {1476-4687},
	shorttitle = {Molecular {Structure} of {Nucleic} {Acids}},
	url = {https://www.nature.com/articles/171737a0},
	doi = {10.1038/171737a0},
	abstract = {The determination in 1953 of the structure of deoxyribonucleic acid (DNA), with its two entwined helices and paired organic bases, was a tour de force in X-ray crystallography. But more significantly, it also opened the way for a deeper understanding of perhaps the most important biological process. In the words of Watson and Crick: "It has not escaped our notice that the specific pairing that we have postulated immediately suggests a possible copying mechanism for the genetic material." [Obituary of Francis Crick:},
	language = {en},
	number = {4356},
	urldate = {2021-04-13},
	journal = {Nature},
	author = {Watson, J. D. and Crick, F. H. C.},
	month = apr,
	year = {1953},
	note = {Number: 4356
Publisher: Nature Publishing Group},
	pages = {737--738},
}

@article{weitzman_recombinant_1998,
	title = {Recombinant {Growth}*},
	volume = {113},
	issn = {0033-5533},
	url = {https://doi.org/10.1162/003355398555595},
	doi = {10.1162/003355398555595},
	abstract = {This paper attempts to provide microfoundations for the knowledge production function in an idea-based growth model. Production of new ideas is made a function of newly reconfigured old ideas in the spirit of the way an agricultural research station develops improved plant varieties by cross-pollinating existing plant varieties. The model shows how knowledge can build upon itself in a combinatoric feedback process that may have significant implications for economic growth. The paper's main theme is that the ultimate limits to growth lie not so much in our ability to generate new ideas as in our ability to process an abundance of potentially new ideas into usable form.},
	number = {2},
	urldate = {2021-05-02},
	journal = {The Quarterly Journal of Economics},
	author = {Weitzman, Martin L.},
	month = may,
	year = {1998},
	note = {Number: 2},
	pages = {331--360},
}

@article{weitzman_recombinant_1998-1,
	title = {Recombinant {Growth}*},
	volume = {113},
	issn = {0033-5533},
	url = {https://doi.org/10.1162/003355398555595},
	doi = {10.1162/003355398555595},
	abstract = {This paper attempts to provide microfoundations for the knowledge production function in an idea-based growth model. Production of new ideas is made a function of newly reconfigured old ideas in the spirit of the way an agricultural research station develops improved plant varieties by cross-pollinating existing plant varieties. The model shows how knowledge can build upon itself in a combinatoric feedback process that may have significant implications for economic growth. The paper's main theme is that the ultimate limits to growth lie not so much in our ability to generate new ideas as in our ability to process an abundance of potentially new ideas into usable form.},
	number = {2},
	urldate = {2021-05-02},
	journal = {The Quarterly Journal of Economics},
	author = {Weitzman, Martin L.},
	month = may,
	year = {1998},
	note = {Number: 2},
	pages = {331--360},
}

@article{berliant_knowledge_2008,
	title = {Knowledge {Creation} as a {Square} {Dance} on the {Hilbert} {Cube}*},
	volume = {49},
	copyright = {© (2008) by the Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association},
	issn = {1468-2354},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-2354.2008.00512.x},
	doi = {https://doi.org/10.1111/j.1468-2354.2008.00512.x},
	abstract = {This article presents a micromodel of knowledge creation through the interactions among a group of people. The model features myopic agents in a pure externality model of interaction. Surprisingly, for a large set of initial conditions we find that the equilibrium process of knowledge creation converges to the most productive state, where the population splits into smaller groups of optimal size; close interaction takes place within each group only. This optimal size is larger as heterogeneity of knowledge is more important in the knowledge production process. Equilibrium paths are found analytically; they are a discontinuous function of initial heterogeneity.},
	language = {en},
	number = {4},
	urldate = {2021-05-02},
	journal = {International Economic Review},
	author = {Berliant, Marcus and Fujita, Masahisa},
	year = {2008},
	note = {Number: 4
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1468-2354.2008.00512.x},
	pages = {1251--1295},
}

@article{lucas_ideas_2009,
	title = {Ideas and {Growth}},
	volume = {76},
	issn = {0013-0427},
	url = {https://www.jstor.org/stable/40071767},
	abstract = {This paper introduces and partially develops a new model of endogenous technological change, viewed as the product of a class of problem-solving producers. The model, based on earlier work by Eaton and Kortum, is built up from the premise that all knowledge resides in the head of some individual person and the knowledge of a firm, or economy, or any group of people is simply the knowledge of the individuals that comprise it. The model is applied to an economy with a cohort structure. A calibration of the model using cross-section earnings data, in addition to aggregate GDP growth, is considered.},
	number = {301},
	urldate = {2021-05-02},
	journal = {Economica},
	author = {Lucas, Robert E.},
	year = {2009},
	note = {Number: 301
Publisher: [London School of Economics, Wiley, The London School of Economics and Political Science, The Suntory and Toyota International Centres for Economics and Related Disciplines]},
	pages = {1--19},
}

@article{jr_knowledge_2014,
	title = {Knowledge {Growth} and the {Allocation} of {Time}},
	volume = {122},
	url = {https://ideas.repec.org/a/ucp/jpolec/doi10.1086-674363.html},
	abstract = {We analyze a model economy with many agents, each with a different productivity level. Agents divide their time between two activities: producing goods with the production-related knowledge they already have and interacting with others in search of new, productivity-increasing ideas. These choices jointly determine the economy's current production level and its rate of learning and real growth. We construct the balanced growth path for this economy. We also study the allocation chosen by an idealized planner who takes into account and internalizes the external benefits of search. Finally, we provide three examples of alternative learning technologies and show that the properties of equilibrium allocations are quite sensitive to two of these variations.},
	language = {en},
	number = {1},
	urldate = {2021-05-02},
	journal = {Journal of Political Economy},
	author = {Jr, Robert E. Lucas and Moll, Benjamin},
	year = {2014},
	note = {Number: 1
Publisher: University of Chicago Press},
	pages = {1--51},
}

@article{thursby_prepublication_2018,
	title = {Prepublication disclosure of scientific results: {Norms}, competition, and commercial orientation},
	volume = {4},
	copyright = {Copyright © 2018 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).. This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.},
	issn = {2375-2548},
	shorttitle = {Prepublication disclosure of scientific results},
	url = {https://advances.sciencemag.org/content/4/5/eaar2133},
	doi = {10.1126/sciadv.aar2133},
	abstract = {On the basis of a survey of 7103 active faculty researchers in nine fields, we examine the extent to which scientists disclose prepublication results, and when they do, why? Except in two fields, more scientists disclose results before publication than not, but there is significant variation in their reasons to disclose, in the frequency of such disclosure, and in withholding crucial results when making public presentations. They disclose results for feedback and credit and to attract collaborators. Particularly in formulaic fields, scientists disclose to attract new researchers to the field independent of collaboration and to deter others from working on their exact problem. A probability model shows that 70\% of field variation in disclosure is related to differences in respondent beliefs about norms, competition, and commercialization. Our results suggest new research directions—for example, do the problems addressed or the methods of scientific production themselves shape norms and competition? Are the levels we observe optimal or simply path-dependent? What is the interplay of norms, competition, and commercialization in disclosure and the progress of science?
To disclose results before publication or not? That is the question.
To disclose results before publication or not? That is the question.},
	language = {en},
	number = {5},
	urldate = {2021-05-03},
	journal = {Science Advances},
	author = {Thursby, Jerry G. and Haeussler, Carolin and Thursby, Marie C. and Jiang, Lin},
	month = may,
	year = {2018},
	note = {Number: 5
Publisher: American Association for the Advancement of Science
Section: Research Article},
	pages = {eaar2133},
}

@article{partha_toward_1994,
	series = {Special {Issue} in {Honor} of {Nathan} {Rosenberg}},
	title = {Toward a new economics of science},
	volume = {23},
	issn = {0048-7333},
	url = {https://www.sciencedirect.com/science/article/pii/0048733394010021},
	doi = {10.1016/0048-7333(94)01002-1},
	abstract = {Science policy issues have recently joined technology issues in being acknowledged to have strategic importance for national ‘competitiveness’ and ‘economic security’. The economics literature addressed specifically to science and its interdependences with technological progress has been quite narrowly focused and has lacked an overarching conceptual framework to guide empirical studies and public policy discussions in this area. The emerging ‘new economics of science’, described by this paper, offers a way to remedy these deficiencies. It makes use of insights from the theory of games of incomplete information to synthesize the classic approach of Arrow and Nelson in examining the implications of the characteristics of information for allocative efficiency in research activities, on the one hand, with the functionalist analysis of institutional structures, reward systems and behavioral norms of ‘open science’ communities-associated with the sociology of science in the tradition of Merton-on the other. An analysis is presented of the gross features of the institutions and norms distinguishing open science from other modes of organizing scientific research, which shows that the collegiate reputation-based reward system functions rather well in satisfying the requirement of social efficiency in increasing the stock of reliable knowledge. At a more fine-grain level of examination, however, the detailed workings of the system based on the pursuit of priority are found to cause numerous inefficiencies in the allocation of basic and applied science resources, both within given fields and programs and across time. Another major conclusion, arrived at in the context of examining policy measures and institutional reforms proposed to promote knowledge transfers between university-based open science and commercial R\&D, is that there are no economic forces that operate automatically to maintain dynamic efficiency in the interactions of these two (organizational) spheres. Ill-considered institutional experiments, which destroy their distinctive features if undertaken on a sufficient scale, may turn out to be very costly in terms of long-term economic performance.},
	language = {en},
	number = {5},
	urldate = {2021-05-03},
	journal = {Research Policy},
	author = {Partha, Dasgupta and David, Paul A.},
	month = sep,
	year = {1994},
	note = {Number: 5},
	pages = {487--521},
}

@article{murray_mice_2016,
	title = {Of {Mice} and {Academics}: {Examining} the {Effect} of {Openness} on {Innovation}},
	volume = {8},
	issn = {1945-7731},
	shorttitle = {Of {Mice} and {Academics}},
	url = {https://www.aeaweb.org/articles?id=10.1257/pol.20140062},
	doi = {10.1257/pol.20140062},
	abstract = {This paper argues that openness, by lowering costs to access existing research, can enhance both early and late stage innovation through greater exploration of novel research directions. We examine a natural experiment in openness: late-1990s NIH agreements that reduced academics' access costs regarding certain genetically engineered mice. Implementing difference-in-differences estimators, we find that increased openness encourages entry by new researchers and exploration of more diverse research paths, and does not reduce the creation of new genetically engineered mice. Our findings highlight a neglected cost of strong intellectual property restrictions: lower levels of exploration leading to reduced diversity of research output. (JEL I23, O31, O33, O34)},
	language = {en},
	number = {1},
	urldate = {2021-05-03},
	journal = {American Economic Journal: Economic Policy},
	author = {Murray, Fiona and Aghion, Philippe and Dewatripont, Mathias and Kolev, Julian and Stern, Scott},
	month = feb,
	year = {2016},
	note = {Number: 1},
	keywords = {Diffusion Processes, Intellectual Property and Intellectual Capital, Higher Education, Research Institutions, Innovation and Invention: Processes and Incentives, Technological Change: Choices and Consequences},
	pages = {212--252},
}

@article{jones_as_2011,
	title = {As {Science} {Evolves}, {How} {Can} {Science} {Policy}?},
	volume = {11},
	issn = {1531-3468},
	url = {https://www.journals.uchicago.edu/doi/full/10.1086/655820},
	doi = {10.1086/655820},
	abstract = {Getting science policy right is a core objective of government that bears on scientific advance, economic growth, health, and longevity. Yet the process of science is changing. As science advances and knowledge accumulates, ensuing generations of innovators spend longer in training and become more narrowly expert, shifting key innovations (i) later in the life cycle and (ii) from solo researchers toward teams. This paper summarizes the evidence that science has evolved—and continues to evolve—on both dimensions. The paper then considers science policy. The ongoing shift away from younger scholars and toward teamwork raises serious policy challenges. Central issues involve (a) maintaining incentives for entry into scientific careers as the training phase extends, (b) ensuring effective evaluation of ideas (including decisions on patent rights and research grants) as evaluator expertise narrows, and (c) providing appropriate effort incentives as scientists increasingly work in teams. Institutions such as government grant agencies, the patent office, the science education system, and the Nobel Prize come under a unified focus in this paper. In all cases, the question is how these institutions can change. As science evolves, science policy may become increasingly misaligned with science itself—unless science policy evolves in tandem.},
	urldate = {2021-05-03},
	journal = {Innovation Policy and the Economy},
	author = {Jones, Benjamin F.},
	month = jan,
	year = {2011},
	note = {Publisher: The University of Chicago Press},
	pages = {103--131},
}

@article{watson_molecular_1953-1,
	title = {Molecular {Structure} of {Nucleic} {Acids}: {A} {Structure} for {Deoxyribose} {Nucleic} {Acid}},
	volume = {171},
	copyright = {1953 Nature Publishing Group},
	issn = {1476-4687},
	shorttitle = {Molecular {Structure} of {Nucleic} {Acids}},
	url = {https://www.nature.com/articles/171737a0.},
	doi = {10.1038/171737a0},
	abstract = {The determination in 1953 of the structure of deoxyribonucleic acid (DNA), with its two entwined helices and paired organic bases, was a tour de force in X-ray crystallography. But more significantly, it also opened the way for a deeper understanding of perhaps the most important biological process. In the words of Watson and Crick: "It has not escaped our notice that the specific pairing that we have postulated immediately suggests a possible copying mechanism for the genetic material." [Obituary of Francis Crick:},
	language = {en},
	number = {4356},
	urldate = {2021-05-03},
	journal = {Nature},
	author = {Watson, J. D. and Crick, F. H. C.},
	month = apr,
	year = {1953},
	note = {Number: 4356
Publisher: Nature Publishing Group},
	pages = {737--738},
}

@article{nosek_preregistration_2018,
	title = {The preregistration revolution},
	volume = {115},
	copyright = {© 2018 . http://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/115/11/2600},
	doi = {10.1073/pnas.1708274114},
	abstract = {Progress in science relies in part on generating hypotheses with existing observations and testing hypotheses with new observations. This distinction between postdiction and prediction is appreciated conceptually but is not respected in practice. Mistaking generation of postdictions with testing of predictions reduces the credibility of research findings. However, ordinary biases in human reasoning, such as hindsight bias, make it hard to avoid this mistake. An effective solution is to define the research questions and analysis plan before observing the research outcomes—a process called preregistration. Preregistration distinguishes analyses and outcomes that result from predictions from those that result from postdictions. A variety of practical strategies are available to make the best possible use of preregistration in circumstances that fall short of the ideal application, such as when the data are preexisting. Services are now available for preregistration across all disciplines, facilitating a rapid increase in the practice. Widespread adoption of preregistration will increase distinctiveness between hypothesis generation and hypothesis testing and will improve the credibility of research findings.},
	language = {en},
	number = {11},
	urldate = {2021-05-03},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Nosek, Brian A. and Ebersole, Charles R. and DeHaven, Alexander C. and Mellor, David T.},
	month = mar,
	year = {2018},
	pmid = {29531091},
	note = {Number: 11
Publisher: National Academy of Sciences
Section: Colloquium Paper},
	keywords = {confirmatory analysis, exploratory analysis, methodology, open science, preregistration},
	pages = {2600--2606},
}

@article{song_extent_2009,
	title = {Extent of publication bias in different categories of research cohorts: a meta-analysis of empirical studies},
	volume = {9},
	issn = {1471-2288},
	shorttitle = {Extent of publication bias in different categories of research cohorts},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2789098/},
	doi = {10.1186/1471-2288-9-79},
	abstract = {Background
The validity of research synthesis is threatened if published studies comprise a biased selection of all studies that have been conducted. We conducted a meta-analysis to ascertain the strength and consistency of the association between study results and formal publication.

Methods
The Cochrane Methodology Register Database, MEDLINE and other electronic bibliographic databases were searched (to May 2009) to identify empirical studies that tracked a cohort of studies and reported the odds of formal publication by study results. Reference lists of retrieved articles were also examined for relevant studies. Odds ratios were used to measure the association between formal publication and significant or positive results. Included studies were separated into subgroups according to starting time of follow-up, and results from individual cohort studies within the subgroups were quantitatively pooled.

Results
We identified 12 cohort studies that followed up research from inception, four that included trials submitted to a regulatory authority, 28 that assessed the fate of studies presented as conference abstracts, and four cohort studies that followed manuscripts submitted to journals. The pooled odds ratio of publication of studies with positive results, compared to those without positive results (publication bias) was 2.78 (95\% CI: 2.10 to 3.69) in cohorts that followed from inception, 5.00 (95\% CI: 2.01 to 12.45) in trials submitted to regulatory authority, 1.70 (95\% CI: 1.44 to 2.02) in abstract cohorts, and 1.06 (95\% CI: 0.80 to 1.39) in cohorts of manuscripts.

Conclusion
Dissemination of research findings is likely to be a biased process. Publication bias appears to occur early, mainly before the presentation of findings at conferences or submission of manuscripts to journals.},
	urldate = {2021-05-03},
	journal = {BMC Medical Research Methodology},
	author = {Song, Fujian and Parekh-Bhurke, Sheetal and Hooper, Lee and Loke, Yoon K and Ryder, Jon J and Sutton, Alex J and Hing, Caroline B and Harvey, Ian},
	month = nov,
	year = {2009},
	pmid = {19941636},
	pmcid = {PMC2789098},
	pages = {79},
}

@article{song_extent_2009-1,
	title = {Extent of publication bias in different categories of research cohorts: a meta-analysis of empirical studies},
	volume = {9},
	issn = {1471-2288},
	shorttitle = {Extent of publication bias in different categories of research cohorts},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2789098/},
	doi = {10.1186/1471-2288-9-79},
	abstract = {Background
The validity of research synthesis is threatened if published studies comprise a biased selection of all studies that have been conducted. We conducted a meta-analysis to ascertain the strength and consistency of the association between study results and formal publication.

Methods
The Cochrane Methodology Register Database, MEDLINE and other electronic bibliographic databases were searched (to May 2009) to identify empirical studies that tracked a cohort of studies and reported the odds of formal publication by study results. Reference lists of retrieved articles were also examined for relevant studies. Odds ratios were used to measure the association between formal publication and significant or positive results. Included studies were separated into subgroups according to starting time of follow-up, and results from individual cohort studies within the subgroups were quantitatively pooled.

Results
We identified 12 cohort studies that followed up research from inception, four that included trials submitted to a regulatory authority, 28 that assessed the fate of studies presented as conference abstracts, and four cohort studies that followed manuscripts submitted to journals. The pooled odds ratio of publication of studies with positive results, compared to those without positive results (publication bias) was 2.78 (95\% CI: 2.10 to 3.69) in cohorts that followed from inception, 5.00 (95\% CI: 2.01 to 12.45) in trials submitted to regulatory authority, 1.70 (95\% CI: 1.44 to 2.02) in abstract cohorts, and 1.06 (95\% CI: 0.80 to 1.39) in cohorts of manuscripts.

Conclusion
Dissemination of research findings is likely to be a biased process. Publication bias appears to occur early, mainly before the presentation of findings at conferences or submission of manuscripts to journals.},
	urldate = {2021-05-03},
	journal = {BMC Medical Research Methodology},
	author = {Song, Fujian and Parekh-Bhurke, Sheetal and Hooper, Lee and Loke, Yoon K and Ryder, Jon J and Sutton, Alex J and Hing, Caroline B and Harvey, Ian},
	month = nov,
	year = {2009},
	pmid = {19941636},
	pmcid = {PMC2789098},
	pages = {79},
}

@article{dickersin_nih_1993,
	title = {{NIH} clinical trials and publication bias},
	volume = {Doc No 50},
	abstract = {To investigate the association between trial characteristics, findings, and publication. The major factor hypothesized to be associated with publication was "significant" results, which included both statistically significant results and results assessed by the investigators to be qualitatively significant, when statistical testing was not done. Other factors hypothesized to have a possible association with publication were funding institute, funding mechanism (grant versus contract versus intramural), multicenter status, use of comparison groups, large sample size, type of control (parallel versus nonparallel), use of randomization and masking, type of analysis (by treatment received versus by treatment assigned), and investigator sex and rank.
Follow-up, by 1988 interview with the principal investigator or surrogate, of all clinical trials funded by the National Institutes of Health (NIH) in 1979, to learn of trial results and publication status.
Two hundred ninety-three NIH trials, funded in 1979.
Publication of clinical trial results.
Of the 198 clinical trials completed by 1988, 93\% had been published. Trials with "significant" results were more likely to be published than those showing "nonsignificant" results (adjusted odds ratio [OR] = 12.30; 95\% confidence interval [CI], 2.54 to 60.00). No other factor was positively associated with publication. Most unpublished trials remained so because investigators thought the results were "not interesting" or they "did not have enough time" (42.8\%). Metaanalysis using data from this and 3 similar studies provided a combined unadjusted OR of 2.88 (95\% CI, 2.13 to 3.89) for the association between significant results and publication.
Even when the overall publication rate is high, such as for trials funded by the NIH, publication bias remains a significant problem. Given the importance of trials and their utility in evaluating medical treatments, especially within the context of metaanalysis, it is clear that we need more reliable systems for maintaining information about initiated studies. Trial registers represent such a system but must receive increased financial support to succeed.},
	journal = {The Online journal of current clinical trials},
	author = {Dickersin, Kay and Min, YI},
	month = may,
	year = {1993},
	pages = {[4967 words; 53 paragraphs]},
}

@inproceedings{gao_trick_2014-1,
	address = {New York, NY, USA},
	series = {{EC} '14},
	title = {Trick or treat: putting peer prediction to the test},
	isbn = {978-1-4503-2565-3},
	shorttitle = {Trick or treat},
	url = {https://doi.org/10.1145/2600057.2602865},
	doi = {10.1145/2600057.2602865},
	abstract = {Collecting truthful subjective information from multiple individuals is an important problem in many social and online systems. While peer prediction mechanisms promise to elicit truthful information by rewarding participants with carefully constructed payments, they also admit uninformative equilibria where coordinating participants provide no useful information. To understand how participants behave towards such mechanisms in practice, we conduct the first controlled online experiment of a peer prediction mechanism, engaging the participants in a multiplayer, real-time and repeated game. Using a hidden Markov model to capture players' strategies from their actions, our results show that participants successfully coordinate on uninformative equilibria and the truthful equilibrium is not focal, even when some uninformative equilibria do not exist or are undesirable. In contrast, most players are consistently truthful in the absence of peer prediction, suggesting that these mechanisms may be harmful when truthful reporting has similar cost to strategic behavior.},
	urldate = {2021-05-02},
	booktitle = {Proceedings of the fifteenth {ACM} conference on {Economics} and computation},
	publisher = {Association for Computing Machinery},
	author = {Gao, Xi Alice and Mao, Andrew and Chen, Yiling and Adams, Ryan Prescott},
	month = jun,
	year = {2014},
	keywords = {peer prediction, hidden markov models, online behavioral experiment},
	pages = {507--524},
}

@techreport{akcigit_dancing_2018,
	type = {Working {Paper}},
	title = {Dancing with the {Stars}: {Innovation} {Through} {Interactions}},
	shorttitle = {Dancing with the {Stars}},
	url = {https://www.nber.org/papers/w24466},
	abstract = {An inventor's own knowledge is a key input in the innovation process. This knowledge can be built by interacting with and learning from others. This paper uses a new large-scale panel dataset on European inventors matched to their employers and patents. We document key empirical facts on inventors' productivity over the life cycle, inventors' research teams, and interactions with other inventors. Among others, most patents are the result of collaborative work. Interactions with better inventors are very strongly correlated with higher subsequent productivity. These facts motivate the main ingredients of our new innovation-led endogenous growth model, in which innovations are produced by heterogeneous research teams of inventors using inventor knowledge. The evolution of an inventor's knowledge is explained through the lens of a diffusion model in which inventors can learn in two ways: By interacting with others at an endogenously chosen rate; and from an external, age-dependent source that captures alternative learning channels, such as learning-by-doing. Thus, our knowledge diffusion model nests inside the innovation-based endogenous growth model. We estimate the model, which fits the data very closely, and use it to perform several policy exercises, such as quantifying the large importance of interactions for growth, studying the effects of reducing interaction costs (e.g., through IT or infrastructure), and comparing the learning and innovation processes of different countries.},
	number = {24466},
	urldate = {2021-10-19},
	institution = {National Bureau of Economic Research},
	author = {Akcigit, Ufuk and Caicedo, Santiago and Miguelez, Ernest and Stantcheva, Stefanie and Sterzi, Valerio},
	month = mar,
	year = {2018},
	doi = {10.3386/w24466},
	note = {Series: Working Paper Series},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\8ULK3H43\\Akcigit et al. - 2018 - Dancing with the Stars Innovation Through Interac.pdf:application/pdf},
}

@article{jaravel_team-specific_2018,
	title = {Team-{Specific} {Capital} and {Innovation}},
	volume = {108},
	issn = {0002-8282},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.20151184},
	doi = {10.1257/aer.20151184},
	abstract = {We establish the importance of team-specific capital in the typical inventor's career. Using administrative tax and patent data for the population of US patent inventors from 1996 to 2012, we find that an inventor's premature death causes a large and long-lasting decline in their co-inventor's earnings and citation-weighted patents (–4 percent and –15 percent after 8 years, respectively). After ruling out firm disruption, network effects, and top-down spillovers as main channels, we show that the effect is driven by close-knit teams and that team-specific capital largely results from an "experience" component increasing collaboration value over time.},
	language = {en},
	number = {4-5},
	urldate = {2021-10-19},
	journal = {American Economic Review},
	author = {Jaravel, Xavier and Petkova, Neviana and Bell, Alex},
	month = apr,
	year = {2018},
	keywords = {Human Capital, Labor Productivity, Wage Level and Structure, Occupational Choice, Skills, Wage Differentials, Personnel Economics: Labor Management, Innovation and Invention: Processes and Incentives, Intellectual Property and Intellectual Capital},
	pages = {1034--1073},
	file = {Full Text:C\:\\Users\\aluga\\Zotero\\storage\\A767B25Y\\Jaravel et al. - 2018 - Team-Specific Capital and Innovation.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\7DIHSXK8\\articles.html:text/html},
}

@misc{noauthor_open_nodate,
	title = {“{Open}” disclosure of innovations, incentives and follow-on reuse: {Theory} on processes of cumulative innovation and a field experiment in computational biology - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S0048733314001425},
	urldate = {2021-10-19},
	file = {“Open” disclosure of innovations, incentives and follow-on reuse\: Theory on processes of cumulative innovation and a field experiment in computational biology - ScienceDirect:C\:\\Users\\aluga\\Zotero\\storage\\NSDMS5T9\\S0048733314001425.html:text/html},
}

@article{franco_publication_2014,
	title = {Publication bias in the social sciences: {Unlocking} the file drawer},
	volume = {345},
	shorttitle = {Publication bias in the social sciences},
	url = {https://www.science.org/doi/abs/10.1126/science.1255484},
	doi = {10.1126/science.1255484},
	number = {6203},
	urldate = {2021-10-19},
	journal = {Science},
	author = {Franco, Annie and Malhotra, Neil and Simonovits, Gabor},
	month = sep,
	year = {2014},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1502--1505},
}

@article{chandler_breaking_2013,
	title = {Breaking monotony with meaning: {Motivation} in crowdsourcing markets},
	volume = {90},
	issn = {0167-2681},
	shorttitle = {Breaking monotony with meaning},
	url = {https://www.sciencedirect.com/science/article/pii/S016726811300036X},
	doi = {10.1016/j.jebo.2013.03.003},
	abstract = {We conduct the first natural field experiment to explore the relationship between the “meaningfulness” of a task and worker effort. We employed about 2500 workers from Amazon's Mechanical Turk (MTurk), an online labor market, to label medical images. Although given an identical task, we experimentally manipulated how the task was framed. Subjects in the meaningful treatment were told that they were labeling tumor cells in order to assist medical researchers, subjects in the zero-context condition (the control group) were not told the purpose of the task, and, in stark contrast, subjects in the shredded treatment were not given context and were additionally told that their work would be discarded. We found that when a task was framed more meaningfully, workers were more likely to participate. We also found that the meaningful treatment increased the quantity of output (with an insignificant change in quality) while the shredded treatment decreased the quality of output (with no change in quantity). We believe these results will generalize to other short-term labor markets. Our study also discusses MTurk as an exciting platform for running natural field experiments in economics.},
	language = {en},
	urldate = {2021-10-19},
	journal = {Journal of Economic Behavior \& Organization},
	author = {Chandler, Dana and Kapelner, Adam},
	month = jun,
	year = {2013},
	keywords = {Crowdsourcing, Natural field experiment, Online labor markets, Worker motivation},
	pages = {123--133},
	file = {Submitted Version:C\:\\Users\\aluga\\Zotero\\storage\\F5ZHX69Y\\Chandler and Kapelner - 2013 - Breaking monotony with meaning Motivation in crow.pdf:application/pdf},
}

@article{boudreau_open_2015,
	title = {“{Open}” disclosure of innovations, incentives and follow-on reuse: {Theory} on processes of cumulative innovation and a field experiment in computational biology},
	volume = {44},
	issn = {0048-7333},
	shorttitle = {“{Open}” disclosure of innovations, incentives and follow-on reuse},
	url = {https://www.sciencedirect.com/science/article/pii/S0048733314001425},
	doi = {10.1016/j.respol.2014.08.001},
	abstract = {Most of society's innovation systems – academic science, the patent system, open source, etc. – are “open” in the sense that they are designed to facilitate knowledge disclosure among innovators. An essential difference across innovation systems is whether disclosure is of intermediate progress and solutions or of completed innovations. We theorize and present experimental evidence linking intermediate versus final disclosure to an ‘incentives-versus-reuse’ tradeoff and to a transformation of the innovation search process. We find intermediate disclosure has the advantage of efficiently steering development towards improving existing solution approaches, but also has the effect of limiting experimentation and narrowing technological search. We discuss the comparative advantages of intermediate versus final disclosure policies in fostering innovation.},
	language = {en},
	number = {1},
	urldate = {2021-10-19},
	journal = {Research Policy},
	author = {Boudreau, Kevin J. and Lakhani, Karim R.},
	month = feb,
	year = {2015},
	keywords = {Incentives, Disclosures, Innovation, Open innovation, Policy, Search},
	pages = {4--19},
}

@article{boudreau_open_2015-1,
	title = {“{Open}” disclosure of innovations, incentives and follow-on reuse: {Theory} on processes of cumulative innovation and a field experiment in computational biology},
	volume = {44},
	shorttitle = {“{Open}” disclosure of innovations, incentives and follow-on reuse},
	url = {https://ideas.repec.org/a/eee/respol/v44y2015i1p4-19.html},
	abstract = {Most of society's innovation systems – academic science, the patent system, open source, etc. – are “open” in the sense that they are designed to facilitate knowledge disclosure among innovators. An essential difference across innovation systems is whether disclosure is of intermediate progress and solutions or of completed innovations. We theorize and present experimental evidence linking intermediate versus final disclosure to an ‘incentives-versus-reuse’ tradeoff and to a transformation of the innovation search process. We find intermediate disclosure has the advantage of efficiently steering development towards improving existing solution approaches, but also has the effect of limiting experimentation and narrowing technological search. We discuss the comparative advantages of intermediate versus final disclosure policies in fostering innovation.},
	language = {en},
	number = {1},
	urldate = {2021-10-19},
	journal = {Research Policy},
	author = {Boudreau, Kevin J. and Lakhani, Karim R.},
	year = {2015},
	note = {Publisher: Elsevier},
	keywords = {Incentives, Disclosures, Innovation, Open innovation, Policy, Search},
	pages = {4--19},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\DJVXNJXD\\v44y2015i1p4-19.html:text/html},
}

@article{thursby_prepublication_nodate,
	title = {Prepublication disclosure of scientific results: {Norms}, competition, and commercial orientation},
	volume = {4},
	shorttitle = {Prepublication disclosure of scientific results},
	url = {https://www.science.org/doi/10.1126/sciadv.aar2133},
	doi = {10.1126/sciadv.aar2133},
	number = {5},
	urldate = {2021-11-07},
	journal = {Science Advances},
	author = {Thursby, Jerry G. and Haeussler, Carolin and Thursby, Marie C. and Jiang, Lin},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eaar2133},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\K4EGL5SE\\Thursby et al. - Prepublication disclosure of scientific results N.pdf:application/pdf},
}

@misc{noauthor_bayesian_nodate,
	title = {A {Bayesian} {Truth} {Serum} for {Subjective} {Data}},
	url = {https://www.science.org/doi/10.1126/science.1102081},
	urldate = {2021-11-08},
	file = {A Bayesian Truth Serum for Subjective Data:C\:\\Users\\aluga\\Zotero\\storage\\J9PZBM2Z\\science.html:text/html},
}

@article{prelec_bayesian_2004,
	title = {A {Bayesian} {Truth} {Serum} for {Subjective} {Data}},
	volume = {306},
	url = {https://www.science.org/doi/abs/10.1126/science.1102081},
	doi = {10.1126/science.1102081},
	number = {5695},
	urldate = {2021-11-08},
	journal = {Science},
	author = {Prelec, Dražen},
	month = oct,
	year = {2004},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {462--466},
}

@article{kruppa_probability_2014,
	title = {Probability estimation with machine learning methods for dichotomous and multicategory outcome: {Theory}},
	volume = {56},
	issn = {1521-4036},
	shorttitle = {Probability estimation with machine learning methods for dichotomous and multicategory outcome},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201300068},
	doi = {10.1002/bimj.201300068},
	abstract = {Probability estimation for binary and multicategory outcome using logistic and multinomial logistic regression has a long-standing tradition in biostatistics. However, biases may occur if the model is misspecified. In contrast, outcome probabilities for individuals can be estimated consistently with machine learning approaches, including k-nearest neighbors (k-NN), bagged nearest neighbors (b-NN), random forests (RF), and support vector machines (SVM). Because machine learning methods are rarely used by applied biostatisticians, the primary goal of this paper is to explain the concept of probability estimation with these methods and to summarize recent theoretical findings. Probability estimation in k-NN, b-NN, and RF can be embedded into the class of nonparametric regression learning machines; therefore, we start with the construction of nonparametric regression estimates and review results on consistency and rates of convergence. In SVMs, outcome probabilities for individuals are estimated consistently by repeatedly solving classification problems. For SVMs we review classification problem and then dichotomous probability estimation. Next we extend the algorithms for estimating probabilities using k-NN, b-NN, and RF to multicategory outcomes and discuss approaches for the multicategory probability estimation problem using SVM. In simulation studies for dichotomous and multicategory dependent variables we demonstrate the general validity of the machine learning methods and compare it with logistic regression. However, each method fails in at least one simulation scenario. We conclude with a discussion of the failures and give recommendations for selecting and tuning the methods. Applications to real data and example code are provided in a companion article (doi:10.1002/bimj.201300077).},
	language = {en},
	number = {4},
	urldate = {2023-02-13},
	journal = {Biometrical Journal},
	author = {Kruppa, Jochen and Liu, Yufeng and Biau, Gérard and Kohler, Michael and König, Inke R. and Malley, James D. and Ziegler, Andreas},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.201300068},
	keywords = {Bagged nearest neighbor, Nonparametric regression, Probability estimation, Random forest, Support vector machine},
	pages = {534--563},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\SBL6W57H\\bimj.html:text/html},
}

@article{malley_probability_2012,
	title = {Probability {Machines}},
	volume = {51},
	copyright = {Schattauer GmbH},
	issn = {0026-1270, 2511-705X},
	url = {http://www.thieme-connect.de/DOI/DOI?10.3414/ME00-01-0052},
	doi = {10.3414/ME00-01-0052},
	abstract = {Background: Most machine learning approaches only provide a classification for binary responses. However, probabilities are required for risk estimation using individual patient characteristics. It has been shown recently that every statistical learning machine known to be consistent for a nonparametric regression problem is a probability machine that is provably consistent for this estimation problem.

  Objectives: The aim of this paper is to show how random forests and nearest neighbors can be used for consistent estimation of individual probabilities.

  Methods: Two random forest algorithms and two nearest neighbor algorithms are described in detail for estimation of individual probabilities. We discuss the consistency of random forests, nearest neighbors and other learning machines in detail. We conduct a simulation study to illustrate the validity of the methods. We exemplify the algorithms by analyzing two well-known data sets on the diagnosis of appendicitis and the diagnosis of diabetes in Pima Indians.

  Results: Simulations demonstrate the validity of the method. With the real data application, we show the accuracy and practicality of this approach. We provide sample code from R packages in which the probability estimation is already available. This means that all calculations can be performed using existing software.

  Conclusions: Random forest algorithms as well as nearest neighbor approaches are valid machine learning methods for estimating individual probabilities for binary responses. Freely available implementations are available in R and may be used for applications.},
	language = {en},
	number = {1},
	urldate = {2023-02-13},
	journal = {Methods of Information in Medicine},
	author = {Malley, J. D. and Kruppa, J. and Dasgupta, A. and Malley, K. G. and Ziegler, A.},
	year = {2012},
	note = {Publisher: Schattauer GmbH},
	keywords = {Brier score, consistency, k nearest neighbor, logistic regression, probability estimation, random forest},
	pages = {74--81},
	file = {Accepted Version:C\:\\Users\\aluga\\Zotero\\storage\\ND7US8RJ\\Malley et al. - 2012 - Probability Machines.pdf:application/pdf},
}

@article{brodeur_methods_2020,
	title = {Methods {Matter}: p-{Hacking} and {Publication} {Bias} in {Causal} {Analysis} in {Economics}},
	volume = {110},
	issn = {0002-8282},
	shorttitle = {Methods {Matter}},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.20190687},
	doi = {10.1257/aer.20190687},
	abstract = {The credibility revolution in economics has promoted causal identification using randomized control trials (RCT), difference-in-differences (DID), instrumental variables (IV) and regression discontinuity design (RDD). Applying multiple approaches to over 21,000 hypothesis tests published in 25 leading economics journals, we find that the extent of p-hacking and publication bias varies greatly by method. IV (and to a lesser extent DID) are particularly problematic. We find no evidence that (i) papers published in the Top 5 journals are different to others; (ii) the journal "revise and resubmit" process mitigates the problem; (iii) things are improving through time.},
	language = {en},
	number = {11},
	urldate = {2023-02-14},
	journal = {American Economic Review},
	author = {Brodeur, Abel and Cook, Nikolai and Heyes, Anthony},
	month = nov,
	year = {2020},
	keywords = {and Selection, Hypothesis Testing: General, Model Evaluation, Sociology of Economics, Validation},
	pages = {3634--3660},
}

@article{askarov_significance_2022,
	title = {The {Significance} of {Data}-{Sharing} {Policy}},
	issn = {1542-4766},
	url = {https://doi.org/10.1093/jeea/jvac053},
	doi = {10.1093/jeea/jvac053},
	abstract = {We assess the impact of mandating data-sharing in economics journals on two dimensions of research credibility: statistical significance and excess statistical significance (ESS). ESS is a necessary condition for publication selection bias. Quasi-experimental difference-in-differences analysis of 20,121 estimates published in 24 general interest and leading field journals shows that data-sharing policies have reduced reported statistical significance and the associated t-values. The magnitude of this reduction is large and of practical significance. We also find suggestive evidence that mandatory data-sharing reduces ESS and hence decreases publication bias.},
	urldate = {2023-02-14},
	journal = {Journal of the European Economic Association},
	author = {Askarov, Zohid and Doucouliagos, Anthony and Doucouliagos, Hristos and Stanley, T D},
	month = sep,
	year = {2022},
	pages = {jvac053},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\KVKT566U\\6706852.html:text/html},
}

@misc{brodeur_pre-registration_2022,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Do {Pre}-{Registration} and {Pre}-{Analysis} {Plans} {Reduce} p-{Hacking} and {Publication} {Bias}?},
	url = {https://papers.ssrn.com/abstract=4180594},
	doi = {10.2139/ssrn.4180594},
	abstract = {Randomized controlled trials (RCTs) are increasingly prominent in economics, with pre-registration and pre-analysis plans (PAPs) promoted as important in ensuring the credibility of findings. We investigate whether these tools reduce the extent of p-hacking and publication bias by collecting and studying the universe of test statistics, 15,992 in total, from RCTs published in 15 leading economics journals from 2018 through 2021. In our primary analysis, we find no meaningful difference in the distribution of test statistics from pre-registered studies, compared to their non-pre-registered counterparts. However, pre-registered studies that have a complete PAP are significantly less p-hacked. These results point to the importance of PAPs, rather than pre-registration in itself, in ensuring credibility.},
	language = {en},
	urldate = {2023-02-14},
	author = {Brodeur, Abel and Cook, Nikolai and Hartley, Jonathan and Heyes, Anthony},
	month = dec,
	year = {2022},
	keywords = {p-Hacking, Pre-analysis Plan, Pre-registration, Publication Bias, Research Credibility},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\VXUAJGN5\\Brodeur et al. - 2022 - Do Pre-Registration and Pre-Analysis Plans Reduce .pdf:application/pdf},
}

@misc{korinek_preparing_2022,
	type = {Working {Paper}},
	series = {Working {Paper} {Series}},
	title = {Preparing for the ({Non}-{Existent}?) {Future} of {Work}},
	shorttitle = {Preparing for the ({Non}-{Existent}?},
	url = {https://www.nber.org/papers/w30172},
	doi = {10.3386/w30172},
	abstract = {This paper considers the labor market and distributional implications of a scenario of ever-more-intelligent autonomous machines that substitute for human labor and drive down wages. We lay out three concerns arising from such a scenario and evaluate recent predictions and objections to these concerns. Then we analyze how a utilitarian social planner would allocate work and income if these concerns start to materialize. As the income produced by autonomous machines rises and the value of labor declines, a utilitarian planner finds it optimal to phase out work, beginning with workers who have low labor productivity and job satisfaction, since they have comparative advantage in enjoying leisure. This is in stark contrast to welfare systems that force individuals with low labor productivity to work. If there are significant wage declines, avoiding mass misery will require other ways of distributing income than labor markets, whether via sufficiently well-distributed capital ownership or via benefits. Recipients could still engage in work for its own sake if they enjoy work amenities such as structure, purpose and meaning. If work gives rise to positive externalities such as social connections or political stability, or if individuals undervalue the benefits of work because of internalities, then a social planner would incentivize work. However, in the long run, the planner might be able to achieve a higher level of social welfare by adopting alternative ways of providing these benefits.},
	urldate = {2023-02-14},
	publisher = {National Bureau of Economic Research},
	author = {Korinek, Anton and Juelfs, Megan},
	month = jun,
	year = {2022},
	doi = {10.3386/w30172},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\ZGDDKHKR\\Korinek and Juelfs - 2022 - Preparing for the (Non-Existent) Future of Work.pdf:application/pdf},
}

@article{ross-hellauer_survey_2017,
	title = {Survey on open peer review: {Attitudes} and experience amongst editors, authors and reviewers},
	volume = {12},
	issn = {1932-6203},
	shorttitle = {Survey on open peer review},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0189311},
	doi = {10.1371/journal.pone.0189311},
	abstract = {Open peer review (OPR) is a cornerstone of the emergent Open Science agenda. Yet to date no large-scale survey of attitudes towards OPR amongst academic editors, authors, reviewers and publishers has been undertaken. This paper presents the findings of an online survey, conducted for the OpenAIRE2020 project during September and October 2016, that sought to bridge this information gap in order to aid the development of appropriate OPR approaches by providing evidence about attitudes towards and levels of experience with OPR. The results of this cross-disciplinary survey, which received 3,062 full responses, show the majority (60.3\%) of respondents to be believe that OPR as a general concept should be mainstream scholarly practice (although attitudes to individual traits varied, and open identities peer review was not generally favoured). Respondents were also in favour of other areas of Open Science, like Open Access (88.2\%) and Open Data (80.3\%). Among respondents we observed high levels of experience with OPR, with three out of four (76.2\%) reporting having taken part in an OPR process as author, reviewer or editor. There were also high levels of support for most of the traits of OPR, particularly open interaction, open reports and final-version commenting. Respondents were against opening reviewer identities to authors, however, with more than half believing it would make peer review worse. Overall satisfaction with the peer review system used by scholarly journals seems to strongly vary across disciplines. Taken together, these findings are very encouraging for OPR’s prospects for moving mainstream but indicate that due care must be taken to avoid a “one-size fits all” solution and to tailor such systems to differing (especially disciplinary) contexts. OPR is an evolving phenomenon and hence future studies are to be encouraged, especially to further explore differences between disciplines and monitor the evolution of attitudes.},
	language = {en},
	number = {12},
	urldate = {2023-02-14},
	journal = {PLOS ONE},
	author = {Ross-Hellauer, Tony and Deppe, Arvid and Schmidt, Birgit},
	month = dec,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Ecology and environmental sciences, Open access publishing, Open peer review, Open science, Peer review, Psychological attitudes, Social sciences, Surveys},
	pages = {e0189311},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\VPLB9Z2M\\Ross-Hellauer et al. - 2017 - Survey on open peer review Attitudes and experien.pdf:application/pdf},
}

@article{thursby_prepublication_2018-1,
	title = {Prepublication disclosure of scientific results: {Norms}, competition, and commercial orientation},
	volume = {4},
	shorttitle = {Prepublication disclosure of scientific results},
	url = {https://www.science.org/doi/full/10.1126/sciadv.aar2133},
	doi = {10.1126/sciadv.aar2133},
	abstract = {On the basis of a survey of 7103 active faculty researchers in nine fields, we examine the extent to which scientists disclose prepublication results, and when they do, why? Except in two fields, more scientists disclose results before publication than not, but there is significant variation in their reasons to disclose, in the frequency of such disclosure, and in withholding crucial results when making public presentations. They disclose results for feedback and credit and to attract collaborators. Particularly in formulaic fields, scientists disclose to attract new researchers to the field independent of collaboration and to deter others from working on their exact problem. A probability model shows that 70\% of field variation in disclosure is related to differences in respondent beliefs about norms, competition, and commercialization. Our results suggest new research directions—for example, do the problems addressed or the methods of scientific production themselves shape norms and competition? Are the levels we observe optimal or simply path-dependent? What is the interplay of norms, competition, and commercialization in disclosure and the progress of science?},
	number = {5},
	urldate = {2023-02-14},
	journal = {Science Advances},
	author = {Thursby, Jerry G. and Haeussler, Carolin and Thursby, Marie C. and Jiang, Lin},
	month = may,
	year = {2018},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eaar2133},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\BX8CRVWH\\Thursby et al. - 2018 - Prepublication disclosure of scientific results N.pdf:application/pdf},
}

@article{canetti_zero-knowledge_2023,
	title = {Zero-{Knowledge} {Mechanisms}},
	url = {https://arxiv.org/abs/2302.05590v1},
	doi = {10.48550/arXiv.2302.05590},
	abstract = {A powerful feature in mechanism design is the ability to irrevocably commit to the rules of a mechanism. Commitment is achieved by public declaration, which enables players to verify incentive properties in advance and the outcome in retrospect. However, public declaration can reveal superfluous information that the mechanism designer might prefer not to disclose, such as her target function or private costs. Avoiding this may be possible via a trusted mediator; however, the availability of a trusted mediator, especially if mechanism secrecy must be maintained for years, might be unrealistic. We propose a new approach to commitment, and show how to commit to, and run, any given mechanism without disclosing it, while enabling the verification of incentive properties and the outcome -- all without the need for any mediators. Our framework is based on zero-knowledge proofs -- a cornerstone of modern cryptographic theory. Applications include non-mediated bargaining with hidden yet binding offers.},
	language = {en},
	urldate = {2023-02-15},
	author = {Canetti, Ran and Fiat, Amos and Gonczarowski, Yannai A.},
	month = feb,
	year = {2023},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\KYSJ43G8\\Canetti et al. - 2023 - Zero-Knowledge Mechanisms.pdf:application/pdf},
}

@article{knochelmann_open_2019,
	title = {Open {Science} in the {Humanities}, or: {Open} {Humanities}?},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2304-6775},
	shorttitle = {Open {Science} in the {Humanities}, or},
	url = {https://www.mdpi.com/2304-6775/7/4/65},
	doi = {10.3390/publications7040065},
	abstract = {Open science refers to both the practices and norms of more open and transparent communication and research in scientific disciplines and the discourse on these practices and norms. There is no such discourse dedicated to the humanities. Though the humanities appear to be less coherent as a cluster of scholarship than the sciences are, they do share unique characteristics which lead to distinct scholarly communication and research practices. A discourse on making these practices more open and transparent needs to take account of these characteristics. The prevalent scientific perspective in the discourse on more open practices does not do so, which confirms that the discourse’s name, open science, indeed excludes the humanities so that talking about open science in the humanities is incoherent. In this paper, I argue that there needs to be a dedicated discourse for more open research and communication practices in the humanities, one that integrates several elements currently fragmented into smaller, unconnected discourses (such as on open access, preprints, or peer review). I discuss three essential elements of open science—preprints, open peer review practices, and liberal open licences—in the realm of the humanities to demonstrate why a dedicated open humanities discourse is required.},
	language = {en},
	number = {4},
	urldate = {2023-02-20},
	journal = {Publications},
	author = {Knöchelmann, Marcel},
	month = dec,
	year = {2019},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {open science, digital humanities, open humanities, peer review, scholarly communication},
	pages = {65},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\DUWAFPUR\\Knöchelmann - 2019 - Open Science in the Humanities, or Open Humanitie.pdf:application/pdf},
}

@misc{parinov_end_2016,
	title = {End of {Publication}? {Open} access and a new scholarly communication technology},
	shorttitle = {End of {Publication}?},
	url = {http://arxiv.org/abs/1608.05505},
	doi = {10.48550/arXiv.1608.05505},
	abstract = {At this time, developers of research information systems are experimenting with new tools for research outputs usage that can expand the open access to research. These tools allow researchers to record research as annotations, nanopublications or other micro research outputs and link them by scientific relationships. If these micro outputs and relationships are shared by their creators publicly, these actions can initiate direct scholarly communication between the creators and the authors of the used research outputs. Such direct communication takes place while researchers are manipulating and organising their research results, e.g. as manuscripts. Thus, researchers come to communication before the manuscripts become traditional publications. In this paper, we discuss how this pre-publication communication can affect existing research practice. It can have important consequences for the research community like the end of publication as a communication instrument, the higher level of transparency in research, changes for the Open Access movement, academic publishers, peer-reviewing and research assessment systems. We analyse a background that exists in the economics discipline for experiments with the pre-publication communication. We propose a set of experiments with already existed and new tools, which can help with exploring the end of publication possible impacts on the research community.},
	urldate = {2023-02-20},
	publisher = {arXiv},
	author = {Parinov, Sergey and Antonova, Victoria},
	month = aug,
	year = {2016},
	note = {arXiv:1608.05505 [cs]},
	keywords = {68U35, Computer Science - Computers and Society, Computer Science - Digital Libraries, D.2.10, D.2.12, D.2.2, H.1.2, H.3.4, H.3.5, H.3.7, K.4},
	annote = {Comment: 8 pages, 3 figures},
	file = {arXiv Fulltext PDF:C\:\\Users\\aluga\\Zotero\\storage\\SGZ2F4LG\\Parinov and Antonova - 2016 - End of Publication Open access and a new scholarl.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\XATF7B65\\1608.html:text/html},
}

@article{shah_challenges_2022,
	title = {Challenges, experiments, and computational solutions in peer review},
	volume = {65},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3528086},
	doi = {10.1145/3528086},
	abstract = {Improving the peer review process in a scientific manner shows promise.},
	language = {en},
	number = {6},
	urldate = {2023-02-20},
	journal = {Communications of the ACM},
	author = {Shah, Nihar B.},
	month = jun,
	year = {2022},
	pages = {76--87},
	file = {Full Text:C\:\\Users\\aluga\\Zotero\\storage\\R69PDRMZ\\Shah - 2022 - Challenges, experiments, and computational solutio.pdf:application/pdf},
}

@article{soergel_open_nodate,
	title = {Open {Scholarship} and {Peer} {Review}: a {Time} for {Experimentation}},
	abstract = {Across a wide range of scientiﬁc communities, there is growing interest in accelerating and improving the progress of scholarship by making the peer review process more open. Multiple new publication venues and services are arising, especially in the life sciences, but each represents a single point in the multidimensional landscape of paper and review access for authors, reviewers and readers.},
	language = {en},
	author = {Soergel, David and Saunders, Adam and McCallum, Andrew},
	file = {Soergel et al. - Open Scholarship and Peer Review a Time for Exper.pdf:C\:\\Users\\aluga\\Zotero\\storage\\X236X33A\\Soergel et al. - Open Scholarship and Peer Review a Time for Exper.pdf:application/pdf},
}

@misc{noauthor_role_nodate,
	title = {The {Role} of {Peer} {Review} for {Scholarly} {Journals} in the {Information} {Age}},
	url = {https://doi.org/10.3998/3336451.0010.107},
	abstract = {This article discusses recent innovations in how peer review is conducted in light of the various functions journals fulfill in scholarly communities.},
	language = {en},
	urldate = {2023-02-20},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\FDXGLZWS\\3336451.0010.html:text/html},
}

@book{soergel_open_2013,
	title = {Open {Scholarship} and {Peer} {Review}: a {Time} for {Experimentation}},
	shorttitle = {Open {Scholarship} and {Peer} {Review}},
	abstract = {Across a wide range of scientific communities, there is growing interest in accelerating and improving the progress of scholarship by making the peer review process more open. Multiple new publication venues and services are arising, especially in the life sciences, but each represents a single point in the multi-dimensional landscape of paper and review access for authors, reviewers and readers. In this paper, we introduce a vocabulary for describing the landscape of choices regarding open access, formal peer review, and public commentary. We argue that the opportunities and pitfalls of open peer review warrant experimentation in these dimensions, and discuss desiderata of a flexible system. We close by describing OpenReview.net, our web-based system in which a small set of flexible primitives support a wide variety of peer review choices, and which provided the reviewing infrastructure for the 2013 International Conference on Learning Representations. We intend this software to enable trials of different policies, in order to help scientific communities explore open scholarship while addressing legitimate concerns regarding confidentiality , attribution, and bias.},
	author = {Soergel, David and Saunders, Adam and Mccallum, Andrew},
	month = jun,
	year = {2013},
}

@misc{noauthor_role_nodate-1,
	title = {The {Role} of {Peer} {Review} for {Scholarly} {Journals} in the {Information} {Age}},
	url = {https://doi.org/10.3998/3336451.0010.107},
	abstract = {This article discusses recent innovations in how peer review is conducted in light of the various functions journals fulfill in scholarly communities.},
	language = {en},
	urldate = {2023-02-20},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\GBUWCMJ8\\3336451.0010.html:text/html},
}

@misc{srinivasan_auctions_2021,
	title = {Auctions and {Prediction} {Markets} for {Scientific} {Peer} {Review}},
	url = {http://arxiv.org/abs/2109.00923},
	doi = {10.48550/arXiv.2109.00923},
	abstract = {Peer reviewed publications are considered the gold standard in certifying and disseminating ideas that a research community considers valuable. However, we identify two major drawbacks of the current system: (1) the overwhelming demand for reviewers due to a large volume of submissions, and (2) the lack of incentives for reviewers to participate and expend the necessary effort to provide high-quality reviews. In this work, we adopt a mechanism-design approach to propose improvements to the peer review process. We present a two-stage mechanism which ties together the paper submission and review process, simultaneously incentivizing high-quality reviews and high-quality submissions. In the first stage, authors participate in a VCG auction for review slots by submitting their papers along with a bid that represents their expected value for having their paper reviewed. For the second stage, we propose a novel prediction market-style mechanism (H-DIPP) building on recent work in the information elicitation literature, which incentivizes participating reviewers to provide honest and effortful reviews. The revenue raised by the Stage I auction is used in Stage II to pay reviewers based on the quality of their reviews.},
	urldate = {2023-02-21},
	publisher = {arXiv},
	author = {Srinivasan, Siddarth and Morgenstern, Jamie},
	month = aug,
	year = {2021},
	note = {arXiv:2109.00923 [cs, econ, q-fin]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Economics - General Economics},
	file = {arXiv Fulltext PDF:C\:\\Users\\aluga\\Zotero\\storage\\CTMEJZVY\\Srinivasan and Morgenstern - 2021 - Auctions and Prediction Markets for Scientific Pee.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\6VAXK4FS\\2109.html:text/html},
}

@misc{noauthor_peer_nodate,
	title = {Peer {Review} as an {Evolving} {Response} to {Organizational} {Constraint}: {Evidence} from {Sociology} {Journals}, 1952–2018 {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/s12108-020-09473-x},
	urldate = {2023-02-21},
	file = {Peer Review as an Evolving Response to Organizational Constraint\: Evidence from Sociology Journals, 1952–2018 | SpringerLink:C\:\\Users\\aluga\\Zotero\\storage\\5ZGL8JRX\\s12108-020-09473-x.html:text/html},
}

@article{simmons_false_2009-1,
	title = {False {Alarms}, {Tornado} {Warnings}, and {Tornado} {Casualties}},
	volume = {1},
	issn = {1948-8327},
	url = {https://journals.ametsoc.org/wcas/article/1/1/38/750/False-Alarms-Tornado-Warnings-and-Tornado},
	doi = {10.1175/2009WCAS1005.1},
	language = {en},
	number = {1},
	urldate = {2020-10-21},
	journal = {Weather, Climate, and Society},
	author = {Simmons, Kevin M. and Sutter, Daniel},
	month = oct,
	year = {2009},
	note = {Number: 1
Publisher: American Meteorological Society},
	pages = {38--53},
}

@article{ambuehl_belief_2018,
	title = {Belief updating and the demand for information},
	volume = {109},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825617302191},
	doi = {10.1016/j.geb.2017.11.009},
	abstract = {How do individuals value noisy information that guides economic decisions? In our laboratory experiment, we find that individuals underreact to increasing the informativeness of a signal, thus undervalue high-quality information, and that they disproportionately prefer information that may yield certainty. Both biases appear to be mainly due to non-standard belief updating. We find that individuals differ consistently in their responsiveness to information – the extent that their beliefs move upon observing signals. Individual parameters of responsiveness to information have explanatory power in two distinct choice environments and are unrelated to proxies for mathematical aptitude.},
	language = {en},
	urldate = {2022-05-30},
	journal = {Games and Economic Behavior},
	author = {Ambuehl, Sandro and Li, Shengwu},
	month = may,
	year = {2018},
	keywords = {Experimental economics, Belief updating, Demand for information, Probability weighting, Responsiveness to information},
	pages = {21--39},
}

@article{coutts_testing_2019,
	title = {Testing models of belief bias: {An} experiment},
	volume = {113},
	issn = {0899-8256},
	shorttitle = {Testing models of belief bias},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825618301763},
	doi = {10.1016/j.geb.2018.11.001},
	abstract = {Optimistic beliefs affect important areas of economic decision making, yet direct knowledge on how belief biases operate remains limited. To better understand these biases I introduce a theoretical framework that trades off anticipatory benefits against two potential costs of forming biased beliefs: (1) material costs which result from poor decisions, of Brunnermeier and Parker (2005), and (2) direct psychological costs of distorting reality, of Bracha and Brown (2012). The experiment exploits the potential of the BDM elicitation procedure adopted to lotteries to distort beliefs in different directions, depending on which costs are most important. Relative to an elicitation procedure without distortionary incentives, beliefs are biased in the optimistic direction. Increasing payments for accuracy further increases belief reports, in many cases away from the truth, consistent with psychological costs of belief distortion. Yet the overall results suggest that such theories of optimism fail to explain how beliefs respond to financial incentives.},
	language = {en},
	urldate = {2022-05-30},
	journal = {Games and Economic Behavior},
	author = {Coutts, Alexander},
	month = jan,
	year = {2019},
	keywords = {Beliefs, Affective expected utility, Anticipation, Optimism, Overconfidence, Pessimism},
	pages = {549--565},
}

@article{coutts_good_2019,
	title = {Good news and bad news are still news: experimental evidence on belief updating},
	volume = {22},
	issn = {1573-6938},
	shorttitle = {Good news and bad news are still news},
	url = {https://doi.org/10.1007/s10683-018-9572-5},
	doi = {10.1007/s10683-018-9572-5},
	abstract = {Bayesian updating remains the benchmark for dynamic modeling under uncertainty within economics. Recent theory and evidence suggest individuals may process information asymmetrically when it relates to personal characteristics or future life outcomes, with good news receiving more weight than bad news. I examine information processing across a broad set of contexts: (1) ego relevant, (2) financially relevant, and (3) non value relevant. In the first two cases, information about outcomes is valenced, containing either good or bad news. In the third case, information is value neutral. In contrast to a number of previous studies I do not find differences in belief updating across valenced and value neutral settings. Updating across all contexts is asymmetric and conservative: the former is influenced by sequences of signals received, a new variation of confirmation bias, while the latter is driven by non-updates. Despite this, posteriors are well approximated by those calculated using Bayes’ rule. Most importantly these patterns are present across all contexts, cautioning against the interpretation of asymmetric updating or other deviations from Bayes’ rule as being motivated by psychological biases.},
	language = {en},
	number = {2},
	urldate = {2022-05-30},
	journal = {Experimental Economics},
	author = {Coutts, Alexander},
	month = jun,
	year = {2019},
	note = {Number: 2},
	keywords = {Beliefs, C91, D84, Overconfidence, Asymmetric belief updating, Bayes’ rule, Conservatism, D83},
	pages = {369--395},
}

@article{golman_demand_2021,
	title = {The {Demand} for, and {Avoidance} of, {Information}},
	issn = {0025-1909},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2021.4244},
	doi = {10.1287/mnsc.2021.4244},
	abstract = {Management scientists recognize that decision making depends on the information people have but lack a unified behavioral theory of the demand for (and avoidance of) information. Drawing on an existing theoretical framework in which utility depends on beliefs and the attention paid to them, we develop and test a theory of the demand for information encompassing instrumental considerations, curiosity, and desire to direct attention to beliefs one feels good about. We decompose an individual’s demand for information into the desire to refine beliefs, holding attention constant, and the desire to focus attention on anticipated beliefs, holding these beliefs constant. Because the utility of resolving uncertainty (i.e., refining beliefs) depends on the attention paid to it and more important or salient questions capture more attention, demand for information depends on the importance and salience of the question(s) it addresses. In addition, because getting new information focuses attention on one’s beliefs and people want to savor good news and ignore bad news, the desire to obtain or avoid information depends on the valence (i.e., goodness or badness) of anticipated beliefs. Five experiments (n = 2,361) test and find support for these hypotheses, looking at neutrally valenced as well as ego-relevant information. People are indeed more inclined to acquire information (a) when it feels more important, even if it cannot aid decision making (Experiments 1A and 2A); (b) when a question is more salient, manipulated through time lag (Experiments 1B and 2B); and (c) when anticipated beliefs have higher valence (Experiment 2C).

This paper was accepted by Yan Chen, behavioral economics and decision analysis.},
	urldate = {2022-05-30},
	journal = {Management Science},
	author = {Golman, Russell and Loewenstein, George and Molnar, Andras and Saccardo, Silvia},
	month = dec,
	year = {2021},
	note = {Publisher: INFORMS},
	keywords = {curiosity, information gap, motivated attention, ostrich effect},
}

@incollection{kahneman_prospect_2012,
	series = {World {Scientific} {Handbook} in {Financial} {Economics} {Series}},
	title = {Prospect {Theory}: {An} {Analysis} of {Decision} {Under} {Risk}},
	volume = {Volume 4},
	isbn = {978-981-4417-34-1},
	shorttitle = {Prospect {Theory}},
	url = {https://www.worldscientific.com/doi/abs/10.1142/9789814417358_0006},
	number = {Volume 4},
	urldate = {2022-05-30},
	booktitle = {Handbook of the {Fundamentals} of {Financial} {Decision} {Making}},
	publisher = {WORLD SCIENTIFIC},
	author = {Kahneman, Daniel and Tversky, Amos},
	month = jun,
	year = {2012},
	doi = {10.1142/9789814417358_0006},
	pages = {99--127},
}

@misc{noauthor_responsiveness_2022,
	title = {Responsiveness to feedback as a personal trait {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/s11166-018-9277-3},
	urldate = {2022-05-30},
	month = may,
	year = {2022},
}

@article{snow_ambiguity_2011,
	title = {Ambiguity aversion and the propensities for self-insurance and self-protection},
	volume = {42},
	issn = {1573-0476},
	url = {https://doi.org/10.1007/s11166-010-9112-y},
	doi = {10.1007/s11166-010-9112-y},
	abstract = {Two models of ambiguity preferences that permit comparative statics analysis of greater ambiguity aversion yield definite predictions concerning propensities for self-insurance and self-protection: The levels of both activities that are optimal for an ambiguity-averse decision maker are higher in the presence of ambiguity than in its absence, and demands for both activities increase with greater ambiguity aversion. The reason is that, at levels optimal for one decision maker, an increase in either activity results in a mean-preserving contraction in the distribution of expected utility in the presence of ambiguity, which is valuable to anyone with the same risk preferences who is more ambiguity averse.},
	language = {en},
	number = {1},
	urldate = {2022-05-30},
	journal = {Journal of Risk and Uncertainty},
	author = {Snow, Arthur},
	month = feb,
	year = {2011},
	note = {Number: 1},
	keywords = {D80, D81, Greater ambiguity aversion, Non-expected utility, Second-order probability},
	pages = {27--43},
}

@article{grether_testing_1992,
	title = {Testing bayes rule and the representativeness heuristic: {Some} experimental evidence},
	volume = {17},
	issn = {0167-2681},
	shorttitle = {Testing bayes rule and the representativeness heuristic},
	url = {https://www.sciencedirect.com/science/article/pii/016726819290078P},
	doi = {10.1016/0167-2681(92)90078-P},
	abstract = {The psychological literature has identified a number of heuristics which individuals may use in making judgements or choices under uncertainty. Mathematically equivalent problems may be treated differently depending upon details of the decision setting. The results presented in this paper are consistent with those findings. In equivalent problems subjects appear to adopt different strategies in response to observing different data. Some experiments included financial incentives for accuracy and some did not. The majority of subjects in both treatments behaved reasonably, but of those lacking financial incentives a larger proportion gave absurd responses. This suggests that data from decision experiments in which no financial incentives were should be treated as possibly contaminated and statistical methods robust against outliers employed.},
	language = {en},
	number = {1},
	urldate = {2022-05-30},
	journal = {Journal of Economic Behavior \& Organization},
	author = {Grether, David M.},
	month = jan,
	year = {1992},
	note = {Number: 1},
	pages = {31--57},
}

@article{karni_mechanism_2009-1,
	title = {A {Mechanism} for {Eliciting} {Probabilities}},
	volume = {77},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/40263877},
	abstract = {This paper describes a direct revelation mechanism for eliciting agents' subjective probabilities. The game induced by the mechanism has a dominant strategy equilibrium in which the players reveal their subjective probabilities.},
	number = {2},
	urldate = {2022-05-30},
	journal = {Econometrica},
	author = {Karni, Edi},
	year = {2009},
	note = {Number: 2
Publisher: [Wiley, The Econometric Society]},
	pages = {603--606},
}

@article{karni_mechanism_2009-2,
	title = {A {Mechanism} for {Eliciting} {Probabilities}},
	volume = {77},
	url = {https://ideas.repec.org/a/ecm/emetrp/v77y2009i2p603-606.html},
	abstract = {This paper describes a direct revelation mechanism for eliciting agents' subjective probabilities. The game induced by the mechanism has a dominant strategy equilibrium in which the players reveal their subjective probabilities. Copyright 2009 The Econometric Society.},
	language = {en},
	number = {2},
	urldate = {2022-05-30},
	journal = {Econometrica},
	author = {Karni, Edi},
	year = {2009},
	note = {Number: 2
Publisher: Econometric Society},
	pages = {603--606},
}

@article{schotter_belief_2014-2,
	title = {Belief {Elicitation} in the {Laboratory}},
	volume = {6},
	url = {https://doi.org/10.1146/annurev-economics-080213-040927},
	doi = {10.1146/annurev-economics-080213-040927},
	abstract = {One constraint we face as economists is not being able to observe all the relevant variables required to test our theories or make policy prescriptions. Laboratory techniques allow us to convert many variables (such as beliefs) that are unobservable in the field into observables. This article presents a survey of the literature on belief elicitation in laboratory experimental economics. We discuss several techniques available to elicit beliefs in an incentive-compatible manner and the problems involved in their use. We then look at how successful these techniques have been when employed in laboratory studies. We find that despite some problems, beliefs elicited in the laboratory are meaningful (i.e., they are generally used as the basis for behavior), and the process of eliciting beliefs seems not to be too intrusive. One hope for the future is that by eliciting beliefs, we may be able to develop better theories of belief formation.},
	number = {1},
	urldate = {2022-05-30},
	journal = {Annual Review of Economics},
	author = {Schotter, Andrew and Trevino, Isabel},
	year = {2014},
	note = {Number: 1
\_eprint: https://doi.org/10.1146/annurev-economics-080213-040927},
	keywords = {decision theory, experiments},
	pages = {103--128},
}

@article{mobius_managing_2022,
	title = {Managing {Self}-{Confidence}: {Theory} and {Experimental} {Evidence}},
	issn = {0025-1909},
	shorttitle = {Managing {Self}-{Confidence}},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2021.4294},
	doi = {10.1287/mnsc.2021.4294},
	abstract = {We use a series of experiments to understand whether and how people’s beliefs about their own abilities are biased relative to the Bayesian benchmark and how these beliefs then affect behavior. We find that subjects systematically and substantially overweight positive feedback relative to negative (asymmetry) and also update too little overall (conservatism). These biases are substantially less pronounced in an ego-free control experiment. Updating does retain enough of the structure of Bayes’ rule to let us model it coherently in an optimizing framework, in which, interestingly, asymmetry and conservatism emerge as complementary biases. We also find that exogenous changes in beliefs affect subjects’ decisions to enter into a competition and do so similarly for more and less biased subjects, suggesting that people cannot “undo” their biases when the time comes to decide.

This paper was accepted by Axel Ockenfels, behavioral economics and decision analysis.},
	urldate = {2022-05-30},
	journal = {Management Science},
	author = {Möbius, Markus M. and Niederle, Muriel and Niehaus, Paul and Rosenblat, Tanya S.},
	month = mar,
	year = {2022},
	note = {Publisher: INFORMS},
	keywords = {asymmetric belief updating, conservatism, information aversion, overconfidence},
}

@article{ortoleva_modeling_2012,
	title = {Modeling the {Change} of {Paradigm}: {Non}-{Bayesian} {Reactions} to {Unexpected} {News}},
	volume = {102},
	issn = {0002-8282},
	shorttitle = {Modeling the {Change} of {Paradigm}},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.102.6.2410},
	doi = {10.1257/aer.102.6.2410},
	abstract = {Bayes' rule has two well-known limitations: 1) it does not model the
reaction to zero-probability events; 2) a sizable empirical evidence documents systematic violations of it. We characterize axiomatically an alternative updating rule, the Hypothesis Testing model. According
to it, the agent follows Bayes' rule if she receives information to which she assigned a probability above a threshold. Otherwise, she looks at a prior over priors, updates it using Bayes' rule for second-order
priors, and chooses the prior to which the updated prior over priors assigns the highest likelihood. We also present an application to equilibrium refinement in game theory. (JEL D11, D81, D83)},
	language = {en},
	number = {6},
	urldate = {2022-05-30},
	journal = {American Economic Review},
	author = {Ortoleva, Pietro},
	month = may,
	year = {2012},
	note = {Number: 6},
	keywords = {Belief, Communication, Consumer Economics: Theory, Criteria for Decision-Making under Risk and Uncertainty, Search, Information and Knowledge, Learning},
	pages = {2410--2436},
}

@article{holt_update_2009,
	series = {"{Individual} {Decision}-{Making}, {Bayesian} {Estimation} and {Market} {Design}: {A} {Festschrift} in honor of {David} {Grether}"},
	title = {An update on {Bayesian} updating},
	volume = {69},
	issn = {0167-2681},
	url = {https://www.sciencedirect.com/science/article/pii/S0167268108001753},
	doi = {10.1016/j.jebo.2007.08.013},
	abstract = {This paper reports an experiment in which subjects are asked to assess probabilities for unknown events, with treatments that vary the extremity of the prior information. Probabilities are elicited using a Becker–DeGroot–Marshak procedure that does not depend on assumptions about risk aversion. The focus is on the pattern of biases in information processing.},
	language = {en},
	number = {2},
	urldate = {2022-05-30},
	journal = {Journal of Economic Behavior \& Organization},
	author = {Holt, Charles A. and Smith, Angela M.},
	month = feb,
	year = {2009},
	note = {Number: 2},
	keywords = {Probability weighting, Baye's rule, Laboratory experiments},
	pages = {125--134},
}

@techreport{falk_beliefs_2016,
	title = {Beliefs and {Utility}: {Experimental} {Evidence} on {Preferences} for {Information}},
	shorttitle = {Beliefs and {Utility}},
	url = {https://ideas.repec.org/p/ces/ceswps/_6061.html},
	abstract = {Beliefs are a central determinant of behavior. Recent models assume that beliefs about or the anticipation of future consumption have direct utilityconsequences. This gives rise to informational preferences, i.e., preferences over the timing and structure of information. Using a novel and purposefully simple set-up, we experimentally analyze preferences for information along four dimensions. We find evidence that the majority of subjects prefers receiving information sooner. This preference, however, is not uniform but depends on context. When the environment allows subjects to not focus attention on (negative) consumption events, later information becomes more attractive. We also identify an aversion towards piecemeal information. Variations in prior distributions do not seem to affect information preferences.},
	language = {en},
	number = {6061},
	urldate = {2022-05-30},
	institution = {CESifo},
	author = {Falk, Armin and Zimmermann, Florian},
	year = {2016},
	note = {Issue: 6061
Publication Title: CESifo Working Paper Series},
	keywords = {experiments, anticipatory utility, attention, beliefs, information preferences, news utility, reference-dependent preferences},
}

@article{baillon_testing_2015,
	title = {Testing {Ambiguity} {Models} through the {Measurement} of {Probabilities} for {Gains} and {Losses}},
	volume = {7},
	issn = {1945-7669},
	url = {https://www.aeaweb.org/articles?id=10.1257/mic.20130196},
	doi = {10.1257/mic.20130196},
	abstract = {This paper reports on two experiments that test the descriptive validity of ambiguity models using a natural source of uncertainty (the evolution of stock indices) and both gains and losses. We observed violations of probabilistic sophistication, violations that imply a fourfold pattern of ambiguity attitudes: ambiguity aversion for likely gains and unlikely losses and ambiguity seeking for unlikely gains and likely losses. Our data are most consistent with prospect theory and, to a lesser extent, α-maxmin expected utility and Choquet expected utility. Models with uniform ambiguity attitudes are inconsistent with most of the observed behavioral patterns. (JEL D81, D83, G11, G12, G14)},
	language = {en},
	number = {2},
	urldate = {2022-05-30},
	journal = {American Economic Journal: Microeconomics},
	author = {Baillon, Aurélien and Bleichrodt, Han},
	month = apr,
	year = {2015},
	note = {Number: 2},
	keywords = {Belief, Communication, Information and Knowledge, Learning, Bond Interest Rates, Information and Market Efficiency, Criteria for Decision-Making under Risk and Uncertainty, Search, Event Studies, Insider Trading, Investment Decisions, Asset Pricing, Trading Volume, Unawareness, Portfolio Choice},
	pages = {77--100},
}

@article{healy_explaining_nodate,
	title = {{EXPLAINING} {THE} {BDM}—{OR} {ANY} {RANDOM} {BINARY} {CHOICE} {ELICITATION} {MECHANISM}—{TO} {SUBJECTS}},
	language = {en},
	author = {Healy, Paul J},
	pages = {10},
}

@article{kruse_valuing_2003,
	title = {Valuing low probability risk: survey and experimental evidence},
	volume = {50},
	issn = {0167-2681},
	shorttitle = {Valuing low probability risk},
	url = {https://www.sciencedirect.com/science/article/pii/S0167268102000392},
	doi = {10.1016/S0167-2681(02)00039-2},
	abstract = {This study uses a survey question and an economics experiment to elicit the value of a risk mitigation investment. For 93 subjects (48 males and 45 females) the responses to hypothetical questions are compared with a risk mitigation decision that has a salient outcome. We find no gender-differentiated responses to either the maximum accepted price in the economics experiment or hypothetical willingness to pay questions from the survey. In our design, the two procedures generate aggregate measures that were in close agreement, however individual decisions were seldom consistent.},
	language = {en},
	number = {4},
	urldate = {2022-05-30},
	journal = {Journal of Economic Behavior \& Organization},
	author = {Kruse, Jamie Brown and Thompson, Mark A},
	month = apr,
	year = {2003},
	note = {Number: 4},
	keywords = {Risk mitigation, Experiment, Gender, Low probability risk, Survey},
	pages = {495--505},
}

@article{schade_protecting_2012,
	title = {Protecting {Against} {Low}-{Probability} {Disasters}: {The} {Role} of {Worry}},
	volume = {25},
	issn = {08943257},
	shorttitle = {Protecting {Against} {Low}-{Probability} {Disasters}},
	url = {https://repub.eur.nl/pub/26503/},
	doi = {10.1002/bdm.754},
	abstract = {We carry out a large monetary stakes insurance experiment with very small probabilities of losses and ambiguous as well as exact probabilities. Many individuals do not want to pay anything for insurance whether the probabilities are given exactly or are ambiguous. Many others, however, are willing to pay surprisingly large amounts. With ambiguity, the percentage of those paying nothing is smaller and the willingness to pay (WTP) of the other individuals larger than with exact probabilities. Comparing elasticities with ambiguity, we find that worry is much more important than subjective probability in determining WTP for insurance. Furthermore, when the ambiguous loss probability is increased by a factor of 1000, it has almost no effect on WTP.},
	language = {en},
	number = {5},
	urldate = {2022-05-30},
	journal = {Journal of Behavioral Decision Making},
	author = {Schade, Christian and Kunreuther, Howard and Koellinger, Philipp},
	month = dec,
	year = {2012},
	note = {Number: 5},
	pages = {534--543},
}

@article{schade_protecting_2012-1,
	title = {Protecting {Against} {Low}-{Probability} {Disasters}: {The} {Role} of {Worry}},
	volume = {25},
	shorttitle = {Protecting {Against} {Low}-{Probability} {Disasters}},
	url = {https://repository.upenn.edu/bepp_papers/34},
	doi = {10.1002/bdm.754},
	number = {5},
	journal = {Journal of Behavioral Decision Making},
	author = {Schade, Christian and Kunreuther, Howard and Koellinger, Philipp},
	month = dec,
	year = {2012},
	note = {Number: 5},
	pages = {534--543},
}

@article{laury_insurance_2009,
	title = {Insurance decisions for low-probability losses},
	volume = {39},
	issn = {1573-0476},
	url = {https://doi.org/10.1007/s11166-009-9072-2},
	doi = {10.1007/s11166-009-9072-2},
	abstract = {It is widely accepted that individuals tend to underinsure against low-probability, high-loss events relative to high-probability, low-loss events. This conventional wisdom is based largely on field studies, as there is very little experimental evidence. We reexamine this issue with an experiment that accounts for possible confounds in prior insurance experiments. Our results are counter to the prior experimental evidence, as we observe subjects buying more insurance for lower-probability events than for higher-probability events, given a constant expected loss and load factor. Insofar as underinsurance for catastrophic risk is observed in the field, our results suggest that this can be attributed to factors other than only the relative probability of the loss events.},
	language = {en},
	number = {1},
	urldate = {2022-05-30},
	journal = {Journal of Risk and Uncertainty},
	author = {Laury, Susan K. and McInnes, Melayne Morgan and Swarthout, J. Todd},
	month = aug,
	year = {2009},
	note = {Number: 1},
	keywords = {Experiments, C91, D80, Insurance, Low-probability hazards, Risk},
	pages = {17--44},
}

@article{shafran_self-protection_2011,
	title = {Self-protection against repeated low probability risks},
	volume = {42},
	issn = {1573-0476},
	url = {https://doi.org/10.1007/s11166-011-9116-2},
	doi = {10.1007/s11166-011-9116-2},
	abstract = {This paper reports the results of experiments designed to test the effect of experience on preferences for self-protection against low and high probability losses. Subjects gained experience by repeatedly making choices about whether or not to invest in a protective activity and then observing the result of their choice. Half of the subjects faced a low probability risk while the other half faced a higher probability risk with the severity of loss scaled down to hold expected value constant. Protection was more common against the high probability risk. Despite receiving full information about the risks in advance, most subjects made choices in response to prior outcomes. This led to a great deal of experimentation when losses were common (the high probability risk) but very little experimentation when losses were infrequent (the low probability risk).},
	language = {en},
	number = {3},
	urldate = {2022-05-30},
	journal = {Journal of Risk and Uncertainty},
	author = {Shafran, Aric P.},
	month = jun,
	year = {2011},
	note = {Number: 3},
	keywords = {Risk mitigation, Experiments, C91, D81, Low probability risks, Self-protection},
	pages = {263--285},
}

@article{meyer_failing_2012,
	title = {Failing to learn from experience about catastrophes: {The} case of hurricane preparedness},
	volume = {45},
	issn = {1573-0476},
	shorttitle = {Failing to learn from experience about catastrophes},
	url = {https://doi.org/10.1007/s11166-012-9146-4},
	doi = {10.1007/s11166-012-9146-4},
	abstract = {This paper explores the question of whether there are inherent limits to our ability to learn from experience about the value of protection against low-probability, high-consequence, events. Findings are reported from two controlled experiments in which participants have a monetary incentive to learn from experience making investments to protect against hurricane risks. A central finding is that investments display a short-term forgetting effect consistent with the use of reinforcement learning rules, where a significant driver of investments in a given period is whether storm losses were incurred in the precious period. Given the relative rarity of such losses, this reinforcement process produces a mean investment level below that which would be optimal for most storm threats. Investments are also found to be insensitive to the censoring effect of protection itself, implying that the size of experienced losses—rather than losses that are avoided—is the primary driver of investment decisions.},
	language = {en},
	number = {1},
	urldate = {2022-05-30},
	journal = {Journal of Risk and Uncertainty},
	author = {Meyer, Robert J.},
	month = aug,
	year = {2012},
	note = {Number: 1},
	keywords = {Natural disasters, D8, D9, Decision making under uncertainty, Learning from experience, Q5},
	pages = {25--50},
}

@article{camerer_decision_1989,
	title = {Decision {Processes} for {Low} {Probability} {Events}: {Policy} {Implications}},
	volume = {8},
	issn = {0276-8739},
	shorttitle = {Decision {Processes} for {Low} {Probability} {Events}},
	url = {https://www.jstor.org/stable/3325045},
	doi = {10.2307/3325045},
	abstract = {This survey describes the impact of judgements and choices about low probability, high consequence events on the policymaking process. Empirical evidence indicates that normative models of choice, such as expected utility theory, are inadequate descriptions of individual choices. The ambiguity of low probabilities also affects decisions in ways that are not normative. Further, people exhibit biases in judgments about risks and probabilities. These findings have stimulated development of new theories, such as prospect theory and generalized utility theories incorporating attributes such as regret. The authors survey many of these empirical results and explore their implications for policy. They consider the role of information, economic incentives, compensation, and regulation in inducing socially desirable effects through the reframing of outcomes. They suggest that surveys and experiments can help analysts better understand the decision process for low probability events and design more effective public policies.},
	number = {4},
	urldate = {2022-05-30},
	journal = {Journal of Policy Analysis and Management},
	author = {Camerer, Colin F. and Kunreuther, Howard},
	year = {1989},
	note = {Number: 4
Publisher: [Wiley, Association for Public Policy Analysis and Management]},
	pages = {565--592},
}

@article{schoemaker_experimental_1979,
	title = {An {Experimental} {Study} of {Insurance} {Decisions}},
	volume = {46},
	issn = {0022-4367},
	url = {https://www.jstor.org/stable/252533},
	doi = {10.2307/252533},
	abstract = {This paper describes an experimental survey of insurance preferences, administered to college students and clients of an insurance agency. Expected utility theory is contrasted with prospect theory, a recently developed alternative model of choice. The results lend more support to prospect theory than utility theory. However, insurance decisions appear more complex than either model suggests. The findings support earlier field and laboratory studies highlighting people's limited abilities to process information. Further research is needed to understand better the influence of financial status, statistical knowledge, cognitive style, and context and format effects on insurance purchasing decisions.},
	number = {4},
	urldate = {2022-05-30},
	journal = {The Journal of Risk and Insurance},
	author = {Schoemaker, Paul J. H. and Kunreuther, Howard C.},
	year = {1979},
	note = {Number: 4
Publisher: [American Risk and Insurance Association, Wiley]},
	pages = {603--618},
}

@article{richter_behavioral_2014,
	title = {Behavioral insurance: {Theory} and experiments},
	volume = {48},
	issn = {1573-0476},
	shorttitle = {Behavioral insurance},
	url = {https://doi.org/10.1007/s11166-014-9188-x},
	doi = {10.1007/s11166-014-9188-x},
	abstract = {“Risk and insurance” provides an illustrative set of decisions made in the presence of uncertainty. As behavioral models become more integrated into economics and finance, many of their effects are illustrated quite well within insurance markets. Especially noteworthy are the complementary roles of theory and experiments. This article reviews the interactive role of experiments and theory in analyzing insurance demand from a behavioral perspective. We pay special attention to several models of underinvestment in insurance or in other risk-mitigation markets.},
	language = {en},
	number = {2},
	urldate = {2022-05-30},
	journal = {Journal of Risk and Uncertainty},
	author = {Richter, Andreas and Schiller, Jörg and Schlesinger, Harris},
	month = apr,
	year = {2014},
	note = {Number: 2},
	keywords = {C91, D81, Non-expected utility, Adverse selection, Ambiguity aversion, Annuity puzzle, Behavioral economics, Catastrophe insurance, D03, D11, D14, D82, D91, G22, Genetic tests, I12, Inequality aversion, Laboratory experiment, Loss aversion},
	pages = {85--96},
}

@article{volkman-wise_representativeness_2015,
	title = {Representativeness and managing catastrophe risk},
	volume = {51},
	issn = {1573-0476},
	url = {https://doi.org/10.1007/s11166-015-9230-7},
	doi = {10.1007/s11166-015-9230-7},
	abstract = {The representative heuristic causes individuals to underweight prior probabilities and overweight posterior probabilities. We examine the effect of the representative heuristic on the demand for insurance and participation in mitigation activities. Pre-disaster, the representative heuristic leads to lower demand for insurance, even for a subsidized policy; indeed zero coverage may be optimal for a subsidized policy. After a disaster occurs, the heuristic causes individuals to demand more insurance than those not subject to the heuristic, even if policies are unfairly priced. We depict the subsidization needed prior to a disaster to induce individuals to purchase insurance and show the level of unfair pricing that can be tolerated post-disaster. Similarly, the heuristic causes individuals to have a lower willingness to pay for mitigation activities pre-disaster, relative to an individual not subject to the heuristic. Post-disaster the heuristic causes willingness to pay for mitigation to be higher.},
	language = {en},
	number = {3},
	urldate = {2022-05-30},
	journal = {Journal of Risk and Uncertainty},
	author = {Volkman-Wise, Jacqueline},
	month = dec,
	year = {2015},
	note = {Number: 3},
	keywords = {Probability estimation, D83, D81, G22, Catastrophic risks, Disaster, Insurance demand, Representative heuristic, Risk belief},
	pages = {267--290},
}

@article{harrison_evaluating_2016,
	title = {{EVALUATING} {THE} {EXPECTED} {WELFARE} {GAIN} {FROM} {INSURANCE}},
	volume = {83},
	issn = {0022-4367},
	url = {https://econpapers.repec.org/article/blajrinsu/v_3a83_3ay_3a2016_3ai_3a1_3ap_3a91-120.htm},
	number = {1},
	urldate = {2022-05-30},
	journal = {Journal of Risk \& Insurance},
	author = {Harrison, Glenn and Ng, Jia Min},
	year = {2016},
	note = {Number: 1
Publisher: The American Risk and Insurance Association},
	pages = {91--120},
}

@article{hoffman_how_2016,
	title = {How is {Information} {Valued}? {Evidence} from {Framed} {Field} {Experiments}},
	volume = {126},
	issn = {0013-0133},
	shorttitle = {How is {Information} {Valued}?},
	url = {https://doi.org/10.1111/ecoj.12401},
	doi = {10.1111/ecoj.12401},
	abstract = {Do people buy the right amount of information? In a novel field experiment, businesspeople experts provided guesses about the price and quality of actual websites. Compensation was provided for correct results (high or low). Before answers were revealed, subjects could pay to get a noisy signal. I find that the relationship between subjects’ accuracy and their demand for information is much flatter than would be optimal. Subjects underpay for information when signals are valuable and overpay when signals are less valuable. I also find that subjects exhibit significant overconfidence. However, even when the value of information is adjusted to account for subjects’ overconfidence or subjects’ tendency to sometimes misuse information, subjects underpay when signals are valuable and overpay when signals are less valuable.},
	number = {595},
	urldate = {2022-06-07},
	journal = {The Economic Journal},
	author = {Hoffman, Mitchell},
	month = sep,
	year = {2016},
	note = {Number: 595},
	pages = {1884--1911},
}

@article{ambuehl_belief_2018-1,
	title = {Belief updating and the demand for information},
	volume = {109},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825617302191},
	doi = {10.1016/j.geb.2017.11.009},
	abstract = {How do individuals value noisy information that guides economic decisions? In our laboratory experiment, we find that individuals underreact to increasing the informativeness of a signal, thus undervalue high-quality information, and that they disproportionately prefer information that may yield certainty. Both biases appear to be mainly due to non-standard belief updating. We find that individuals differ consistently in their responsiveness to information – the extent that their beliefs move upon observing signals. Individual parameters of responsiveness to information have explanatory power in two distinct choice environments and are unrelated to proxies for mathematical aptitude.},
	language = {en},
	urldate = {2022-06-08},
	journal = {Games and Economic Behavior},
	author = {Ambuehl, Sandro and Li, Shengwu},
	month = may,
	year = {2018},
	keywords = {Experimental economics, Belief updating, Demand for information, Probability weighting, Responsiveness to information},
	pages = {21--39},
}

@article{kahneman_psychology_1973,
	title = {On the psychology of prediction},
	volume = {80},
	issn = {1939-1471},
	doi = {10.1037/h0034747},
	abstract = {Considers that intuitive predictions follow a judgmental heuristic-representativeness. By this heuristic, people predict the outcome that appears most representative of the evidence. Consequently, intuitive predictions are insensitive to the reliability of the evidence or to the prior probability of the outcome, in violation of the logic of statistical prediction. The hypothesis that people predict by representativeness was supported in a series of studies with both naive and sophisticated university students (N = 871). The ranking of outcomes by likelihood coincided with the ranking by representativeness, and Ss erroneously predicted rare events and extreme values if these happened to be representative. The experience of unjustified confidence in predictions and the prevalence of fallacious intuitions concerning statistical regression are traced to the representativeness heuristic. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Psychological Review},
	author = {Kahneman, Daniel and Tversky, Amos},
	year = {1973},
	note = {Number: 4
Place: US
Publisher: American Psychological Association},
	keywords = {Intuition, Judgment, Prediction, Statistical Probability},
	pages = {237--251},
}

@article{hammerton_case_1973,
	title = {A case of radical probability estimation},
	volume = {101},
	issn = {0022-1015},
	doi = {10.1037/h0035224},
	abstract = {Describes 3 experiments in which housewives (N = 142) estimated the probability (p) of the presence of a disease which had been indicated by diagnostic equipment. Although data given to Ss indicated p   .5, Ss consistently estimated p   .8. Successive trials altered the order of presentation of data and progressively reduced the data given. However, Ss always gave closely similar p values, accompanied by high confidence ratings. 2 hypotheses are examined to account for these findings. A 3rd experiment suggests the conclusion that the most important factor is that Ss import a rigid prior probability from their previous experience and ignore numerical data. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Journal of Experimental Psychology},
	author = {Hammerton, M.},
	year = {1973},
	note = {Number: 2
Place: US
Publisher: American Psychological Association},
	keywords = {Estimation, Experiences (Events), Homemakers, Probability Learning},
	pages = {252--254},
}

@article{lin_willingness_2013,
	title = {Willingness to pay for diagnostic technologies: a review of the contingent valuation literature},
	volume = {16},
	issn = {1524-4733},
	shorttitle = {Willingness to pay for diagnostic technologies},
	doi = {10.1016/j.jval.2013.04.005},
	abstract = {OBJECTIVES: To understand how people value information from diagnostic technologies, we reviewed and analyzed published willingness-to-pay (WTP) studies on the topic.
METHODS: We searched PubMed for English-language articles related to WTP for diagnostic laboratory tests published from 1985 through 2011. We characterized methodological differences across studies, examined individual- and technology-level factors associated with WTP, and summarized median WTP values across different diagnostic tests.
RESULTS: We identified 66 relevant WTP studies. Half focused on oncology, while others analyzed infectious diseases (n = 11, 16.1\%) and obstetric or gynecological conditions (n = 8, 11.7\%), among others. Most laboratory tests included in studies were biological samples/genetic testing (n = 44, 61.1\%) or imaging tests (n = 23, 31.9\%). Approximately one third of the analyses (n = 20, 30.3\%) used discrete-choice questions to elicit WTP values. Higher income, education, disease severity, perceived disease risk, family history, and more accurate tests were in general associated with higher WTP values for diagnostic information. Of the 44 studies with median WTP values available, most reported a median WTP value below \$100. The median WTP value for colon or colorectal cancer screening ranged from below \$100 to over \$1000.
CONCLUSIONS: The contingent valuation literature in diagnostics has grown rapidly, and suggests that many respondents place considerable value on diagnostic information. There exists, however, great variation in studies with respect to the type of technologies and diseases assessed, respondent characteristics, and study methodology. The perceived value of diagnostic technologies is also influenced by the study design and elicitation methods.},
	language = {eng},
	number = {5},
	journal = {Value in Health: The Journal of the International Society for Pharmacoeconomics and Outcomes Research},
	author = {Lin, Pei-Jung and Cangelosi, Michael J. and Lee, David W. and Neumann, Peter J.},
	month = aug,
	year = {2013},
	pmid = {23947973},
	note = {Number: 5},
	keywords = {willingness to pay, Choice Behavior, contingent valuation, Costs and Cost Analysis, Diagnostic Techniques and Procedures, diagnostics, Financing, Personal, Models, Economic, review, Risk Assessment, Severity of Illness Index, Socioeconomic Factors},
	pages = {797--805},
}

@article{liang_acceptability_2003,
	title = {Acceptability of diagnostic tests for breast cancer},
	volume = {79},
	issn = {0167-6806},
	doi = {10.1023/a:1023914612152},
	abstract = {PURPOSE: To assess the acceptability of new non-invasive breast cancer diagnostic tests intended to triage women in need of biopsy.
METHODS: Women who had abnormal screening tests and had been recommended to have a biopsy were invited to receive digital mammography, magnetic resonance imaging (MRI), and nuclear medicine evaluation (Tc-99m-sestamibi scanning) before biopsy. Participants completed a questionnaire about satisfaction and acceptability of the procedures. Satisfaction measured women's overall and test-specific satisfaction. Acceptability was measured by self-reported discomfort, embarrassment and women's preference in terms of willingness to pay to avoid a biopsy.
RESULTS: Women were satisfied with all of the potential diagnostic triage procedures. Most found the tests more comfortable than a routine mammogram (47, 50, and 66\% undergoing MRI, digital mammography, and sestamibi scanning, respectively). Women who provided a response to willingness to pay questions (N = 43) were willing to pay an average of 611 dollars to have a test instead of a biopsy, if the test was as accurate as biopsy. The willingness to pay significantly decreased to 308 dollars if the test only had 95\% accuracy. Those who had prior benign breast disease were less willing to pay for a test with 95\% accuracy than those without this history.
CONCLUSION: Instead of immediate biopsy after an abnormal screening, these results suggest that women would find non-invasive triage tests acceptable, or preferable to biopsy if they were equally accurate or nearly equally accurate as a biopsy. New technologies to diagnose breast cancer should focus on decreasing discomfort as well as increasing test accuracy.},
	language = {eng},
	number = {2},
	journal = {Breast Cancer Research and Treatment},
	author = {Liang, Wenchi and Lawrence, William F. and Burnett, Caroline B. and Hwang, Yi-Ting and Freedman, Matthew and Trock, Bruce J. and Mandelblatt, Jeanne S. and Lippman, Marc E.},
	month = may,
	year = {2003},
	pmid = {12825854},
	note = {Number: 2},
	keywords = {Adult, Aged, Biopsy, Breast Neoplasms, Female, Humans, Magnetic Resonance Imaging, Mammography, Mass Screening, Middle Aged, Patient Acceptance of Health Care, Patient Satisfaction, Prospective Studies, Radiographic Image Enhancement, Radionuclide Imaging, Triage, United States},
	pages = {199--206},
}

@article{gigerenzer_helping_2007,
	title = {Helping {Doctors} and {Patients} {Make} {Sense} of {Health} {Statistics}},
	volume = {8},
	issn = {1529-1006},
	doi = {10.1111/j.1539-6053.2008.00033.x},
	abstract = {Many doctors, patients, journalists, and politicians alike do not understand what health statistics mean or draw wrong conclusions without noticing. Collective statistical illiteracy refers to the widespread inability to understand the meaning of numbers. For instance, many citizens are unaware that higher survival rates with cancer screening do not imply longer life, or that the statement that mammography screening reduces the risk of dying from breast cancer by 25\% in fact means that 1 less woman out of 1,000 will die of the disease. We provide evidence that statistical illiteracy (a) is common to patients, journalists, and physicians; (b) is created by nontransparent framing of information that is sometimes an unintentional result of lack of understanding but can also be a result of intentional efforts to manipulate or persuade people; and (c) can have serious consequences for health. The causes of statistical illiteracy should not be attributed to cognitive biases alone, but to the emotional nature of the doctor-patient relationship and conflicts of interest in the healthcare system. The classic doctor-patient relation is based on (the physician's) paternalism and (the patient's) trust in authority, which make statistical literacy seem unnecessary; so does the traditional combination of determinism (physicians who seek causes, not chances) and the illusion of certainty (patients who seek certainty when there is none). We show that information pamphlets, Web sites, leaflets distributed to doctors by the pharmaceutical industry, and even medical journals often report evidence in nontransparent forms that suggest big benefits of featured interventions and small harms. Without understanding the numbers involved, the public is susceptible to political and commercial manipulation of their anxieties and hopes, which undermines the goals of informed consent and shared decision making. What can be done? We discuss the importance of teaching statistical thinking and transparent representations in primary and secondary education as well as in medical school. Yet this requires familiarizing children early on with the concept of probability and teaching statistical literacy as the art of solving real-world problems rather than applying formulas to toy problems about coins and dice. A major precondition for statistical literacy is transparent risk communication. We recommend using frequency statements instead of single-event probabilities, absolute risks instead of relative risks, mortality rates instead of survival rates, and natural frequencies instead of conditional probabilities. Psychological research on transparent visual and numerical forms of risk communication, as well as training of physicians in their use, is called for. Statistical literacy is a necessary precondition for an educated citizenship in a technological democracy. Understanding risks and asking critical questions can also shape the emotional climate in a society so that hopes and anxieties are no longer as easily manipulated from outside and citizens can develop a better-informed and more relaxed attitude toward their health.},
	language = {eng},
	number = {2},
	journal = {Psychological Science in the Public Interest: A Journal of the American Psychological Society},
	author = {Gigerenzer, Gerd and Gaissmaier, Wolfgang and Kurz-Milcke, Elke and Schwartz, Lisa M. and Woloshin, Steven},
	month = nov,
	year = {2007},
	pmid = {26161749},
	note = {Number: 2},
	pages = {53--96},
}

@article{howard_does_2009,
	title = {Does {Attribute} {Framing} in {Discrete} {Choice} {Experiments} {Influence} {Willingness} to {Pay}? {Results} from a {Discrete} {Choice} {Experiment} in {Screening} for {Colorectal} {Cancer}},
	volume = {12},
	issn = {1098-3015},
	shorttitle = {Does {Attribute} {Framing} in {Discrete} {Choice} {Experiments} {Influence} {Willingness} to {Pay}?},
	url = {https://www.sciencedirect.com/science/article/pii/S1098301510607152},
	doi = {10.1111/j.1524-4733.2008.00417.x},
	abstract = {Objective
Recent reviews of discrete choice methodology identified methodological issues warranting further exploration, including the issue of “framing.” The objective of this study was to conduct a methodological exploration of the effect of attribute framing on marginal rates of substitution (MRS), including willingness to pay (WTP) from a discrete choice experiment (DCE), within the context of colorectal cancer screening preferences.
Methods
The survey, a fractional factorial design of a two-alternative, unlabeled experiment, was mailed to a sample of 1920 subjects in NSW, Australia. Participants were randomized to one of four alternative “frames” of information. Attributes included: accuracy of the test for finding cancers, accuracy of the test for finding large polyps, how good the test is at saying you don't have cancer, cost, dietary and medication restrictions and sample collection. A mixed logit model was used to estimate preferences; MRS between attributes, including WTP, was calculated.
Results
A total of 1157 surveys from 1920 (60.2\%) were returned. Accuracy of the test for finding cancer was most likely to influence choice of test, followed by accuracy of the test for finding large polyps. Under some circumstances, framing of the attributes (e.g., cancers found vs. cancers missed) influenced the relative importance of attributes. Attribute framing significantly influenced estimates of WTP, and benefit: harm trade-offs that were calculated from MRS.
Conclusions
Attribute framing can influence willingness to pay and benefit: harm trade-offs from DCEs. Appropriate design and analysis methods should be explored to further characterize the influence and extent of framing in discrete choice studies.},
	language = {en},
	number = {2},
	urldate = {2022-07-14},
	journal = {Value in Health},
	author = {Howard, Kirsten and Salkeld, Glenn},
	month = mar,
	year = {2009},
	note = {Number: 2},
	keywords = {colorectal cancer, discrete choice experiments, preferences, screening},
	pages = {354--363},
}

@article{bornstein_rationality_2001,
	title = {Rationality in medical decision making: a review of the literature on doctors' decision-making biases},
	volume = {7},
	issn = {1356-1294},
	shorttitle = {Rationality in medical decision making},
	doi = {10.1046/j.1365-2753.2001.00284.x},
	abstract = {The objectives of this study were to describe ways in which doctors make suboptimal diagnostic and treatment decisions, and to discuss possible means of alleviating those biases, using a review of past studies from the psychological and medical decision-making literatures. A number of biases can affect the ways in which doctors gather and use evidence in making diagnoses. Biases also exist in how doctors make treatment decisions once a definitive diagnosis has been made. These biases are not peculiar to the medical domain but, rather, are manifestations of suboptimal reasoning to which people are susceptible in general. None the less, they can have potentially grave consequences in medical settings, such as erroneous diagnosis or patient mismanagement. No surefire methods exist for eliminating biases in medical decision making, but there is some evidence that the adoption of an evidence-based medicine approach or the incorporation of formal decision analytic tools can improve the quality of doctors' reasoning. Doctors' reasoning is vulnerable to a number of biases that can lead to errors in diagnosis and treatment, but there are positive signs that means for alleviating some of these biases are available.},
	language = {eng},
	number = {2},
	journal = {Journal of Evaluation in Clinical Practice},
	author = {Bornstein, B. H. and Emler, A. C.},
	month = may,
	year = {2001},
	pmid = {11489035},
	note = {Number: 2},
	keywords = {Female, Humans, Middle Aged, Attitude of Health Personnel, Bias, Child, Decision Making, Evidence-Based Medicine, Male, Therapeutics},
	pages = {97--107},
}

@article{neumann_willingness--pay_2012,
	title = {Willingness-to-pay for predictive tests with no immediate treatment implications: a survey of {US} residents},
	volume = {21},
	issn = {1099-1050},
	shorttitle = {Willingness-to-pay for predictive tests with no immediate treatment implications},
	doi = {10.1002/hec.1704},
	abstract = {We assessed how much, if anything, people would pay for a laboratory test that predicted their future disease status. A questionnaire was administered via an internet-based survey to a random sample of adult US respondents. Each respondent answered questions about two different scenarios, each of which specified: one of four randomly selected diseases (Alzheimer's, arthritis, breast cancer, or prostate cancer); an ex ante risk of developing the disease (randomly designated 10 or 25\%); and test accuracy (randomly designated perfect or 'not perfectly accurate'). Willingness-to-pay (WTP) was elicited with a double-bounded, dichotomous-choice approach. Of 1463 respondents who completed the survey, most (70-88\%, depending on the scenario) were inclined to take the test. Inclination to take the test was lower for Alzheimer's and higher for prostate cancer compared with arthritis, and rose somewhat with disease prevalence and for the perfect versus imperfect test [Correction made here after initial online publication.]. Median WTP varied from \$109 for the imperfect arthritis test to \$263 for the perfect prostate cancer test. Respondents' preferences for predictive testing, even in the absence of direct treatment consequences, reflected health and non-health related factors, and suggests that conventional cost-effectiveness analyses may underestimate the value of testing.},
	language = {eng},
	number = {3},
	journal = {Health Economics},
	author = {Neumann, Peter J. and Cohen, Joshua T. and Hammitt, James K. and Concannon, Thomas W. and Auerbach, Hannah R. and Fang, Chihui and Kent, David M.},
	month = mar,
	year = {2012},
	pmid = {22271512},
	note = {Number: 3},
	keywords = {Choice Behavior, Financing, Personal, Risk Assessment, Adult, Aged, Breast Neoplasms, Female, Humans, Middle Aged, United States, Male, Aged, 80 and over, Alzheimer Disease, Arthritis, Chronic Disease, Cost-Benefit Analysis, Diagnostic Tests, Routine, Health Surveys, Logistic Models, Prostatic Neoplasms, Risk Factors, Surveys and Questionnaires, Young Adult},
	pages = {238--251},
}

@article{schwartz_enthusiasm_2004,
	title = {Enthusiasm for cancer screening in the {United} {States}},
	volume = {291},
	issn = {1538-3598},
	doi = {10.1001/jama.291.1.71},
	abstract = {CONTEXT: Public health officials, physicians, and disease advocacy groups have worked hard to educate individuals living in the United States about the importance of cancer screening.
OBJECTIVE: To determine the public's enthusiasm for early cancer detection.
DESIGN, SETTING, AND PARTICIPANTS: Survey using a national telephone interview of adults selected by random digit dialing, conducted from December 2001 through July 2002. Five hundred individuals participated (women aged {\textgreater} or =40 years and men aged {\textgreater} or =50 years; without a history of cancer).
MAIN OUTCOME MEASURES: Responses to a survey with 5 modules: a general screening module (eg, value of early detection, total-body computed tomography); and 4 screening test modules: Papanicolaou test; mammography; prostate-specific antigen (PSA) test; and sigmoidoscopy or colonoscopy.
RESULTS: Most adults (87\%) believe routine cancer screening is almost always a good idea and that finding cancer early saves lives (74\% said most or all the time). Less than one third believe that there will be a time when they will stop undergoing routine screening. A substantial proportion believe that an 80-year-old who chose not to be tested was irresponsible: ranging from 41\% with regard to mammography to 32\% for colonoscopy. Thirty-eight percent of respondents had experienced at least 1 false-positive screening test; more than 40\% of these individuals characterized that experience as "very scary" or the "scariest time of my life." Yet, looking back, 98\% were glad they had had the initial screening test. Most had a strong desire to know about the presence of cancer regardless of its implications: two thirds said they would want to be tested for cancer even if nothing could be done; and 56\% said they would want to be tested for what is sometimes termed pseudodisease (cancers growing so slowly that they would never cause problems during the persons lifetime even if untreated). Seventy-three percent of respondents would prefer to receive a total-body computed tomographic scan instead of receiving 1000 dollars in cash.
CONCLUSIONS: The public is enthusiastic about cancer screening. This commitment is not dampened by false-positive test results or the possibility that testing could lead to unnecessary treatment. This enthusiasm creates an environment ripe for the premature diffusion of technologies such as total-body computed tomographic scanning, placing the public at risk of overtesting and overtreatment.},
	language = {eng},
	number = {1},
	journal = {JAMA},
	author = {Schwartz, Lisa M. and Woloshin, Steven and Fowler, Floyd J. and Welch, H. Gilbert},
	month = jan,
	year = {2004},
	pmid = {14709578},
	note = {Number: 1},
	keywords = {Adult, Aged, Female, Humans, Mass Screening, Middle Aged, Patient Acceptance of Health Care, United States, Male, Aged, 80 and over, Health Care Surveys, Neoplasms, Public Opinion, Radiography},
	pages = {71--78},
}

@article{eil_good_2011,
	title = {The {Good} {News}-{Bad} {News} {Effect}: {Asymmetric} {Processing} of {Objective} {Information} about {Yourself}},
	volume = {3},
	issn = {1945-7669},
	shorttitle = {The {Good} {News}-{Bad} {News} {Effect}},
	url = {https://www.aeaweb.org/articles?id=10.1257/mic.3.2.114},
	doi = {10.1257/mic.3.2.114},
	abstract = {We study processing and acquisition of objective information regarding qualities that people care about, intelligence and beauty. Subjects receiving negative feedback did not respect the strength of these signals, were far less predictable in their updating behavior and exhibited an aversion to new information. In response to good news, inference conformed more closely to Bayes' Rule, both in accuracy and precision. Signal direction did not affect updating or acquisition in our neutral control. Unlike past work, our design varied direction and agreement with priors independently. The results indicate that
confirmation bias is driven by direction; confirmation alone had no
effect. (JEL D82, D83)},
	language = {en},
	number = {2},
	urldate = {2022-07-21},
	journal = {American Economic Journal: Microeconomics},
	author = {Eil, David and Rao, Justin M.},
	month = may,
	year = {2011},
	note = {Number: 2},
	keywords = {Belief, Communication, Information and Knowledge, Learning, Asymmetric and Private Information, Search},
	pages = {114--138},
}

@misc{masatlioglu_intrinsic_2017,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Intrinsic {Information} {Preferences} and {Skewness}},
	url = {https://papers.ssrn.com/abstract=3232350},
	doi = {10.2139/ssrn.3232350},
	abstract = {We present experimental results from a broad investigation of intrinsic preferences for information. We examine whether people prefer negatively skewed or positively skewed information structures, and how individual preferences over the skewness and the degree of information relate to one another. The results reveal new insights regarding intrinsic preferences for information, including the possibility that positively skewed information structures may ameliorate information avoidance arising from a desire to preserve hope. We discuss our findings through the lens of existing theories.},
	language = {en},
	urldate = {2022-07-21},
	author = {Masatlioglu, Yusufcan and Orhun, A. Yesim and Raymond, Collin},
	month = sep,
	year = {2017},
	note = {Issue: 3232350},
	keywords = {A. Yesim Orhun, Collin Raymond, Intrinsic Information Preferences and Skewness, SSRN, Yusufcan  Masatlioglu},
}

@article{kocher_let_2014,
	title = {‘{Let} me dream on!’ {Anticipatory} emotions and preference for timing in lotteries},
	volume = {98},
	issn = {0167-2681},
	url = {https://www.sciencedirect.com/science/article/pii/S0167268113003041},
	doi = {10.1016/j.jebo.2013.12.006},
	abstract = {We analyze one of the explanations why people participate in lotteries. Our hypothesis stipulates that part of the value that a unit of money buys in lotteries is consumed before the actual resolution in the form of emotions such as hope. In other words, a person holding a lottery ticket may prefer a delayed resolution of risk due to positive anticipatory emotions. This conjecture is tested in an experiment with real lottery tickets. We show that our theoretical considerations may contribute to explaining empirical puzzles associated with lottery participation, timing of resolution and the spreading of lots over drawings. More specifically, we find that a substantial minority of participants prefer delayed resolution, that anticipated thrill is the main variable explaining this choice, and that emotions actually experienced during the waiting period are indeed predominantly positive and correlated with predictions. Finally, we find that a great majority prefers to ‘spread’ chances, that is, to obtain one ticket for each of two drawings rather than two for the same drawing.},
	language = {en},
	urldate = {2022-07-21},
	journal = {Journal of Economic Behavior \& Organization},
	author = {Kocher, Martin G. and Krawczyk, Michal and van Winden, Frans},
	month = feb,
	year = {2014},
	keywords = {D81, Experiment, Anticipatory emotions, C93, Lotteries},
	pages = {29--40},
}

@article{eliaz_paying_2010,
	title = {Paying for confidence: {An} experimental study of the demand for non-instrumental information},
	volume = {70},
	issn = {0899-8256},
	shorttitle = {Paying for confidence},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825610000229},
	doi = {10.1016/j.geb.2010.01.006},
	abstract = {This paper presents experimental evidence that when individuals are about to make a given decision under risk, they are willing to pay for information on the likelihood that this decision is ex-post optimal, even if this information will not affect their decision. Our findings suggest that this demand for non-instrumental information is caused by what we refer to as a “confidence effect”: the desire to increase one's posterior belief by ruling out “bad news”, even when such news would have no effect on one's decision. We conduct various treatments to show that our subjects' behavior is not likely to be caused by an intrinsic preference for information, failure of backward induction or an attempt to minimize thinking costs.},
	language = {en},
	number = {2},
	urldate = {2022-07-21},
	journal = {Games and Economic Behavior},
	author = {Eliaz, Kfir and Schotter, Andrew},
	month = nov,
	year = {2010},
	note = {Number: 2},
	pages = {304--324},
}

@article{castagnetti_protecting_2022,
	title = {Protecting the ego: {Motivated} information selection and updating},
	volume = {142},
	issn = {0014-2921},
	shorttitle = {Protecting the ego},
	url = {https://www.sciencedirect.com/science/article/pii/S0014292121002786},
	doi = {10.1016/j.euroecorev.2021.104007},
	abstract = {We investigate whether individuals self-select feedback that allows them to maintain their motivated beliefs. In our lab experiment, subjects can choose the information structure that gives them feedback regarding their rank in the IQ distribution (ego-relevant treatment) or regarding a random number (control). Although beliefs are incentivized, individuals are less likely to select the most informative feedback in the ego-relevant treatment. Instead, many individuals select information structures in which negative feedback is less salient. When receiving negative feedback with lower salience subjects update their beliefs less, but only in the ego-relevant treatment and not in the control. Hence, our results suggest that individuals sort themselves into information structures that allow them to misinterpret negative feedback in a self-serving way. Consequently, subjects in the IQ treatment remain on average overconfident despite receiving feedback.},
	language = {en},
	urldate = {2022-07-21},
	journal = {European Economic Review},
	author = {Castagnetti, Alessandro and Schmacker, Renke},
	month = feb,
	year = {2022},
	keywords = {Overconfidence, Information acquisition, Motivated beliefs, Updating},
	pages = {104007},
}

@article{xu_revealed_nodate,
	title = {Revealed {Preferences} over {Experts} and {Quacks} and {Failures} of {Contingent} {Reasoning}},
	abstract = {In many economic scenarios, people face incomplete information about the payoffrelevant states of the world, and they may resort to different tests (e.g., analysts, medical diagnoses, or psychic octopuses) to obtain information to reduce their risk exposure. This chapter studies how people evaluate and choose tests. Are they able to avoid useless ones (quacks) and identify genuinely useful ones (experts)? Are they over-paying for quacks and under-paying for experts, and why? I develop a novel experiment wherein people face a rich and structured choice set of expert and quack tests and choose their favorite ones through a graphic coloring task. I ﬁnd that people do fail to distinguish experts and quacks on a large scale, and they are over-paying for quacks but accurately paying for experts. These results are not driven by the standard explanations suggested in the literature, including belief updating bias, failure in best-responding, and intrinsic preference over certain information characteristics. Instead, I show that the main culprit is the failure of contingent reasoning in information processing. That is, people cannot correctly foresee how expert and quack tests inﬂuence their decision problems for all contingencies provided by signals. The failure of contingent reasoning underlies many decision problems in behavioral economics and game theory, and this paper provides new implications for these ﬁelds.},
	language = {en},
	author = {Xu, Yan},
	pages = {37},
}

@incollection{benjamin_chapter_2019,
	series = {Handbook of {Behavioral} {Economics} - {Foundations} and {Applications} 2},
	title = {Chapter 2 - {Errors} in probabilistic reasoning and judgment biases},
	volume = {2},
	url = {https://www.sciencedirect.com/science/article/pii/S2352239918300228},
	abstract = {Errors in probabilistic reasoning have been the focus of much psychology research and are among the original topics of modern behavioral economics. This chapter reviews theory and evidence on this topic, with the goal of facilitating more systematic study of belief biases and their integration into economics. The chapter discusses biases in beliefs about random processes, biases in belief updating, the representativeness heuristic as a possible unifying theory, and interactions between biased belief updating and other features of the updating situation. Throughout, I aim to convey how much evidence there is for (and against) each putative bias, and I highlight when and how different biases may be related to each other. The chapter ends by drawing general lessons for when people update too much or too little, reflecting on modeling challenges, pointing to areas of economics to which the biases are relevant, and highlighting some possible directions for future work.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Handbook of {Behavioral} {Economics}: {Applications} and {Foundations} 1},
	publisher = {North-Holland},
	author = {Benjamin, Daniel J.},
	editor = {Bernheim, B. Douglas and DellaVigna, Stefano and Laibson, David},
	month = jan,
	year = {2019},
	doi = {10.1016/bs.hesbe.2018.11.002},
	keywords = {Base-rate neglect, Confirmation bias, Conservatism bias, Gambler's fallacy, Hot hand, Law of Small Numbers, Non-belief in the Law of Large Numbers, Partition dependence, Representativeness heuristic, Sample-size neglect},
	pages = {69--186},
	file = {Full Text:C\:\\Users\\aluga\\Zotero\\storage\\2L8AHFU2\\Benjamin - 2019 - Chapter 2 - Errors in probabilistic reasoning and .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\JUDKVA5J\\S2352239918300228.html:text/html},
}

@misc{noauthor_bayes_nodate,
	title = {Bayes {Rule} as a {Descriptive} {Model}: {The} {Representativeness} {Heuristic}* {\textbar} {The} {Quarterly} {Journal} of {Economics} {\textbar} {Oxford} {Academic}},
	url = {https://academic.oup.com/qje/article-abstract/95/3/537/1934441},
	urldate = {2023-03-29},
	file = {Bayes Rule as a Descriptive Model\: The Representativeness Heuristic* | The Quarterly Journal of Economics | Oxford Academic:C\:\\Users\\aluga\\Zotero\\storage\\NZB5QQE8\\1934441.html:text/html},
}

@article{tversky_judgment_1974,
	title = {Judgment under {Uncertainty}: {Heuristics} and {Biases}},
	volume = {185},
	shorttitle = {Judgment under {Uncertainty}},
	url = {https://www.science.org/doi/10.1126/science.185.4157.1124},
	doi = {10.1126/science.185.4157.1124},
	abstract = {This article described three heuristics that are employed in making judgments under uncertainty: (i) representativeness, which is usually employed when people are asked to judge the probability that an object or event A belongs to class or process B; (ii) availability of instances or scenarios, which is often employed when people are asked to assess the frequency of a class or the plausibility of a particular development; and (iii) adjustment from an anchor, which is usually employed in numerical prediction when a relevant value is available. These heuristics are highly economical and usually effective, but they lead to systematic and predictable errors. A better understanding of these heuristics and of the biases to which they lead could improve judgments and decisions in situations of uncertainty.},
	number = {4157},
	urldate = {2023-03-29},
	journal = {Science},
	author = {Tversky, Amos and Kahneman, Daniel},
	month = sep,
	year = {1974},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1124--1131},
}

@article{tversky_belief_1971,
	title = {Belief in the law of small numbers},
	volume = {76},
	issn = {1939-1455},
	doi = {10.1037/h0031322},
	abstract = {Reports that people have erroneous intuitions about the laws of chance. In particular, they regard a sample randomly drawn from a population as highly representative, I.e., similar to the population in all essential characteristics. The prevalence of the belief and its unfortunate consequences for psychological research are illustrated by the responses of 84 professional psychologists to a questionnaire concerning research decisions. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Psychological Bulletin},
	author = {Tversky, Amos and Kahneman, Daniel},
	year = {1971},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Consequence, Methodology, Statistical Analysis},
	pages = {105--110},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\IX9RBVH8\\1972-01934-001.html:text/html},
}

@article{kahneman_subjective_1972,
	title = {Subjective probability: {A} judgment of representativeness},
	volume = {3},
	issn = {0010-0285},
	shorttitle = {Subjective probability},
	url = {https://www.sciencedirect.com/science/article/pii/0010028572900163},
	doi = {10.1016/0010-0285(72)90016-3},
	abstract = {This paper explores a heuristic—representativeness—according to which the subjective probability of an event, or a sample, is determined by the degree to which it: (i) is similar in essential characteristics to its parent population; and (ii) reflects the salient features of the process by which it is generated. This heuristic is explicated in a series of empirical examples demonstrating predictable and systematic errors in the evaluation of uncertain events. In particular, since sample size does not represent any property of the population, it is expected to have little or no effect on judgment of likelihood. This prediction is confirmed in studies showing that subjective sampling distributions and posterior probability judgments are determined by the most salient characteristic of the sample (e.g., proportion, mean) without regard to the size of the sample. The present heuristic approach is contrasted with the normative (Bayesian) approach to the analysis of the judgment of uncertainty.},
	language = {en},
	number = {3},
	urldate = {2023-03-29},
	journal = {Cognitive Psychology},
	author = {Kahneman, Daniel and Tversky, Amos},
	month = jul,
	year = {1972},
	pages = {430--454},
	file = {ScienceDirect Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\WFTLV42Q\\0010028572900163.html:text/html},
}

@article{green_experiment_1965,
	title = {An {Experiment} in {Probability} {Estimation}},
	volume = {2},
	issn = {0022-2437},
	url = {https://doi.org/10.1177/002224376500200306},
	doi = {10.1177/002224376500200306},
	abstract = {While the activity of marketing research can be fruitfully viewed within a statistical decision theoretic model, relatively little is known concerning the descriptive aspects of how people?managers or consumers?revise probabilities in the light of new information. This paper reports the results of a behavioral study in probability revision, and the implications of these findings for the operational use of decision theoretic concepts in prescriptive and descriptive choice-making models.},
	language = {en},
	number = {3},
	urldate = {2023-03-29},
	journal = {Journal of Marketing Research},
	author = {Green, Paul E. and Halbert, Michael H. and Robinson, Patrick J.},
	month = aug,
	year = {1965},
	note = {Publisher: SAGE Publications Inc},
	pages = {266--273},
}

@article{phillips_conservatism_1966,
	title = {Conservatism in a simple probability inference task},
	volume = {72},
	issn = {0022-1015},
	doi = {10.1037/h0023653},
	abstract = {3 experiments investigated the effects on posterior probability estimates of: (1) prior probabilities, amount of data, and diagnostic impact of the data; (2) payoffs; and (3) response modes. Ss usually behaved conservatively, i.e., the difference between their prior and posterior probability estimates was less than that prescribed by Bayes' theorem. Conservatism was unaffected by prior probabilities, remained constant as the amount of data increased, and decreased as the diagnostic value of each datum decreased. More learning occurred under payoff than under nonpayoff conditions and between-S variance was less under payoff conditions. Estimates were most nearly Bayesian under the (formally inappropriate) linear payoff, but considerable overestimation resulted; the log payoff condition yielded less conservatism than the quadratic payoff. Estimates were most nearly Bayesian when Ss estimated odds on a logarithmic scale. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Journal of Experimental Psychology},
	author = {Phillips, Lawrence D. and Edwards, Ward},
	year = {1966},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Conservatism, Learning, Inference, Probability Judgment},
	pages = {346--354},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\8D2NIAAU\\1966-11887-001.html:text/html},
}

@article{peterson_sensitivity_1965,
	title = {Sensitivity of subjective probability revision},
	volume = {70},
	issn = {0022-1015},
	doi = {10.1037/h0022023},
	abstract = {Ss were required to revise their subjective probabilities of hypotheses as the result of information provided by a datum. Subjective probability revisions were then compared with the corresponding correct revisions as calculated via Bayes' theorem. 2 independent variables, prior odds in favor of a hypothesis and the theoretical impact of the datum, both influenced 2 dependent variables, amount and accuracy of subjective probability revision. These effects were such that variations in subjective probability revision were in the same direction, but of smaller magnitude, than corresponding variations in Bayesian probability change. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Journal of Experimental Psychology},
	author = {Peterson, Cameron R. and Miller, Alan J.},
	year = {1965},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Statistical Probability, Probability Judgment},
	pages = {117--121},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\P3BNHZ9U\\1965-11511-001.html:text/html},
}

@article{edwards_optimal_1965,
	title = {Optimal strategies for seeking information: {Models} for statistics, choice reaction times, and human information processing},
	volume = {2},
	issn = {0022-2496},
	shorttitle = {Optimal strategies for seeking information},
	url = {https://www.sciencedirect.com/science/article/pii/0022249665900076},
	doi = {10.1016/0022-2496(65)90007-6},
	abstract = {Models for optional stopping in statistics are also normative models for tasks in which subjects may purchase risk-reducing information before making a decision. A Bayesian model for optional stopping for the two-hypothesis continuous case is developed; it takes explicit account of cost of information, values of the possible outcomes of the final decision, and prior probabilities of the hypotheses. A nonparametric model for choice reaction times is derived. It makes strong predictions about times and errors; only one quantity in it is not directly observable. A second example uses the model to design and predict results of a binomial information-purchase experiment.},
	language = {en},
	number = {2},
	urldate = {2023-03-29},
	journal = {Journal of Mathematical Psychology},
	author = {Edwards, Ward},
	month = jul,
	year = {1965},
	pages = {312--329},
	file = {ScienceDirect Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\TEIPL9PE\\0022249665900076.html:text/html;Submitted Version:C\:\\Users\\aluga\\Zotero\\storage\\5D346VRW\\Edwards - 1965 - Optimal strategies for seeking information Models.pdf:application/pdf},
}

@misc{noauthor_seeking_nodate,
	title = {Seeking {Information} to {Reduce} the {Risk} of {Decisions} on {JSTOR}},
	url = {https://www.jstor.org/stable/1420490?casa_token=kj9WwI9Rkb4AAAAA%3Alskk75zHyOc_55dq1JNjGYlAyoxxng4dF0J-rYlaCxT0-z7VOVYfd9-4cw1R1v9KoIUWuHjvITmdSNbzyXv3q3qrwuCo4S1XF-DFsM2JFT1rejenzN6H},
	urldate = {2023-03-29},
	file = {Seeking Information to Reduce the Risk of Decisions on JSTOR:C\:\\Users\\aluga\\Zotero\\storage\\XJSG997K\\1420490.html:text/html},
}

@article{phillips_conservatism_1966-1,
	title = {Conservatism in a {Simple} {Probability} {Inference} {Task}},
	volume = {72},
	doi = {10.1037/h0023653},
	number = {3},
	journal = {Journal of Experimental Psychology},
	author = {Phillips, Lawrence D. and Edwards, Ward},
	year = {1966},
	pages = {346},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\8PLBJTZI\\PHICIA.html:text/html},
}

@article{kahneman_psychology_1973-1,
	title = {On the psychology of prediction},
	volume = {80},
	issn = {1939-1471},
	doi = {10.1037/h0034747},
	abstract = {Considers that intuitive predictions follow a judgmental heuristic-representativeness. By this heuristic, people predict the outcome that appears most representative of the evidence. Consequently, intuitive predictions are insensitive to the reliability of the evidence or to the prior probability of the outcome, in violation of the logic of statistical prediction. The hypothesis that people predict by representativeness was supported in a series of studies with both naive and sophisticated university students (N = 871). The ranking of outcomes by likelihood coincided with the ranking by representativeness, and Ss erroneously predicted rare events and extreme values if these happened to be representative. The experience of unjustified confidence in predictions and the prevalence of fallacious intuitions concerning statistical regression are traced to the representativeness heuristic. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Psychological Review},
	author = {Kahneman, Daniel and Tversky, Amos},
	year = {1973},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Intuition, Judgment, Prediction, Statistical Probability},
	pages = {237--251},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\NQPTVWPL\\1974-02325-001.html:text/html},
}

@article{grether_bayes_1980,
	title = {Bayes {Rule} as a {Descriptive} {Model}: {The} {Representativeness} {Heuristic}},
	volume = {95},
	issn = {0033-5533},
	shorttitle = {Bayes {Rule} as a {Descriptive} {Model}},
	url = {https://www.jstor.org/stable/1885092},
	doi = {10.2307/1885092},
	abstract = {Results of experiments designed to test the claim of psychologists that expected utility theory does not provide a good descriptive model are reported. The deviation from tested theory is that, in revising beliefs, individuals ignore prior or base-rate-information contrary to Bayes rule. Flaws in the evidence in the psychological literature are noted, an experiment avoiding these difficulties is designed and carried out, and the psychologists' predictions are stated in terms of a more general model. The psychologists' predictions are confirmed for inexperienced or financially unmotivated subjects, but for others the evidence is less clear.},
	number = {3},
	urldate = {2023-03-29},
	journal = {The Quarterly Journal of Economics},
	author = {Grether, David M.},
	year = {1980},
	note = {Publisher: Oxford University Press},
	pages = {537--557},
	file = {JSTOR Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\VNJJCYI2\\Grether - 1980 - Bayes Rule as a Descriptive Model The Representat.pdf:application/pdf},
}

@techreport{massri_towards_2023,
	address = {Austin, Texas, USA},
	title = {Towards {InnoGraph}: {A} {Knowledge} {Graph} for {AI} {Innovation}},
	shorttitle = {Towards {InnoGraph}},
	url = {https://zenodo.org/record/7750707},
	abstract = {Researchers seeking to comprehend the state-of-the-art innovations in a particular field of study must examine recent patents and scientific articles in that domain. Innovation ecosystems consist of interconnected information about entities such as researchers, institutions, projects, products, and technologies. However, representing such information in a machine-readable format is challenging because concepts like "knowledge" are not easily represented. Nonetheless, even a partial representation of innovation ecosystems provides valuable insights. Therefore, representing innovation ecosystems as knowledge graphs (KGs) would enable advanced data analysis and generate new insights. To this end, we propose InnoGraph, a framework that integrates multiple heterogeneous data sources to build a Knowledge Graph of the worldwide AI innovation ecosystem.},
	language = {eng},
	urldate = {2023-07-14},
	author = {Massri, M.Besher and Spahiu, Blerina and Grobelnik, Marko and Alexiev, Vladimir and Palmonari, Matteo and Roman, Dumitru},
	month = mar,
	year = {2023},
	doi = {10.1145/3543873.3587614},
	keywords = {artificial intelligence, economics knowledge graph, innovation, innovation ecosystem, knowledge graph, science knowledge graph},
	annote = {The work on InnoGraph is partially funded by the projects enRichMyData (HE 101070284), Graph-Massivizer (HE 101093202), DataCloud (H2020 101016835), and BigDataMine (NFR 309691). The original work is inspired by a partnership between OECD and JSI, on the OECD AI Policy Observatory.},
	file = {Zenodo Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\KFFACVZH\\Massri et al. - 2023 - Towards InnoGraph A Knowledge Graph for AI Innova.pdf:application/pdf},
}

@inproceedings{sun_assessing_2022,
	address = {New York, NY, USA},
	series = {{SIGIR} '22},
	title = {Assessing {Scientific} {Research} {Papers} with {Knowledge} {Graphs}},
	isbn = {978-1-4503-8732-3},
	url = {https://dl.acm.org/doi/10.1145/3477495.3531879},
	doi = {10.1145/3477495.3531879},
	abstract = {In recent decades, the growing scale of scientific research has led to numerous novel findings. Reproducing these findings is the foundation of future research. However, due to the complexity of experiments, manually assessing scientific research is laborious and time-intensive, especially in social and behavioral sciences. Although increasing reproducibility studies have garnered increased attention in the research community, there is still a lack of systematic ways for evaluating scientific research at scale. In this paper, we propose a novel approach towards automatically assessing scientific publications by constructing a knowledge graph (KG) that captures a holistic view of the research contributions. Specifically, during the KG construction, we combine information from two different perspectives: micro-level features that capture knowledge from published articles such as sample sizes, effect sizes, and experimental models, and macro-level features that comprise relationships between entities such as authorship and reference information. We then learn low-dimensional representations using language models and knowledge graph embeddings for entities (nodes in KGs), which are further used for the assessments. A comprehensive set of experiments on two benchmark datasets shows the usefulness of leveraging KGs for scoring scientific research.},
	urldate = {2023-07-13},
	booktitle = {Proceedings of the 45th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Kexuan and Qiu, Zhiqiang and Salinas, Abel and Huang, Yuzhong and Lee, Dong-Ho and Benjamin, Daniel and Morstatter, Fred and Ren, Xiang and Lerman, Kristina and Pujara, Jay},
	month = jul,
	year = {2022},
	keywords = {knowledge graph, reproducibility, social and behavioral sciences},
	pages = {2467--2472},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\EQ54HQVB\\Sun et al. - 2022 - Assessing Scientific Research Papers with Knowledg.pdf:application/pdf},
}

@article{manghi_new_2021,
	title = {New trends in scientific knowledge graphs and research impact assessment},
	volume = {2},
	issn = {2641-3337},
	url = {https://direct.mit.edu/qss/article/2/4/1296/108052/New-trends-in-scientific-knowledge-graphs-and},
	doi = {10.1162/qss_e_00160},
	language = {en},
	number = {4},
	urldate = {2023-07-14},
	journal = {Quantitative Science Studies},
	author = {Manghi, Paolo and Mannocci, Andrea and Osborne, Francesco and Sacharidis, Dimitris and Salatino, Angelo and Vergoulis, Thanasis},
	month = dec,
	year = {2021},
	pages = {1296--1300},
	file = {Manghi et al. - 2021 - New trends in scientific knowledge graphs and rese.pdf:C\:\\Users\\aluga\\Zotero\\storage\\BRV7M8SV\\Manghi et al. - 2021 - New trends in scientific knowledge graphs and rese.pdf:application/pdf},
}

@article{deagen_fair_2022,
	title = {{FAIR} and {Interactive} {Data} {Graphics} from a {Scientific} {Knowledge} {Graph}},
	volume = {9},
	copyright = {2022 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-022-01352-z},
	doi = {10.1038/s41597-022-01352-z},
	abstract = {Graph databases capture richly linked domain knowledge by integrating heterogeneous data and metadata into a unified representation. Here, we present the use of bespoke, interactive data graphics (bar charts, scatter plots, etc.) for visual exploration of a knowledge graph. By modeling a chart as a set of metadata that describes semantic context (SPARQL query) separately from visual context (Vega-Lite specification), we leverage the high-level, declarative nature of the SPARQL and Vega-Lite grammars to concisely specify web-based, interactive data graphics synchronized to a knowledge graph. Resources with dereferenceable URIs (uniform resource identifiers) can employ the hyperlink encoding channel or image marks in Vega-Lite to amplify the information content of a given data graphic, and published charts populate a browsable gallery of the database. We discuss design considerations that arise in relation to portability, persistence, and performance. Altogether, this pairing of SPARQL and Vega-Lite—demonstrated here in the domain of polymer nanocomposite materials science—offers an extensible approach to FAIR (findable, accessible, interoperable, reusable) scientific data visualization within a knowledge graph framework.},
	language = {en},
	number = {1},
	urldate = {2023-07-14},
	journal = {Scientific Data},
	author = {Deagen, Michael E. and McCusker, Jamie P. and Fateye, Tolulomo and Stouffer, Samuel and Brinson, L. Cate and McGuinness, Deborah L. and Schadler, Linda S.},
	month = may,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Databases, Materials science, Research management},
	pages = {239},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\UZXLW323\\Deagen et al. - 2022 - FAIR and Interactive Data Graphics from a Scientif.pdf:application/pdf},
}

@article{domingo-fernandez_covid-19_2021,
	title = {{COVID}-19 {Knowledge} {Graph}: a computable, multi-modal, cause-and-effect knowledge model of {COVID}-19 pathophysiology},
	volume = {37},
	issn = {1367-4811},
	shorttitle = {{COVID}-19 {Knowledge} {Graph}},
	doi = {10.1093/bioinformatics/btaa834},
	abstract = {SUMMARY: The COVID-19 crisis has elicited a global response by the scientific community that has led to a burst of publications on the pathophysiology of the virus. However, without coordinated efforts to organize this knowledge, it can remain hidden away from individual research groups. By extracting and formalizing this knowledge in a structured and computable form, as in the form of a knowledge graph, researchers can readily reason and analyze this information on a much larger scale. Here, we present the COVID-19 Knowledge Graph, an expansive cause-and-effect network constructed from scientific literature on the new coronavirus that aims to provide a comprehensive view of its pathophysiology. To make this resource available to the research community and facilitate its exploration and analysis, we also implemented a web application and released the KG in multiple standard formats.
AVAILABILITY AND IMPLEMENTATION: The COVID-19 Knowledge Graph is publicly available under CC-0 license at https://github.com/covid19kg and https://bikmi.covid19-knowledgespace.de.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
	language = {eng},
	number = {9},
	journal = {Bioinformatics (Oxford, England)},
	author = {Domingo-Fernández, Daniel and Baksi, Shounak and Schultz, Bruce and Gadiya, Yojana and Karki, Reagon and Raschka, Tamara and Ebeling, Christian and Hofmann-Apitius, Martin and Kodamullil, Alpha Tom},
	month = jun,
	year = {2021},
	pmid = {32976572},
	pmcid = {PMC7558629},
	keywords = {Humans, COVID-19, Pattern Recognition, Automated, Publications, SARS-CoV-2, Software},
	pages = {1332--1334},
	file = {Full Text:C\:\\Users\\aluga\\Zotero\\storage\\N9PRK4F9\\Domingo-Fernández et al. - 2021 - COVID-19 Knowledge Graph a computable, multi-moda.pdf:application/pdf},
}

@article{auer_improving_2020,
	title = {Improving {Access} to {Scientific} {Literature} with {Knowledge} {Graphs}},
	volume = {44},
	issn = {1865-7648},
	url = {https://www.degruyter.com/document/doi/10.1515/bfp-2020-2042/html?lang=en},
	doi = {10.1515/bfp-2020-2042},
	abstract = {The transfer of knowledge has not changed fundamentally for many hundreds of years: It is usually document-based-formerly printed on paper as a classic essay and nowadays as PDF. With around 2.5 million new research contributions every year, researchers drown in a flood of pseudo-digitized PDF publications. As a result research is seriously weakened. In this article, we argue for representing scholarly contributions in a structured and semantic way as a knowledge graph. The advantage is that information represented in a knowledge graph is readable by machines and humans. As an example, we give an overview on the Open Research Knowledge Graph (ORKG), a service implementing this approach. For creating the knowledge graph representation, we rely on a mixture of manual (crowd/expert sourcing) and (semi-)automated techniques. Only with such a combination of human and machine intelligence, we can achieve the required quality of the representation to allow for novel exploration and assistance services for researchers. As a result, a scholarly knowledge graph such as the ORKG can be used to give a condensed overview on the state-of-the-art addressing a particular research quest, for example as a tabular comparison of contributions according to various characteristics of the approaches. Further possible intuitive access interfaces to such scholarly knowledge graphs include domain-specific (chart) visualizations or answering of natural language questions.},
	language = {en},
	number = {3},
	urldate = {2023-07-14},
	journal = {Bibliothek Forschung und Praxis},
	author = {Auer, Sören and Oelen, Allard and Haris, Muhammad and Stocker, Markus and D’Souza, Jennifer and Farfar, Kheir Eddine and Vogt, Lars and Prinz, Manuel and Wiens, Vitalis and Jaradeh, Mohamad Yaser},
	month = dec,
	year = {2020},
	note = {Publisher: De Gruyter},
	keywords = {crowdsourcing, knowledge graph, semantic web, Subject classification, text mining},
	pages = {516--529},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\AHFLW2B3\\Auer et al. - 2020 - Improving Access to Scientific Literature with Kno.pdf:application/pdf},
}

@article{dessi_scicero_2022,
	title = {{SCICERO}: {A} deep learning and {NLP} approach for generating scientific knowledge graphs in the computer science domain},
	volume = {258},
	issn = {0950-7051},
	shorttitle = {{SCICERO}},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705122010383},
	doi = {10.1016/j.knosys.2022.109945},
	abstract = {Science communication has a number of bottlenecks that include the rising number of published research papers and its non-machine-accessible and document-based paradigm, which makes the exploration, reading, and reuse of research outcomes rather inefficient. Recently, Knowledge Graphs (KG), i.e., semantic interlinked networks of entities, have been proposed as a new core technology to describe and curate scholarly information with the goal to make it machine readable and understandable. However, the main drawback of the use of such a technology is that researchers are asked to manually annotate their research papers and add their contributions within the KGs. To address this problem, in this paper we propose SCICERO, a novel KG generation approach that takes in input text from research articles and generates a KG of research entities. SCICERO uses Natural Language Processing techniques to parse the content of scientific papers to discover entities and relationships, exploits state-of-the-art Deep Learning Transformer models to make sense and validate extracted information, and uses Semantic Web best practices to formally represent the extracted entities and relationships, making the written content of research papers machine-actionable. SCICERO has been tested on a dataset of 6.7M papers about Computer Science generating a KG of about 10M entities. It has been evaluated on a manually generated gold standard of 3,600 triples that cover three Computer Science subdomains (Information Retrieval, Natural Language Processing, and Machine Learning) obtaining remarkable results.},
	language = {en},
	urldate = {2023-07-14},
	journal = {Knowledge-Based Systems},
	author = {Dessí, Danilo and Osborne, Francesco and Reforgiato Recupero, Diego and Buscaldi, Davide and Motta, Enrico},
	month = dec,
	year = {2022},
	keywords = {Artificial intelligence, Knowledge graph, Scholarly domain, Scientific facts},
	pages = {109945},
}

@article{stocker_skg4eosc_2022,
	title = {{SKG4EOSC} - {Scholarly} {Knowledge} {Graphs} for {EOSC}: {Establishing} a backbone of knowledge graphs for {FAIR} {Scholarly} {Information} in {EOSC}},
	volume = {8},
	copyright = {2023 Markus Stocker, Tina Heger, Artur Schweidtmann, Hanna Ćwiek-Kupczyńska, Lyubomir Penev, Milan Dojchinovski, Egon Willighagen, Maria-Esther Vidal, Houcemeddine Turki, Daniel Balliet, Ilaria Tiddi, Tobias Kuhn, Daniel Mietchen, Oliver Karras, Lars Vogt, Sebastian Hellmann, Jonathan Jeschke, Paweł Krajewski, Sören Auer},
	issn = {2367-7163},
	shorttitle = {{SKG4EOSC} - {Scholarly} {Knowledge} {Graphs} for {EOSC}},
	url = {https://riojournal.com/article/83789/},
	doi = {10.3897/rio.8.e83789},
	abstract = {In the age of advanced information systems powering fast-paced knowledge economies that face global societal challenges, it is no longer adequate to express scholarly information - an essential resource for modern economies - primarily as article narratives in document form. Despite being a well-established tradition in scholarly communication, PDF-based text publishing is hindering scientific progress as it buries scholarly information into non-machine-readable formats. The key objective of SKG4EOSC is to improve science productivity through development and implementation of services for text and data conversion, and production, curation, and re-use of FAIR scholarly information. This will be achieved by (1) establishing the Open Research Knowledge Graph (ORKG, orkg.org), a service operated by the SKG4EOSC coordinator, as a Hub for access to FAIR scholarly information in the EOSC; (2) lifting to EOSC of numerous and heterogeneous domain-specific research infrastructures through the ORKG Hub’s harmonized access facilities; and (3) leverage the Hub to support cross-disciplinary research and policy decisions addressing societal challenges. SKG4EOSC will pilot the devised approaches and technologies in four research domains: biodiversity crisis, precision oncology, circular processes, and human cooperation. With the aim to improve machine-based scholarly information use, SKG4EOSC addresses an important current and future need of researchers. It extends the application of the FAIR data principles to scholarly communication practices, hence a more comprehensive coverage of the entire research lifecycle. Through explicit, machine actionable provenance links between FAIR scholarly information, primary data and contextual entities, it will substantially contribute to reproducibility, validation and trust in science. The resulting advanced machine support will catalyse new discoveries in basic research and solutions in key application areas.},
	language = {en},
	urldate = {2023-07-14},
	journal = {Research Ideas and Outcomes},
	author = {Stocker, Markus and Heger, Tina and Schweidtmann, Artur and Ćwiek-Kupczyńska, Hanna and Penev, Lyubomir and Dojchinovski, Milan and Willighagen, Egon and Vidal, Maria-Esther and Turki, Houcemeddine and Balliet, Daniel and Tiddi, Ilaria and Kuhn, Tobias and Mietchen, Daniel and Karras, Oliver and Vogt, Lars and Hellmann, Sebastian and Jeschke, Jonathan and Krajewski, Paweł and Auer, Sören},
	month = mar,
	year = {2022},
	note = {Publisher: Pensoft Publishers},
	pages = {e83789},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\A58GYXBI\\Stocker et al. - 2022 - SKG4EOSC - Scholarly Knowledge Graphs for EOSC Es.pdf:application/pdf},
}

@article{rossanez_kgen_2020,
	title = {{KGen}: a knowledge graph generator from biomedical scientific literature},
	volume = {20},
	issn = {1472-6947},
	shorttitle = {{KGen}},
	url = {https://doi.org/10.1186/s12911-020-01341-5},
	doi = {10.1186/s12911-020-01341-5},
	abstract = {Knowledge is often produced from data generated in scientific investigations. An ever-growing number of scientific studies in several domains result into a massive amount of data, from which obtaining new knowledge requires computational help. For example, Alzheimer’s Disease, a life-threatening degenerative disease that is not yet curable. As the scientific community strives to better understand it and find a cure, great amounts of data have been generated, and new knowledge can be produced. A proper representation of such knowledge brings great benefits to researchers, to the scientific community, and consequently, to society.},
	number = {4},
	urldate = {2023-07-14},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Rossanez, Anderson and dos Reis, Julio Cesar and Torres, Ricardo da Silva and de Ribaupierre, Hélène},
	month = dec,
	year = {2020},
	keywords = {Information Extraction, Knowledge Graphs, Ontologies, RDF Triples},
	pages = {314},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\RCV6ZRM2\\Rossanez et al. - 2020 - KGen a knowledge graph generator from biomedical .pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\S3VF32TT\\s12911-020-01341-5.html:text/html},
}

@article{peng_knowledge_2023,
	title = {Knowledge {Graphs}: {Opportunities} and {Challenges}},
	issn = {0269-2821},
	shorttitle = {Knowledge {Graphs}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10068207/},
	doi = {10.1007/s10462-023-10465-9},
	abstract = {With the explosive growth of artificial intelligence (AI) and big data, it has become vitally important to organize and represent the enormous volume of knowledge appropriately. As graph data, knowledge graphs accumulate and convey knowledge of the real world. It has been well-recognized that knowledge graphs effectively represent complex information; hence, they rapidly gain the attention of academia and industry in recent years. Thus to develop a deeper understanding of knowledge graphs, this paper presents a systematic overview of this field. Specifically, we focus on the opportunities and challenges of knowledge graphs. We first review the opportunities of knowledge graphs in terms of two aspects: (1) AI systems built upon knowledge graphs; (2) potential application fields of knowledge graphs. Then, we thoroughly discuss severe technical challenges in this field, such as knowledge graph embeddings, knowledge acquisition, knowledge graph completion, knowledge fusion, and knowledge reasoning. We expect that this survey will shed new light on future research and the development of knowledge graphs.},
	urldate = {2023-07-14},
	journal = {Artificial Intelligence Review},
	author = {Peng, Ciyuan and Xia, Feng and Naseriparsa, Mehdi and Osborne, Francesco},
	month = apr,
	year = {2023},
	pmid = {37362886},
	pmcid = {PMC10068207},
	pages = {1--32},
	file = {PubMed Central Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\BWF2L7WH\\Peng et al. - 2023 - Knowledge Graphs Opportunities and Challenges.pdf:application/pdf},
}

@misc{brack_citation_2021,
	title = {Citation {Recommendation} for {Research} {Papers} via {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/2106.05633},
	doi = {10.48550/arXiv.2106.05633},
	abstract = {Citation recommendation for research papers is a valuable task that can help researchers improve the quality of their work by suggesting relevant related work. Current approaches for this task rely primarily on the text of the papers and the citation network. In this paper, we propose to exploit an additional source of information, namely research knowledge graphs (KG) that interlink research papers based on mentioned scientific concepts. Our experimental results demonstrate that the combination of information from research KGs with existing state-of-the-art approaches is beneficial. Experimental results are presented for the STM-KG (STM: Science, Technology, Medicine), which is an automatically populated knowledge graph based on the scientific concepts extracted from papers of ten domains. The proposed approach outperforms the state of the art with a mean average precision of 20.6\% (+0.8) for the top-50 retrieved results.},
	urldate = {2023-07-14},
	publisher = {arXiv},
	author = {Brack, Arthur and Hoppe, Anett and Ewerth, Ralph},
	month = jun,
	year = {2021},
	note = {arXiv:2106.05633 [cs]},
	keywords = {Computer Science - Digital Libraries, Computer Science - Information Retrieval},
	annote = {Comment: Accepted for publication in 25th International Conference on Theory and Practice of Digital Libraries (TPDL), 2021},
	file = {arXiv Fulltext PDF:C\:\\Users\\aluga\\Zotero\\storage\\FY6444SA\\Brack et al. - 2021 - Citation Recommendation for Research Papers via Kn.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\4BVSW3T7\\2106.html:text/html},
}

@misc{noauthor_open_nodate-1,
	title = {Open {Academic} {Graph}},
	url = {https://www.microsoft.com/en-us/research/project/open-academic-graph/},
	abstract = {Open Academic Graph (OAG) is a large knowledge graph unifying two billion-scale academic graphs: Microsoft Academic Graph (MAG) and AMiner. In mid 2017, we published OAG v1, which contains 166,192,182 papers from MAG and 154,771,162 papers from AMiner (see below) and generated 64,639,608 linking (matching) relations between the two graphs. This time, in OAG v2, author, venue and […]},
	language = {en-US},
	urldate = {2023-07-14},
	journal = {Microsoft Research},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\SKVYZTIN\\open-academic-graph.html:text/html},
}

@misc{noauthor_get_nodate,
	title = {Get started - {ORKG}},
	url = {https://orkg.org/about/14/Get_started},
	language = {en},
	urldate = {2023-07-14},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\9U47KA4Q\\Get_started.html:text/html},
}

@techreport{manghi_openaire_2019,
	title = {The {OpenAIRE} {Research} {Graph} {Data} {Model}},
	url = {https://zenodo.org/record/2643199},
	abstract = {The purpose of the European OpenAIRE infrastructure is  to facilitate, foster, support, and monitor Open Science scholarly communication in Europe. The  infrastructure has been operational for almost a decade and successful in linking people,  ideas and resources in support of the free flow, access, sharing, and re-use of research outcomes. To this aim it offers dissemination and training on Open Access and Open Science, facilitates exchange of knowledge, and operates the  technical services required to facilitate and monitor Open Science publishing trends and research impact across geographic and discipline boundaries. OpenAIRE services populate a research graph whose objects are scientific results, organizations, funders, communities, organizations, and data sources. In this article we describe the data model, inspired by several existing metadata standards.},
	language = {eng},
	urldate = {2023-07-14},
	institution = {Zenodo},
	author = {Manghi, Paolo and Bardi, Alessia and Atzori, Claudio and Baglioni, Miriam and Manola, Natalia and Schirrwagen, Jochen and Principe, Pedro},
	month = apr,
	year = {2019},
	doi = {10.5281/zenodo.2643199},
	keywords = {Monitoring, Open Science, OpenAIRE, Research Graph},
	file = {Zenodo Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\7RI3AYYR\\Manghi et al. - 2019 - The OpenAIRE Research Graph Data Model.pdf:application/pdf},
}

@incollection{jaradeh_open_2019,
	title = {Open {Research} {Knowledge} {Graph}:{A} {System} {Walkthrough}},
	volume = {11799},
	shorttitle = {Open {Research} {Knowledge} {Graph}},
	url = {http://arxiv.org/abs/2206.01439},
	abstract = {Despite improved digital access to scholarly literature in the last decades, the fundamental principles of scholarly communication remain unchanged and continue to be largely document-based. Scholarly knowledge remains locked in representations that are inadequate for machine processing. The Open Research Knowledge Graph (ORKG) is an infrastructure for representing, curating and exploring scholarly knowledge in a machine actionable manner. We demonstrate the core functionality of ORKG for representing research contributions published in scholarly articles. A video of the demonstration and the system are available online.},
	urldate = {2023-07-14},
	author = {Jaradeh, Mohamad Yaser and Oelen, Allard and Prinz, Manuel and Stocker, Markus and Auer, Sören},
	year = {2019},
	doi = {10.1007/978-3-030-30760-8_31},
	note = {arXiv:2206.01439 [cs]},
	keywords = {Computer Science - Digital Libraries},
	pages = {348--351},
	annote = {Comment: Pre-print for TPDL 2019 demo},
	file = {arXiv.org Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\86NSHNAL\\2206.html:text/html;Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\HACVLUXG\\Jaradeh et al. - 2019 - Open Research Knowledge GraphA System Walkthrough.pdf:application/pdf},
}

@inproceedings{samy_graph2feat_2023,
	title = {{Graph2Feat}: {Inductive} {Link} {Prediction} via {Knowledge} {Distillation}},
	shorttitle = {{Graph2Feat}},
	doi = {10.1145/3543873.3587596},
	author = {Samy, Ahmed and Kefato, Zekarias and Girdzijauskas, Sarunas},
	month = apr,
	year = {2023},
	pages = {805--812},
	file = {Full Text:C\:\\Users\\aluga\\Zotero\\storage\\WRQKVTYH\\Samy et al. - 2023 - Graph2Feat Inductive Link Prediction via Knowledg.pdf:application/pdf},
}

@inproceedings{samy_graph2feat_2023-1,
	address = {New York, NY, USA},
	series = {{WWW} '23 {Companion}},
	title = {{Graph2Feat}: {Inductive} {Link} {Prediction} via {Knowledge} {Distillation}},
	isbn = {978-1-4503-9419-2},
	shorttitle = {{Graph2Feat}},
	url = {https://dl.acm.org/doi/10.1145/3543873.3587596},
	doi = {10.1145/3543873.3587596},
	abstract = {Link prediction between two nodes is a critical task in graph machine learning. Most approaches are based on variants of graph neural networks (GNNs) that focus on transductive link prediction and have high inference latency. However, many real-world applications require fast inference over new nodes in inductive settings where no information on connectivity is available for these nodes. Thereby, node features provide an inevitable alternative in the latter scenario. To that end, we propose Graph2Feat, which enables inductive link prediction by exploiting knowledge distillation (KD) through the Student-Teacher learning framework. In particular, Graph2Feat learns to match the representations of a lightweight student multi-layer perceptron (MLP) with a more expressive teacher GNN while learning to predict missing links based on the node features, thus attaining both GNN’s expressiveness and MLP’s fast inference. Furthermore, our approach is general; it is suitable for transductive and inductive link predictions on different types of graphs regardless of them being homogeneous or heterogeneous, directed or undirected. We carry out extensive experiments on seven real-world datasets including homogeneous and heterogeneous graphs. Our experiments demonstrate that Graph2Feat significantly outperforms SOTA methods in terms of AUC and average precision in homogeneous and heterogeneous graphs. Finally, Graph2Feat has the minimum inference time compared to the SOTA methods, and 100x acceleration compared to GNNs. The code and datasets are available on GitHub1.},
	urldate = {2023-07-13},
	booktitle = {Companion {Proceedings} of the {ACM} {Web} {Conference} 2023},
	publisher = {Association for Computing Machinery},
	author = {Samy, Ahmed E. and T. Kefato, Zekarias and Girdzijauskas, Sarunas},
	month = apr,
	year = {2023},
	keywords = {graph representation learning, heterogeneous networks, inductive link prediction, knowledge distillation},
	pages = {805--812},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\3WS4R3MP\\Samy et al. - 2023 - Graph2Feat Inductive Link Prediction via Knowledg.pdf:application/pdf},
}

@misc{noauthor_obo_2022,
	title = {{OBO} {Foundry}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=OBO_Foundry&oldid=1073476828},
	abstract = {The Open Biological and Biomedical Ontologies (OBO) Foundry is a group of people dedicated to build and maintain ontologies related to the life sciences.  The OBO Foundry establishes a set of principles for ontology development for creating a suite of interoperable reference ontologies in the biomedical domain. Currently, there are more than a hundred ontologies that follow the OBO Foundry principles.
The OBO Foundry effort makes it easier to integrate biomedical results and carry out analysis in bioinformatics. It does so by offering a structured reference for terms of different research fields and their interconnections (ex: a phenotype in a mouse model and its related phenotype in zebrafish).},
	language = {en},
	urldate = {2023-07-14},
	journal = {Wikipedia},
	month = feb,
	year = {2022},
	note = {Page Version ID: 1073476828},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\SAGJSAG5\\OBO_Foundry.html:text/html},
}

@article{verma_scholarly_2023,
	title = {Scholarly knowledge graphs through structuring scholarly communication: a review},
	volume = {9},
	issn = {2198-6053},
	shorttitle = {Scholarly knowledge graphs through structuring scholarly communication},
	url = {https://doi.org/10.1007/s40747-022-00806-6},
	doi = {10.1007/s40747-022-00806-6},
	abstract = {The necessity for scholarly knowledge mining and management has grown significantly as academic literature and its linkages to authors produce enormously. Information extraction, ontology matching, and accessing academic components with relations have become more critical than ever. Therefore, with the advancement of scientific literature, scholarly knowledge graphs have become critical to various applications where semantics can impart meanings to concepts. The objective of study is to report a literature review regarding knowledge graph construction, refinement and utilization in scholarly domain. Based on scholarly literature, the study presents a complete assessment of current state-of-the-art techniques. We presented an analytical methodology to investigate the existing status of scholarly knowledge graphs (SKG) by structuring scholarly communication. This review paper investigates the field of applying machine learning, rule-based learning, and natural language processing tools and approaches to construct SKG. It further presents the review of knowledge graph utilization and refinement to provide a view of current research efforts. In addition, we offer existing applications and challenges across the board in construction, refinement and utilization collectively. This research will help to identify frontier trends of SKG which will motivate future researchers to carry forward their work.},
	language = {en},
	number = {1},
	urldate = {2023-07-14},
	journal = {Complex \& Intelligent Systems},
	author = {Verma, Shilpa and Bhatia, Rajesh and Harit, Sandeep and Batish, Sanjay},
	month = feb,
	year = {2023},
	keywords = {Knowledge graph construction, Knowledge graph embedding, Scholarly communication, Utilization},
	pages = {1059--1095},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\87F3XF4A\\Verma et al. - 2023 - Scholarly knowledge graphs through structuring sch.pdf:application/pdf},
}

@inproceedings{aryani_open_2020,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Open {Science} {Graphs} {Must} {Interoperate}!},
	isbn = {978-3-030-55814-7},
	doi = {10.1007/978-3-030-55814-7_16},
	abstract = {Open Science Graphs (OSGs) are Scientific Knowledge Graphs whose intent is to improve the overall FAIRness of science, by enabling open access to graph representations of metadata about people, artefacts, institutions involved in the research lifecycle, as well as the relationships between these entities, in order to support stakeholder needs, such as discovery, reuse, reproducibility, statistics, trends, monitoring, impact, validation, and assessment. The represented information may span across entities such as research artefacts (e.g. publications, data, software, samples, instruments) and items of their content (e.g. statistical hypothesis tests reported in publications), research organisations, researchers, services, projects, and funders. OSGs include relationships between such entities and sometimes formalised (semantic) concepts characterising them, such as machine-readable concept descriptions for advanced discoverability, interoperability, and reuse. OSGs are generally valuable individually, but would greatly benefit from information exchange across their collections, thereby improving their efficacy to serve stakeholder needs. They could, therefore, reuse and exploit the data aggregation and added value that characterise each OSG, decentralising the effort and capitalising on synergies, as no one-size-fits-all solution exists. The RDA IG on Open Science Graphs for FAIR Data is investigating the motivation and challenges underpinning the realisation of an Interoperability Framework for OSGs. This work describes the key motivations for i) the definition of a classification for OSGs to compare their features, identify commonalities and differences, and added value and for ii) the definition of an Interoperability Framework, specifically an information model and APIs that enable a seamless exchange of information across graphs.},
	language = {en},
	booktitle = {{ADBIS}, {TPDL} and {EDA} 2020 {Common} {Workshops} and {Doctoral} {Consortium}},
	publisher = {Springer International Publishing},
	author = {Aryani, Amir and Fenner, Martin and Manghi, Paolo and Mannocci, Andrea and Stocker, Markus},
	editor = {Bellatreche, Ladjel and Bieliková, Mária and Boussaïd, Omar and Catania, Barbara and Darmont, Jérôme and Demidova, Elena and Duchateau, Fabien and Hall, Mark and Merčun, Tanja and Novikov, Boris and Papatheodorou, Christos and Risse, Thomas and Romero, Oscar and Sautot, Lucile and Talens, Guilaine and Wrembel, Robert and Žumer, Maja},
	year = {2020},
	keywords = {Open science, Knowledge graph, Interoperability, Research},
	pages = {195--206},
	file = {Submitted Version:C\:\\Users\\aluga\\Zotero\\storage\\NMFV53NH\\Aryani et al. - 2020 - Open Science Graphs Must Interoperate!.pdf:application/pdf},
}

@misc{noauthor_covid-19_nodate,
	title = {{COVID}-19 {Knowledge} {Graph}: a computable, multi-modal, cause-and-effect knowledge model of {COVID}-19 pathophysiology {\textbar} {Bioinformatics} {\textbar} {Oxford} {Academic}},
	url = {https://academic.oup.com/bioinformatics/article/37/9/1332/5911625},
	urldate = {2023-07-14},
	file = {COVID-19 Knowledge Graph\: a computable, multi-modal, cause-and-effect knowledge model of COVID-19 pathophysiology | Bioinformatics | Oxford Academic:C\:\\Users\\aluga\\Zotero\\storage\\FFBNNC2P\\5911625.html:text/html},
}

@misc{noauthor_google_nodate,
	title = {google calendr - {Google} {Search}},
	url = {https://www.google.com/search?q=google+calendr&newwindow=1&sxsrf=AB5stBicoNlajPIIrKzLWDdHFJH6gWZXAA%3A1689353519029&source=hp&ei=Ln2xZOqeOsmoxc8P6buVsAE&iflsig=AD69kcEAAAAAZLGLPwG2VqDUwiSQdruAcaV831tsN5SV&ved=0ahUKEwjq7Zaj1I6AAxVJVPEDHeldBRYQ4dUDCAk&uact=5&oq=google+calendr&gs_lp=Egdnd3Mtd2l6Ig5nb29nbGUgY2FsZW5kcjIHECMYigUYJzIEECMYJzIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAESPkbUABY1RpwAXgAkAEAmAGNAqAB3xiqAQQyLTE0uAEDyAEA-AEBwgIIEAAYigUYkQLCAgsQLhiABBjHARjRA8ICBxAjGLECGCfCAgcQABiABBgK&sclient=gws-wiz},
	urldate = {2023-07-14},
	file = {google calendr - Google Search:C\:\\Users\\aluga\\Zotero\\storage\\C93QSVMJ\\search.html:text/html},
}

@misc{noauthor_google_nodate-1,
	title = {google calendr - {Google} {Search}},
	url = {https://www.google.com/search?q=google+calendr&newwindow=1&sxsrf=AB5stBicoNlajPIIrKzLWDdHFJH6gWZXAA%3A1689353519029&source=hp&ei=Ln2xZOqeOsmoxc8P6buVsAE&iflsig=AD69kcEAAAAAZLGLPwG2VqDUwiSQdruAcaV831tsN5SV&ved=0ahUKEwjq7Zaj1I6AAxVJVPEDHeldBRYQ4dUDCAk&uact=5&oq=google+calendr&gs_lp=Egdnd3Mtd2l6Ig5nb29nbGUgY2FsZW5kcjIHECMYigUYJzIEECMYJzIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAESPkbUABY1RpwAXgAkAEAmAGNAqAB3xiqAQQyLTE0uAEDyAEA-AEBwgIIEAAYigUYkQLCAgsQLhiABBjHARjRA8ICBxAjGLECGCfCAgcQABiABBgK&sclient=gws-wiz},
	urldate = {2023-07-14},
	file = {google calendr - Google Search:C\:\\Users\\aluga\\Zotero\\storage\\3IGN8SBH\\search.html:text/html},
}

@article{du_academic_nodate,
	title = {Academic {Paper} {Knowledge} {Graph}, the {Construction} and {Application}},
	abstract = {Academic papers in the form of documents are still the primary carrier of academic publications. Nevertheless, it is difficult for such documents to express the papers’ semantic elements and discourse structures directly. Hence, this paper focuses on knowledge units with semantic information for papers to construct a knowledge graph, affording quickly retrieving knowledge from academic papers. Based on the in-depth analysis of the general narrative regulations of academic papers, we develop an academic paper representation ontology PEO that includes 29 classes, 18 relations, and five attributes. The experiment demonstrates that the developed ontology has a strong ability to represent knowledge of academic papers. Additionally, this paper preliminarily constructs the knowledge graph PKG of academic papers based on PEO ontology, demonstrating its role in semantic retrieval and intelligent question answering. Overall, this study enriches the academic knowledge’s expression ability and helps better explore the value of academic papers.},
	language = {en},
	author = {Du, Xinyu and Li, Ning},
	file = {Du and Li - Academic Paper Knowledge Graph, the Construction a.pdf:C\:\\Users\\aluga\\Zotero\\storage\\6SDV2IFM\\Du and Li - Academic Paper Knowledge Graph, the Construction a.pdf:application/pdf},
}

@inproceedings{cunningham_graph_2023,
	title = {Graph {Embedding} for {Mapping} {Interdisciplinary} {Research} {Networks}},
	url = {http://arxiv.org/abs/2302.01826},
	doi = {10.1145/3543873.3587570},
	abstract = {Representation learning is the first step in automating tasks such as research paper recommendation, classification, and retrieval. Due to the accelerating rate of research publication, together with the recognised benefits of interdisciplinary research, systems that facilitate researchers in discovering and understanding relevant works from beyond their immediate school of knowledge are vital. This work explores different methods of research paper representation (or document embedding), to identify those methods that are capable of preserving the interdisciplinary implications of research papers in their embeddings. In addition to evaluating state of the art methods of document embedding in a interdisciplinary citation prediction task, we propose a novel Graph Neural Network architecture designed to preserve the key interdisciplinary implications of research articles in citation network node embeddings. Our proposed method outperforms other GNN-based methods in interdisciplinary citation prediction, without compromising overall citation prediction performance.},
	urldate = {2023-07-15},
	booktitle = {Companion {Proceedings} of the {ACM} {Web} {Conference} 2023},
	author = {Cunningham, Eoghan and Greene, Derek},
	month = apr,
	year = {2023},
	note = {arXiv:2302.01826 [cs]},
	keywords = {Computer Science - Digital Libraries},
	pages = {784--789},
	file = {arXiv Fulltext PDF:C\:\\Users\\aluga\\Zotero\\storage\\4Y4YAFFZ\\Cunningham and Greene - 2023 - Graph Embedding for Mapping Interdisciplinary Rese.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\V8GS5PVM\\2302.html:text/html},
}

@inproceedings{stanovsky_proposition_2014,
	address = {Dublin, Ireland},
	title = {Proposition {Knowledge} {Graphs}},
	url = {https://aclanthology.org/W14-4504},
	doi = {10.3115/v1/W14-4504},
	urldate = {2023-07-18},
	booktitle = {Proceedings of the {First} {AHA}!-{Workshop} on {Information} {Discovery} in {Text}},
	publisher = {Association for Computational Linguistics and Dublin City University},
	author = {Stanovsky, Gabriel and Levy, Omer and Dagan, Ido},
	month = aug,
	year = {2014},
	pages = {19--24},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\CNCP4THX\\Stanovsky et al. - 2014 - Proposition Knowledge Graphs.pdf:application/pdf},
}

@misc{giglou_llms4ol_2023,
	title = {{LLMs4OL}: {Large} {Language} {Models} for {Ontology} {Learning}},
	shorttitle = {{LLMs4OL}},
	url = {http://arxiv.org/abs/2307.16648},
	abstract = {We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs) for Ontology Learning (OL). LLMs have shown significant advancements in natural language processing, demonstrating their ability to capture complex language patterns in different knowledge domains. Our LLMs4OL paradigm investigates the following hypothesis: {\textbackslash}textit\{Can LLMs effectively apply their language pattern capturing capability to OL, which involves automatically extracting and structuring knowledge from natural language text?\} To test this hypothesis, we conduct a comprehensive evaluation using the zero-shot prompting method. We evaluate nine different LLM model families for three main OL tasks: term typing, taxonomy discovery, and extraction of non-taxonomic relations. Additionally, the evaluations encompass diverse genres of ontological knowledge, including lexicosemantic knowledge in WordNet, geographical knowledge in GeoNames, and medical knowledge in UMLS.},
	urldate = {2023-09-03},
	publisher = {arXiv},
	author = {Giglou, Hamed Babaei and D'Souza, Jennifer and Auer, Sören},
	month = aug,
	year = {2023},
	note = {arXiv:2307.16648 [cs, math]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Theory},
	annote = {Comment: 15 pages main content, 27 pages overall, 2 Figures, accepted for publication at ISWC 2023 research track},
	file = {arXiv.org Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\75HPL62T\\2307.html:text/html;Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\47KFXPA8\\Giglou et al. - 2023 - LLMs4OL Large Language Models for Ontology Learni.pdf:application/pdf},
}

@article{ji_survey_2022,
	title = {A {Survey} on {Knowledge} {Graphs}: {Representation}, {Acquisition} and {Applications}},
	volume = {33},
	issn = {2162-237X, 2162-2388},
	shorttitle = {A {Survey} on {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/2002.00388},
	doi = {10.1109/TNNLS.2021.3070843},
	abstract = {Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction towards cognition and human-level intelligence. In this survey, we provide a comprehensive review of knowledge graph covering overall research topics about 1) knowledge graph representation learning, 2) knowledge acquisition and completion, 3) temporal knowledge graph, and 4) knowledge-aware applications, and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods, path inference, and logical rule reasoning, are reviewed. We further explore several emerging topics, including meta relational learning, commonsense reasoning, and temporal knowledge graphs. To facilitate future research on knowledge graphs, we also provide a curated collection of datasets and open-source libraries on different tasks. In the end, we have a thorough outlook on several promising research directions.},
	number = {2},
	urldate = {2023-09-03},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Ji, Shaoxiong and Pan, Shirui and Cambria, Erik and Marttinen, Pekka and Yu, Philip S.},
	month = feb,
	year = {2022},
	note = {arXiv:2002.00388 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	pages = {494--514},
	file = {arXiv.org Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\3C9B4YMK\\2002.html:text/html;Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\MNX72DZR\\Ji et al. - 2022 - A Survey on Knowledge Graphs Representation, Acqu.pdf:application/pdf},
}

@inproceedings{auer_towards_2018,
	address = {Novi Sad Serbia},
	title = {Towards a {Knowledge} {Graph} for {Science}},
	isbn = {978-1-4503-5489-9},
	url = {https://dl.acm.org/doi/10.1145/3227609.3227689},
	doi = {10.1145/3227609.3227689},
	abstract = {The document-centric workflows in science have reached (or already exceeded) the limits of adequacy. This is emphasized by recent discussions on the increasing proliferation of scientific literature and the reproducibility crisis. This presents an opportunity to rethink the dominant paradigm of document-centric scholarly information communication and transform it into knowledgebased information flows by representing and expressing information through semantically rich, interlinked knowledge graphs. At the core of knowledge-based information flows is the creation and evolution of information models that establish a common understanding of information communicated between stakeholders as well as the integration of these technologies into the infrastructure and processes of search and information exchange in the research library of the future. By integrating these models into existing and new research infrastructure services, the information structures that are currently still implicit and deeply hidden in documents can be made explicit and directly usable. This has the potential to revolutionize scientific work as information and research results can be seamlessly interlinked with each other and better matched to complex information needs. Furthermore, research results become directly comparable and easier to reuse. As our main contribution, we propose the vision of a knowledge graph for science, present a possible infrastructure for such a knowledge graph as well as our early attempts towards an implementation of the infrastructure.},
	language = {en},
	urldate = {2023-09-03},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Web} {Intelligence}, {Mining} and {Semantics}},
	publisher = {ACM},
	author = {Auer, Sören and Kovtun, Viktor and Prinz, Manuel and Kasprzik, Anna and Stocker, Markus and Vidal, Maria Esther},
	month = jun,
	year = {2018},
	pages = {1--6},
	file = {Auer et al. - 2018 - Towards a Knowledge Graph for Science.pdf:C\:\\Users\\aluga\\Zotero\\storage\\7VRNVH3X\\Auer et al. - 2018 - Towards a Knowledge Graph for Science.pdf:application/pdf},
}

@article{brack_analysing_2022,
	title = {Analysing the requirements for an {Open} {Research} {Knowledge} {Graph}: use cases, quality requirements, and construction strategies},
	volume = {23},
	issn = {1432-1300},
	shorttitle = {Analysing the requirements for an {Open} {Research} {Knowledge} {Graph}},
	url = {https://doi.org/10.1007/s00799-021-00306-x},
	doi = {10.1007/s00799-021-00306-x},
	abstract = {Current science communication has a number of drawbacks and bottlenecks which have been subject of discussion lately: Among others, the rising number of published articles makes it nearly impossible to get a full overview of the state of the art in a certain field, or reproducibility is hampered by fixed-length, document-based publications which normally cannot cover all details of a research work. Recently, several initiatives have proposed knowledge graphs (KG) for organising scientific information as a solution to many of the current issues. The focus of these proposals is, however, usually restricted to very specific use cases. In this paper, we aim to transcend this limited perspective and present a comprehensive analysis of requirements for an Open Research Knowledge Graph (ORKG) by (a) collecting and reviewing daily core tasks of a scientist, (b) establishing their consequential requirements for a KG-based system, (c) identifying overlaps and specificities, and their coverage in current solutions. As a result, we map necessary and desirable requirements for successful KG-based science communication, derive implications, and outline possible solutions.},
	language = {en},
	number = {1},
	urldate = {2023-09-03},
	journal = {International Journal on Digital Libraries},
	author = {Brack, Arthur and Hoppe, Anett and Stocker, Markus and Auer, Sören and Ewerth, Ralph},
	month = mar,
	year = {2022},
	keywords = {Scholarly communication, Design science research, Requirements analysis, Research knowledge graph},
	pages = {33--55},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\8HFYXSFL\\Brack et al. - 2022 - Analysing the requirements for an Open Research Kn.pdf:application/pdf},
}

@inproceedings{brack_domain-independent_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Domain-{Independent} {Extraction} of {Scientific} {Concepts} from {Research} {Articles}},
	isbn = {978-3-030-45439-5},
	doi = {10.1007/978-3-030-45439-5_17},
	abstract = {We examine the novel task of domain-independent scientific concept extraction from abstracts of scholarly articles and present two contributions. First, we suggest a set of generic scientific concepts that have been identified in a systematic annotation process. This set of concepts is utilised to annotate a corpus of scientific abstracts from 10 domains of Science, Technology and Medicine at the phrasal level in a joint effort with domain experts. The resulting dataset is used in a set of benchmark experiments to (a) provide baseline performance for this task, (b) examine the transferability of concepts between domains. Second, we present a state-of-the-art deep learning baseline. Further, we propose the active learning strategy for an optimal selection of instances from among the various domains in our data. The experimental results show that (1) a substantial agreement is achievable by non-experts after consultation with domain experts, (2) the baseline system achieves a fairly high F1 score, (3) active learning enables us to nearly halve the amount of required training data.},
	language = {en},
	booktitle = {Advances in {Information} {Retrieval}},
	publisher = {Springer International Publishing},
	author = {Brack, Arthur and D’Souza, Jennifer and Hoppe, Anett and Auer, Sören and Ewerth, Ralph},
	editor = {Jose, Joemon M. and Yilmaz, Emine and Magalhães, João and Castells, Pablo and Ferro, Nicola and Silva, Mário J. and Martins, Flávio},
	year = {2020},
	keywords = {Scholarly communication, Research knowledge graph, Active learning, Information extraction, Scientific articles, Sequence labelling},
	pages = {251--266},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\I463VW8J\\Brack et al. - 2020 - Domain-Independent Extraction of Scientific Concep.pdf:application/pdf},
}

@inproceedings{jaradeh_open_2019-1,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Open {Research} {Knowledge} {Graph}: {A} {System} {Walkthrough}},
	isbn = {978-3-030-30760-8},
	shorttitle = {Open {Research} {Knowledge} {Graph}},
	doi = {10.1007/978-3-030-30760-8_31},
	abstract = {Despite improved digital access to scholarly literature in the last decades, the fundamental principles of scholarly communication remain unchanged and continue to be largely document-based. Scholarly knowledge remains locked in representations that are inadequate for machine processing. The Open Research Knowledge Graph (ORKG) is an infrastructure for representing, curating and exploring scholarly knowledge in a machine actionable manner. We demonstrate the core functionality of ORKG for representing research contributions published in scholarly articles. A video of the demonstration [7] and the system (https://labs.tib.eu/orkg/) are available online.},
	language = {en},
	booktitle = {Digital {Libraries} for {Open} {Knowledge}},
	publisher = {Springer International Publishing},
	author = {Jaradeh, Mohamad Yaser and Oelen, Allard and Prinz, Manuel and Stocker, Markus and Auer, Sören},
	editor = {Doucet, Antoine and Isaac, Antoine and Golub, Koraljka and Aalberg, Trond and Jatowt, Adam},
	year = {2019},
	keywords = {Knowledge graph, Scholarly communication, Digital libraries, Information science, Research infrastructure},
	pages = {348--351},
	file = {Submitted Version:C\:\\Users\\aluga\\Zotero\\storage\\XN4ZUESD\\Jaradeh et al. - 2019 - Open Research Knowledge Graph A System Walkthroug.pdf:application/pdf},
}

@inproceedings{jaradeh_question_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Question {Answering} on {Scholarly} {Knowledge} {Graphs}},
	isbn = {978-3-030-54956-5},
	doi = {10.1007/978-3-030-54956-5_2},
	abstract = {Answering questions on scholarly knowledge comprising text and other artifacts is a vital part of any research life cycle. Querying scholarly knowledge and retrieving suitable answers is currently hardly possible due to the following primary reason: machine inactionable, ambiguous and unstructured content in publications. We present JarvisQA, a BERT based system to answer questions on tabular views of scholarly knowledge graphs. Such tables can be found in a variety of shapes in the scholarly literature (e.g., surveys, comparisons or results). Our system can retrieve direct answers to a variety of different questions asked on tabular data in articles. Furthermore, we present a preliminary dataset of related tables and a corresponding set of natural language questions. This dataset is used as a benchmark for our system and can be reused by others. Additionally, JarvisQA is evaluated on two datasets against other baselines and shows an improvement of two to three folds in performance compared to related methods.},
	language = {en},
	booktitle = {Digital {Libraries} for {Open} {Knowledge}},
	publisher = {Springer International Publishing},
	author = {Jaradeh, Mohamad Yaser and Stocker, Markus and Auer, Sören},
	editor = {Hall, Mark and Merčun, Tanja and Risse, Thomas and Duchateau, Fabien},
	year = {2020},
	keywords = {Digital Libraries, Information retrieval, Question Answering, Scholarly knowledge, Semantic search, Semantic web},
	pages = {19--32},
	file = {Submitted Version:C\:\\Users\\aluga\\Zotero\\storage\\XBRL5JSN\\Jaradeh et al. - 2020 - Question Answering on Scholarly Knowledge Graphs.pdf:application/pdf},
}

@article{chatterjee_knowledge_2021,
	title = {Knowledge {Graphs} for {COVID}-19: {An} {Exploratory} {Review} of the {Current} {Landscape}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2075-4426},
	shorttitle = {Knowledge {Graphs} for {COVID}-19},
	url = {https://www.mdpi.com/2075-4426/11/4/300},
	doi = {10.3390/jpm11040300},
	abstract = {Background: Searching through the COVID-19 research literature to gain actionable clinical insight is a formidable task, even for experts. The usefulness of this corpus in terms of improving patient care is tied to the ability to see the big picture that emerges when the studies are seen in conjunction rather than in isolation. When the answer to a search query requires linking together multiple pieces of information across documents, simple keyword searches are insufficient. To answer such complex information needs, an innovative artificial intelligence (AI) technology named a knowledge graph (KG) could prove to be effective. Methods: We conducted an exploratory literature review of KG applications in the context of COVID-19. The search term used was “covid-19 knowledge graph”. In addition to PubMed, the first five pages of search results for Google Scholar and Google were considered for inclusion. Google Scholar was used to include non-peer-reviewed or non-indexed articles such as pre-prints and conference proceedings. Google was used to identify companies or consortiums active in this domain that have not published any literature, peer-reviewed or otherwise. Results: Our search yielded 34 results on PubMed and 50 results each on Google and Google Scholar. We found KGs being used for facilitating literature search, drug repurposing, clinical trial mapping, and risk factor analysis. Conclusions: Our synopses of these works make a compelling case for the utility of this nascent field of research.},
	language = {en},
	number = {4},
	urldate = {2023-09-03},
	journal = {Journal of Personalized Medicine},
	author = {Chatterjee, Avishek and Nardi, Cosimo and Oberije, Cary and Lambin, Philippe},
	month = apr,
	year = {2021},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {knowledge graph, COVID-19, drug repurposing, natural language processing},
	pages = {300},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\77E35QUB\\Chatterjee et al. - 2021 - Knowledge Graphs for COVID-19 An Exploratory Revi.pdf:application/pdf},
}

@article{lezhnina_scholarly_2022,
	title = {A {Scholarly} {Knowledge} {Graph}-{Powered} {Dashboard}: {Implementation} and {User} {Evaluation}},
	volume = {7},
	issn = {2504-0537},
	shorttitle = {A {Scholarly} {Knowledge} {Graph}-{Powered} {Dashboard}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9343766/},
	doi = {10.3389/frma.2022.934930},
	abstract = {Scholarly knowledge graphs provide researchers with a novel modality of information retrieval, and their wider use in academia is beneficial for the digitalization of published works and the development of scholarly communication. To increase the acceptance of scholarly knowledge graphs, we present a dashboard, which visualizes the research contributions on an educational science topic in the frame of the Open Research Knowledge Graph (ORKG). As dashboards are created at the intersection of computer science, graphic design, and human-technology interaction, we used these three perspectives to develop a multi-relational visualization tool aimed at improving the user experience. According to preliminary results of the user evaluation survey, the dashboard was perceived as more appealing than the baseline ORKG-powered interface. Our findings can be used for the development of scholarly knowledge graph-powered dashboards in different domains, thus facilitating acceptance of these novel instruments by research communities and increasing versatility in scholarly communication.},
	urldate = {2023-09-04},
	journal = {Frontiers in Research Metrics and Analytics},
	author = {Lezhnina, Olga and Kismihók, Gábor and Prinz, Manuel and Stocker, Markus and Auer, Sören},
	month = jul,
	year = {2022},
	pmid = {35928800},
	pmcid = {PMC9343766},
	pages = {934930},
	file = {PubMed Central Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\KZVDX6QV\\Lezhnina et al. - 2022 - A Scholarly Knowledge Graph-Powered Dashboard Imp.pdf:application/pdf},
}

@inproceedings{brack_domain-independent_2020-1,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Domain-{Independent} {Extraction} of {Scientific} {Concepts} from {Research} {Articles}},
	isbn = {978-3-030-45439-5},
	doi = {10.1007/978-3-030-45439-5_17},
	abstract = {We examine the novel task of domain-independent scientific concept extraction from abstracts of scholarly articles and present two contributions. First, we suggest a set of generic scientific concepts that have been identified in a systematic annotation process. This set of concepts is utilised to annotate a corpus of scientific abstracts from 10 domains of Science, Technology and Medicine at the phrasal level in a joint effort with domain experts. The resulting dataset is used in a set of benchmark experiments to (a) provide baseline performance for this task, (b) examine the transferability of concepts between domains. Second, we present a state-of-the-art deep learning baseline. Further, we propose the active learning strategy for an optimal selection of instances from among the various domains in our data. The experimental results show that (1) a substantial agreement is achievable by non-experts after consultation with domain experts, (2) the baseline system achieves a fairly high F1 score, (3) active learning enables us to nearly halve the amount of required training data.},
	language = {en},
	booktitle = {Advances in {Information} {Retrieval}},
	publisher = {Springer International Publishing},
	author = {Brack, Arthur and D’Souza, Jennifer and Hoppe, Anett and Auer, Sören and Ewerth, Ralph},
	editor = {Jose, Joemon M. and Yilmaz, Emine and Magalhães, João and Castells, Pablo and Ferro, Nicola and Silva, Mário J. and Martins, Flávio},
	year = {2020},
	keywords = {Scholarly communication, Research knowledge graph, Active learning, Information extraction, Scientific articles, Sequence labelling},
	pages = {251--266},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\FRVX8FMB\\Brack et al. - 2020 - Domain-Independent Extraction of Scientific Concep.pdf:application/pdf},
}

@inproceedings{jaradeh_question_2020-1,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Question {Answering} on {Scholarly} {Knowledge} {Graphs}},
	isbn = {978-3-030-54956-5},
	doi = {10.1007/978-3-030-54956-5_2},
	abstract = {Answering questions on scholarly knowledge comprising text and other artifacts is a vital part of any research life cycle. Querying scholarly knowledge and retrieving suitable answers is currently hardly possible due to the following primary reason: machine inactionable, ambiguous and unstructured content in publications. We present JarvisQA, a BERT based system to answer questions on tabular views of scholarly knowledge graphs. Such tables can be found in a variety of shapes in the scholarly literature (e.g., surveys, comparisons or results). Our system can retrieve direct answers to a variety of different questions asked on tabular data in articles. Furthermore, we present a preliminary dataset of related tables and a corresponding set of natural language questions. This dataset is used as a benchmark for our system and can be reused by others. Additionally, JarvisQA is evaluated on two datasets against other baselines and shows an improvement of two to three folds in performance compared to related methods.},
	language = {en},
	booktitle = {Digital {Libraries} for {Open} {Knowledge}},
	publisher = {Springer International Publishing},
	author = {Jaradeh, Mohamad Yaser and Stocker, Markus and Auer, Sören},
	editor = {Hall, Mark and Merčun, Tanja and Risse, Thomas and Duchateau, Fabien},
	year = {2020},
	keywords = {Digital Libraries, Information retrieval, Question Answering, Scholarly knowledge, Semantic search, Semantic web},
	pages = {19--32},
	file = {Submitted Version:C\:\\Users\\aluga\\Zotero\\storage\\PJG9IET4\\Jaradeh et al. - 2020 - Question Answering on Scholarly Knowledge Graphs.pdf:application/pdf},
}

@misc{noauthor_preview_nodate,
	title = {Preview},
	url = {https://zenodo.org/record/3735152/preview/Ingested%20papers.csv},
	urldate = {2023-09-04},
	file = {Preview:C\:\\Users\\aluga\\Zotero\\storage\\EL6LZAJU\\Ingested papers.html:text/html},
}

@misc{oelen_dataset_2020,
	title = {Dataset for {Creating} a {Scholarly} {Knowledge} {Graph} from {Survey} {Article} {Tables}},
	url = {https://zenodo.org/record/3735152},
	doi = {10.5281/zenodo.3735152},
	abstract = {Selected papers.csv This file lists all selected survey papers used to create the knowledge graph. The file contains paper titles, table references (of the tables that are extracted), sources and the reference to the survey paper (either a DOI, or a full textual reference)   ORKG comparisons.csv All comparisons imported in the ORKG are listed in this file. Per survey paper, multiple tables could be extracted, and therefore multiple comparisons are created. The files lists the internal IDs and the URL to the comparisons.    Ingested papers.csv A full list of all individual papers extracted from the survey articles. The file contains paper titles and their respective URL in the ORKG.},
	language = {eng},
	urldate = {2023-09-04},
	publisher = {Zenodo},
	author = {Oelen, Allard and Stocker, Markus and Auer, Sören},
	month = mar,
	year = {2020},
	keywords = {Survey table extraction},
}

@article{milosevic_comparison_2023,
	title = {Comparison of biomedical relationship extraction methods and models for knowledge graph creation},
	volume = {75},
	issn = {15708268},
	url = {http://arxiv.org/abs/2201.01647},
	doi = {10.1016/j.websem.2022.100756},
	abstract = {Biomedical research is growing at such an exponential pace that scientists, researchers, and practitioners are no more able to cope with the amount of published literature in the domain. The knowledge presented in the literature needs to be systematized in such a way that claims and hypotheses can be easily found, accessed, and validated. Knowledge graphs can provide such a framework for semantic knowledge representation from literature. However, in order to build a knowledge graph, it is necessary to extract knowledge as relationships between biomedical entities and normalize both entities and relationship types. In this paper, we present and compare few rule-based and machine learning-based (Naive Bayes, Random Forests as examples of traditional machine learning methods and DistilBERT, PubMedBERT, T5 and SciFive-based models as examples of modern deep learning transformers) methods for scalable relationship extraction from biomedical literature, and for the integration into the knowledge graphs. We examine how resilient are these various methods to unbalanced and fairly small datasets. Our experiments show that transformer-based models handle well both small (due to pre-training on a large dataset) and unbalanced datasets. The best performing model was the PubMedBERT-based model fine-tuned on balanced data, with a reported F1-score of 0.92. DistilBERT-based model followed with F1-score of 0.89, performing faster and with lower resource requirements. BERT-based models performed better then T5-based generative models.},
	urldate = {2023-09-12},
	journal = {Journal of Web Semantics},
	author = {Milosevic, Nikola and Thielemann, Wolfgang},
	month = jan,
	year = {2023},
	note = {arXiv:2201.01647 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Information Retrieval, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, E.2, I.7},
	pages = {100756},
	annote = {Comment: Paper submitted to Journal of Semantic Web},
	file = {arXiv Fulltext PDF:C\:\\Users\\aluga\\Zotero\\storage\\X6UJZVVI\\Milosevic and Thielemann - 2023 - Comparison of biomedical relationship extraction m.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\BL46UHCM\\2201.html:text/html},
}

@misc{caufield_kg-hub_2023,
	title = {{KG}-{Hub} -- {Building} and {Exchanging} {Biological} {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/2302.10800},
	doi = {10.48550/arXiv.2302.10800},
	abstract = {Knowledge graphs (KGs) are a powerful approach for integrating heterogeneous data and making inferences in biology and many other domains, but a coherent solution for constructing, exchanging, and facilitating the downstream use of knowledge graphs is lacking. Here we present KG-Hub, a platform that enables standardized construction, exchange, and reuse of knowledge graphs. Features include a simple, modular extract-transform-load (ETL) pattern for producing graphs compliant with Biolink Model (a high-level data model for standardizing biological data), easy integration of any OBO (Open Biological and Biomedical Ontologies) ontology, cached downloads of upstream data sources, versioned and automatically updated builds with stable URLs, web-browsable storage of KG artifacts on cloud infrastructure, and easy reuse of transformed subgraphs across projects. Current KG-Hub projects span use cases including COVID-19 research, drug repurposing, microbial-environmental interactions, and rare disease research. KG-Hub is equipped with tooling to easily analyze and manipulate knowledge graphs. KG-Hub is also tightly integrated with graph machine learning (ML) tools which allow automated graph machine learning, including node embeddings and training of models for link prediction and node classification.},
	urldate = {2023-09-12},
	publisher = {arXiv},
	author = {Caufield, J. Harry and Putman, Tim and Schaper, Kevin and Unni, Deepak R. and Hegde, Harshad and Callahan, Tiffany J. and Cappelletti, Luca and Moxon, Sierra AT and Ravanmehr, Vida and Carbon, Seth and Chan, Lauren E. and Cortes, Katherina and Shefchek, Kent A. and Elsarboukh, Glass and Balhoff, James P. and Fontana, Tommaso and Matentzoglu, Nicolas and Bruskiewich, Richard M. and Thessen, Anne E. and Harris, Nomi L. and Munoz-Torres, Monica C. and Haendel, Melissa A. and Robinson, Peter N. and Joachimiak, Marcin P. and Mungall, Christopher J. and Reese, Justin T.},
	month = jan,
	year = {2023},
	note = {arXiv:2302.10800 [cs, q-bio]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Quantitative Biology - Quantitative Methods},
	file = {arXiv Fulltext PDF:C\:\\Users\\aluga\\Zotero\\storage\\86VVWMUY\\Caufield et al. - 2023 - KG-Hub -- Building and Exchanging Biological Knowl.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\PV5J57PT\\2302.html:text/html},
}

@article{caufield_kg-hubbuilding_2023,
	title = {{KG}-{Hub}—building and exchanging biological knowledge graphs},
	volume = {39},
	issn = {1367-4811},
	url = {https://doi.org/10.1093/bioinformatics/btad418},
	doi = {10.1093/bioinformatics/btad418},
	abstract = {Knowledge graphs (KGs) are a powerful approach for integrating heterogeneous data and making inferences in biology and many other domains, but a coherent solution for constructing, exchanging, and facilitating the downstream use of KGs is lacking.Here we present KG-Hub, a platform that enables standardized construction, exchange, and reuse of KGs. Features include a simple, modular extract–transform–load pattern for producing graphs compliant with Biolink Model (a high-level data model for standardizing biological data), easy integration of any OBO (Open Biological and Biomedical Ontologies) ontology, cached downloads of upstream data sources, versioned and automatically updated builds with stable URLs, web-browsable storage of KG artifacts on cloud infrastructure, and easy reuse of transformed subgraphs across projects. Current KG-Hub projects span use cases including COVID-19 research, drug repurposing, microbial–environmental interactions, and rare disease research. KG-Hub is equipped with tooling to easily analyze and manipulate KGs. KG-Hub is also tightly integrated with graph machine learning (ML) tools which allow automated graph ML, including node embeddings and training of models for link prediction and node classification.https://kghub.org.},
	number = {7},
	urldate = {2023-09-13},
	journal = {Bioinformatics},
	author = {Caufield, J Harry and Putman, Tim and Schaper, Kevin and Unni, Deepak R and Hegde, Harshad and Callahan, Tiffany J and Cappelletti, Luca and Moxon, Sierra A T and Ravanmehr, Vida and Carbon, Seth and Chan, Lauren E and Cortes, Katherina and Shefchek, Kent A and Elsarboukh, Glass and Balhoff, Jim and Fontana, Tommaso and Matentzoglu, Nicolas and Bruskiewich, Richard M and Thessen, Anne E and Harris, Nomi L and Munoz-Torres, Monica C and Haendel, Melissa A and Robinson, Peter N and Joachimiak, Marcin P and Mungall, Christopher J and Reese, Justin T},
	month = jul,
	year = {2023},
	pages = {btad418},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\2KEXNF6V\\Caufield et al. - 2023 - KG-Hub—building and exchanging biological knowledg.pdf:application/pdf},
}

@article{yang_constructing_2021,
	title = {Constructing public health evidence knowledge graph for decision-making support from {COVID}-19 literature of modelling study},
	volume = {2},
	issn = {2666-4496},
	url = {https://www.sciencedirect.com/science/article/pii/S266644962100030X},
	doi = {10.1016/j.jnlssr.2021.08.002},
	abstract = {The needs of mitigating COVID-19 epidemic prompt policymakers to make public health-related decision under the guidelines of science. Tremendous unstructured COVID-19 publications make it challenging for policymakers to obtain relevant evidence. Knowledge graphs (KGs) can formalize unstructured knowledge into structured form and have been used in supporting decision-making recently. Here, we introduce a novel framework that can extract the COVID-19 public health evidence knowledge graph (CPHE-KG) from papers relating to a modelling study. We screen out a corpus of 3096 COVID-19 modelling study papers by performing a literature assessment process. We define a novel annotation schema to construct the COVID-19 modelling study-related IE dataset (CPHIE). We also propose a novel multi-tasks document-level information extraction model SS-DYGIE++ based on the dataset. Leveraging the model on the new corpus, we construct CPHE-KG containing 60,967 entities and 51,140 relations. Finally, we seek to apply our KG to support evidence querying and evidence mapping visualization. Our SS-DYGIE++(SpanBERT) model has achieved a F1 score of 0.77 and 0.55 respectively in document-level entity recognition and coreference resolution tasks. It has also shown high performance in the relation identification task. With evidence querying, our KG can present the dynamic transmissions of COVID-19 pandemic in different countries and regions. The evidence mapping of our KG can show the impacts of variable non-pharmacological interventions to COVID-19 pandemic. Analysis demonstrates the quality of our KG and shows that it has the potential to support COVID-19 policy making in public health.},
	number = {3},
	urldate = {2023-09-13},
	journal = {Journal of Safety Science and Resilience},
	author = {Yang, Yunrong and Cao, Zhidong and Zhao, Pengfei and Zeng, Dajun Daniel and Zhang, Qingpeng and Luo, Yin},
	month = sep,
	year = {2021},
	keywords = {COVID-19, Knowledge graph, Decision-making support, Evidence-based public health},
	pages = {146--156},
	file = {ScienceDirect Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\JKFAF9QT\\S266644962100030X.html:text/html},
}

@inproceedings{kannan_exaflops_2022,
	title = {Exaflops {Biomedical} {Knowledge} {Graph} {Analytics}},
	doi = {10.1109/SC41404.2022.00011},
	abstract = {We are motivated by newly proposed methods for mining large-scale corpora of scholarly publications (e.g., full biomedical literature), which consists of tens of millions of papers spanning decades of research. In this setting, analysts seek to discover relationships among concepts. They construct graph representations from annotated text databases and then formulate the relationship-mining problem as an all-pairs shortest paths (APSP) and validate connective paths against curated biomedical knowledge graphs (e.g., Spoke). In this context, we present Coast (Exascale Communication-Optimized All-Pairs Shortest Path) and demonstrate 1.004 EF/s on 9,200 Frontier nodes (73,600 GCDs). We develop hyperbolic performance models (HYPERMOD), which guide optimizations and parametric tuning. The proposed Coast algorithm achieved the memory constant parallel efficiency of 99\% in the single-precision tropical semiring. Looking forward, Coast will enable the integration of scholarly corpora like PubMed into the Spoke biomedical knowledge graph.},
	booktitle = {{SC22}: {International} {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
	author = {Kannan, Ramakrishnan and Sao, Piyush and Lu, Hao and Kurzak, Jakub and Schenk, Gundolf and Shi, Yongmei and Lim, Seung–Hwan and Israni, Sharat and Thakkar, Vijay and Cong, Guojing and Patton, Robert and Baranzini, Sergio E. and Vuduc, Richard and Potok, Thomas},
	month = nov,
	year = {2022},
	note = {ISSN: 2167-4337},
	keywords = {Databases, Biological system modeling, High performance computing, High-Performance Computing, Knowledge graphs, Memory management, Optimization, Parallel Algorithms, Shortest Path Problem, Tuning},
	pages = {1--11},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\aluga\\Zotero\\storage\\C8HP6W24\\10046083.html:text/html},
}

@article{hansel_data_2023,
	title = {From {Data} to {Wisdom}: {Biomedical} {Knowledge} {Graphs} for {Real}-{World} {Data} {Insights}},
	volume = {47},
	issn = {0148-5598},
	shorttitle = {From {Data} to {Wisdom}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10191934/},
	doi = {10.1007/s10916-023-01951-2},
	abstract = {Graph data models are an emerging approach to structure clinical and biomedical information. These models offer intriguing opportunities for novel approaches in healthcare, such as disease phenotyping, risk prediction, and personalized precision care. The combination of data and information in a graph model to create knowledge graphs has rapidly expanded in biomedical research, but the integration of real-world data from the electronic health record has been limited. To broadly apply knowledge graphs to EHR and other real-world data, a deeper understanding of how to represent these data in a standardized graph model is needed. We provide an overview of the state-of-the-art research for clinical and biomedical data integration and summarize the potential to accelerate healthcare and precision medicine research through insight generation from integrated knowledge graphs.},
	number = {1},
	urldate = {2023-09-13},
	journal = {Journal of Medical Systems},
	author = {Hänsel, Katrin and Dudgeon, Sarah N. and Cheung, Kei-Hoi and Durant, Thomas J. S. and Schulz, Wade L.},
	year = {2023},
	pmid = {37195430},
	pmcid = {PMC10191934},
	pages = {65},
	file = {PubMed Central Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\LVN6U74L\\Hänsel et al. - 2023 - From Data to Wisdom Biomedical Knowledge Graphs f.pdf:application/pdf},
}

@article{lariviere_oligopoly_2015,
	title = {The {Oligopoly} of {Academic} {Publishers} in the {Digital} {Era}},
	volume = {10},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0127502},
	doi = {10.1371/journal.pone.0127502},
	abstract = {The consolidation of the scientific publishing industry has been the topic of much debate within and outside the scientific community, especially in relation to major publishers’ high profit margins. However, the share of scientific output published in the journals of these major publishers, as well as its evolution over time and across various disciplines, has not yet been analyzed. This paper provides such analysis, based on 45 million documents indexed in the Web of Science over the period 1973-2013. It shows that in both natural and medical sciences (NMS) and social sciences and humanities (SSH), Reed-Elsevier, Wiley-Blackwell, Springer, and Taylor \& Francis increased their share of the published output, especially since the advent of the digital era (mid-1990s). Combined, the top five most prolific publishers account for more than 50\% of all papers published in 2013. Disciplines of the social sciences have the highest level of concentration (70\% of papers from the top five publishers), while the humanities have remained relatively independent (20\% from top five publishers). NMS disciplines are in between, mainly because of the strength of their scientific societies, such as the ACS in chemistry or APS in physics. The paper also examines the migration of journals between small and big publishing houses and explores the effect of publisher change on citation impact. It concludes with a discussion on the economics of scholarly publishing.},
	language = {en},
	number = {6},
	urldate = {2023-09-17},
	journal = {PLOS ONE},
	author = {Larivière, Vincent and Haustein, Stefanie and Mongeon, Philippe},
	month = jun,
	year = {2015},
	note = {Publisher: Public Library of Science},
	keywords = {Social sciences, Bibliometrics, Citation analysis, Economics, Libraries, Medical humanities, Medical journals, Scientific publishing},
	pages = {e0127502},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\W5EMT5DY\\Larivière et al. - 2015 - The Oligopoly of Academic Publishers in the Digita.pdf:application/pdf},
}

@misc{bordalo_how_2023,
	type = {Working {Paper}},
	series = {Working {Paper} {Series}},
	title = {How {People} {Use} {Statistics}},
	url = {https://www.nber.org/papers/w31631},
	doi = {10.3386/w31631},
	abstract = {We document two new facts about the distributions of answers in famous statistical problems: they are i) multi-modal and ii) unstable with respect to irrelevant changes in the problem. We offer a model in which, when solving a problem, people represent each hypothesis by attending “bottom up” to its salient features while neglecting other, potentially more relevant, ones. Only the statistics associated with salient features are used, others are neglected. The model unifies biases in judgments about i.i.d. draws, such as the Gambler’s Fallacy and insensitivity to sample size, with biases in inference such as under- and overreaction and insensitivity to the weight of evidence. The model makes predictions about how changes in the salience of specific features should jointly shape the prevalence of these biases and measured attention to features, but also create entirely new biases. We test and confirm these predictions experimentally. Bottom-up attention to features emerges as a unifying framework for biases conventionally explained using a variety of stable heuristics or distortions of the Bayes rule.},
	urldate = {2023-10-23},
	publisher = {National Bureau of Economic Research},
	author = {Bordalo, Pedro and Conlon, John J. and Gennaioli, Nicola and Kwon, Spencer Yongwook and Shleifer, Andrei},
	month = aug,
	year = {2023},
	doi = {10.3386/w31631},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\L39GSDS3\\Bordalo et al. - 2023 - How People Use Statistics.pdf:application/pdf},
}

@article{cappelen_second-best_2023,
	title = {Second-{Best} {Fairness}: {The} {Trade}-off between {False} {Positives} and {False} {Negatives}},
	volume = {113},
	issn = {0002-8282},
	shorttitle = {Second-{Best} {Fairness}},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.20211015},
	doi = {10.1257/aer.20211015},
	abstract = {A main focus in economics is how to design optimal policies in second-best situations, which often requires a trade-off between giving some individuals more than they deserve, false positives, and others less than they deserve, false negatives. This paper provides novel evidence on people's second-best fairness preferences from large-scale experimental studies in the United States and Norway. The majority of people are more concerned with false negatives than with false positives, but we document substantial heterogeneity in second-best fairness preferences between the countries and across the political spectrum. The findings shed light on the political economy of social insurance and redistribution.},
	language = {en},
	number = {9},
	urldate = {2023-10-23},
	journal = {American Economic Review},
	author = {Cappelen, Alexander W. and Cappelen, Cornelius and Tungodden, Bertil},
	month = sep,
	year = {2023},
	keywords = {Environmental Taxes and Subsidies, Welfare, Well-Being, and Poverty: Government Programs, Provision and Effects of Welfare Programs, Redistributive Effects},
	pages = {2458--2485},
}

@misc{cappelen_second-best_2018,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Second-{Best} {Fairness} {Under} {Limited} {Information}: {The} {Trade}-{Off} between {False} {Positives} and {False} {Negatives}},
	shorttitle = {Second-{Best} {Fairness} {Under} {Limited} {Information}},
	url = {https://papers.ssrn.com/abstract=3243332},
	doi = {10.2139/ssrn.3243332},
	abstract = {In many important economic settings, limited information makes it impossible for decision makers to ensure that each individual gets what he or she deserves. Decision makers are then faced with the trade-off between giving some individuals more than they deserve, false positives, and giving some individuals less than they deserve, false negatives. We present the results from a large-scale experimental study of how people trade off these two mistakes in distributive choices. We find that a majority are more concerned with avoiding false negatives than with avoiding false positives, but we also document heterogeneity With respect to how people make this trade-off. The findings shed important light on people’s attitudes to a wide range of policies by providing novel evidence on an important dimension of people’s social preference.},
	language = {en},
	urldate = {2023-10-23},
	author = {Cappelen, Alexander W. and Cappelen, Cornelius and Tungodden, Bertil},
	month = aug,
	year = {2018},
	keywords = {SSRN, Alexander W. Cappelen, Bertil Tungodden, Cornelius Cappelen, Second-Best Fairness Under Limited Information: The Trade-Off between False Positives and False Negatives},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\C5X2C4JJ\\Cappelen et al. - 2018 - Second-Best Fairness Under Limited Information Th.pdf:application/pdf},
}

@article{aina_contingent_2023,
	title = {Contingent {Belief} {Updating}},
	url = {https://ideas.repec.org//p/ajk/ajkdps/263.html},
	abstract = {We study how contingent thinking – that is, reasoning through all possible contingencies without knowing which is realized – affects belief updating. According to the Bayesian benchmark, beliefs updated after exposure to new information should be equivalent to beliefs assessed for the contingency of receiving such information. Using an experiment, we decompose the effect of contingent thinking on belief updating into two components: (1) hypothetical thinking (updating on a piece of not-yet-observed information) and (2) contrast reasoning (comparing multiple contingencies during the updating process). Our results show that contingent thinking increases deviations from Bayesian updating and that this effect can be attributed to hypothetical thinking.},
	language = {en},
	urldate = {2023-11-29},
	journal = {ECONtribute Discussion Papers Series},
	author = {Aina, Chiara and Amelio, Andrea and Brütt, Katharina},
	month = nov,
	year = {2023},
	note = {Number: 263
Publisher: University of Bonn and University of Cologne, Germany},
	keywords = {Experiment, Belief Updating, Contingent Thinking},
	file = {Fullext PDF:C\:\\Users\\aluga\\Zotero\\storage\\N4R9S92S\\Aina et al. - 2023 - Contingent Belief Updating.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\Z6MWG3KL\\263.html:text/html},
}

@misc{bordalo_how_2023-1,
	type = {Working {Paper}},
	series = {Working {Paper} {Series}},
	title = {How {People} {Use} {Statistics}},
	url = {https://www.nber.org/papers/w31631},
	doi = {10.3386/w31631},
	abstract = {We document two new facts about the distributions of answers in famous statistical problems: they are i) multi-modal and ii) unstable with respect to irrelevant changes in the problem. We offer a model in which, when solving a problem, people represent each hypothesis by attending “bottom up” to its salient features while neglecting other, potentially more relevant, ones. Only the statistics associated with salient features are used, others are neglected. The model unifies biases in judgments about i.i.d. draws, such as the Gambler’s Fallacy and insensitivity to sample size, with biases in inference such as under- and overreaction and insensitivity to the weight of evidence. The model makes predictions about how changes in the salience of specific features should jointly shape the prevalence of these biases and measured attention to features, but also create entirely new biases. We test and confirm these predictions experimentally. Bottom-up attention to features emerges as a unifying framework for biases conventionally explained using a variety of stable heuristics or distortions of the Bayes rule.},
	urldate = {2023-11-29},
	publisher = {National Bureau of Economic Research},
	author = {Bordalo, Pedro and Conlon, John J. and Gennaioli, Nicola and Kwon, Spencer Yongwook and Shleifer, Andrei},
	month = aug,
	year = {2023},
	doi = {10.3386/w31631},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\DK57HABI\\Bordalo et al. - 2023 - How People Use Statistics.pdf:application/pdf},
}

@article{friedl_insurance_2014,
	title = {Insurance demand and social comparison: {An} experimental analysis},
	volume = {48},
	issn = {1573-0476},
	shorttitle = {Insurance demand and social comparison},
	url = {https://doi.org/10.1007/s11166-014-9189-9},
	doi = {10.1007/s11166-014-9189-9},
	abstract = {This paper analyzes whether social comparison can explain the low take-up of disaster insurance usually reported in field studies. We argue that risks in the case of disasters are highly correlated between subjects whereas risks for which high insurance take-up can be observed (e.g. extended warranties or cell phone insurance) are typically idiosyncratic. We set up a simple model with social reference points and show that in the presence of inequality aversion social comparison makes insurance indeed less attractive if risks are correlated. In addition we conducted a simple experiment which confirms these theoretical results. The average willingness to pay for insurance is significantly higher for idiosyncratic than for correlated risks.},
	language = {en},
	number = {2},
	urldate = {2023-11-30},
	journal = {Journal of Risk and Uncertainty},
	author = {Friedl, Andreas and Lima de Miranda, Katharina and Schmidt, Ulrich},
	month = apr,
	year = {2014},
	keywords = {C91, D81, D03, D14, G22, Inequality aversion, Loss aversion, Disaster insurance, Social reference points},
	pages = {97--109},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\6PTCQDZI\\Friedl et al. - 2014 - Insurance demand and social comparison An experim.pdf:application/pdf},
}

@misc{xu_revealed_2022,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Revealed {Preferences} {Over} {Experts} and {Quacks} and {Failures} of {Contingent} {Reasoning}},
	url = {https://papers.ssrn.com/abstract=4560390},
	doi = {10.2139/ssrn.4560390},
	abstract = {In many economic scenarios, people resort to different tests to obtain information about the payoff-relevant states of the world. This paper studies how people evaluate and choose between useless tests (quacks) and genuinely useful ones (experts). Using a novel graphic experiment, I recover individual preferences over tests. I find people fail to distinguish between experts and quacks. Their quack choices are not driven by standard explanations, including belief updating bias, best-responding bias, and intrinsic preference for information. The main culprit is the failure in reasoning the contingency value of tests for their decision problems.},
	language = {en},
	urldate = {2023-11-30},
	author = {Xu, Yan},
	month = sep,
	year = {2022},
	keywords = {belief updating, contingent reasoning, heuristics, information structure},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\4ADU2IET\\Xu - 2022 - Revealed Preferences Over Experts and Quacks and F.pdf:application/pdf},
}

@misc{danz_belief_2020,
	type = {Working {Paper}},
	series = {Working {Paper} {Series}},
	title = {Belief {Elicitation}: {Limiting} {Truth} {Telling} with {Information} on {Incentives}},
	shorttitle = {Belief {Elicitation}},
	url = {https://www.nber.org/papers/w27327},
	doi = {10.3386/w27327},
	abstract = {Belief elicitation is central to inference on economic decision making. The recently introduced Binarized Scoring Rule (BSR) is heralded for its robustness to individuals holding risk averse preferences and for its superior performance when eliciting beliefs. Consequently, the BSR has become the state-of-the-art mechanism. We study truth telling under the BSR and examine whether information on the offered incentives improves reports about a known objective prior. We find that transparent information on incentives gives rise to error rates in excess of 40 percent, and that only 15 percent of participants consistently report the truth. False reports are conservative and appear to result from a biased perception of the BSR incentives. While attempts to debias are somewhat successful, the highest degree of truth telling occurs when information on quantitative incentives is withheld. Consistent with incentives driving false reports, we find that slow release of information decreases truth telling. Perversely, our results suggest that information on the BSR incentives substantially distorts reported beliefs.},
	urldate = {2023-12-19},
	publisher = {National Bureau of Economic Research},
	author = {Danz, David and Vesterlund, Lise and Wilson, Alistair J.},
	month = jun,
	year = {2020},
	doi = {10.3386/w27327},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\9RVBRA3C\\Danz et al. - 2020 - Belief Elicitation Limiting Truth Telling with In.pdf:application/pdf},
}

@article{van_lange_vitamin_2021,
	title = {Vitamin {S}: {Why} {Is} {Social} {Contact}, {Even} {With} {Strangers}, {So} {Important} to {Well}-{Being}?},
	volume = {30},
	issn = {0963-7214},
	shorttitle = {Vitamin {S}},
	url = {https://doi.org/10.1177/09637214211002538},
	doi = {10.1177/09637214211002538},
	abstract = {Even before COVID-19, it was well known in psychological science that people?s well-being is strongly served by the quality of their close relationships. But is well-being also served by social contact with people who are known less well? In this article, we discuss three propositions that support the conclusion that the benefits of social contact also derive from interactions with acquaintances and even strangers. The propositions state that most interaction situations with strangers are benign (Proposition 1), that most strangers are benign (Proposition 2), and that most interactions with strangers enhance well-being (Proposition 3). These propositions are supported, first, by recent research designed to illuminate the primary features of interaction situations. This research shows that situations with strangers often represent low conflict of interest. Also, in interactions with strangers, most people exhibit high levels of low-cost cooperation (social mindfulness) and, if the need is urgent, high levels of high-cost helping. We close by sharing research examples showing that even very subtle interactions with strangers yield short-term happiness. Broader implications for COVID-19 and urbanization are discussed.},
	number = {3},
	urldate = {2024-02-11},
	journal = {Current Directions in Psychological Science},
	author = {Van Lange, Paul A. M. and Columbus, Simon},
	month = jun,
	year = {2021},
	note = {Publisher: SAGE Publications Inc},
	keywords = {Loneliness},
	pages = {267--273},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\I8PQIU9S\\Van Lange and Columbus - 2021 - Vitamin S Why Is Social Contact, Even With Strang.pdf:application/pdf},
}

@article{ganguly_fantasy_2017,
	title = {Fantasy and {Dread}: {The} {Demand} for {Information} and the {Consumption} {Utility} of the {Future}},
	volume = {63},
	issn = {0025-1909},
	shorttitle = {Fantasy and {Dread}},
	url = {https://pubsonline.informs.org/doi/10.1287/mnsc.2016.2550},
	doi = {10.1287/mnsc.2016.2550},
	abstract = {We present evidence that intrinsic demand for information about the future is increasing in expected future consumption utility. In the first experiment, subjects may resolve a lottery now or later. The information is useless for decision making, but the larger the reward, the more likely subjects are to pay to resolve the lottery early. In the second experiment, subjects may pay to avoid being tested for herpes simplex virus type 1 (HSV-1) and the more highly feared type 2 (HSV-2). Subjects are three times more likely to avoid testing for HSV-2, suggesting that more aversive outcomes lead to more information avoidance. In a third experiment, subjects make choices about when to get tested for a fictional disease. Some subjects behave in a way consistent with expected utility theory, and others exhibit greater delay of information for more severe diseases. We also find that information choice is correlated with positive affect, ambiguity aversion, and time preference, as some theories predict.

Data, as supplemental material, are available at https://doi.org/10.1287/mnsc.2016.2550.

This paper was accepted by Teck-Hua Ho, behavioral economics.},
	number = {12},
	urldate = {2024-03-28},
	journal = {Management Science},
	author = {Ganguly, Ananda and Tasoff, Joshua},
	month = dec,
	year = {2017},
	note = {Publisher: INFORMS},
	keywords = {ostrich effect, information aversion, anticipatory utility, information avoidance, information-present consumption substitutability, information–consumption complementarity, intrinsic information preferences, positive affect, sexually transmitted diseases, time preferences},
	pages = {4037--4060},
}

@article{veldkamp_information_2006,
	title = {Information {Markets} and the {Comovement} of {Asset} {Prices}},
	volume = {73},
	issn = {0034-6527},
	url = {https://doi.org/10.1111/j.1467-937X.2006.00397.x},
	doi = {10.1111/j.1467-937X.2006.00397.x},
	abstract = {Traditional asset pricing models predict that covariance between prices of different assets should be lower than what we observe in the data. This paper introduces markets for information that generate high price covariance within a rational expectations framework. When information is costly, rational investors only buy information about a subset of the assets. Because information production has high fixed costs, competitive producers charge more for low-demand information than for high-demand information. The low price of high-demand information makes investors want to purchase the same information that others are purchasing. When investors price assets using a common subset of information, news about one asset affects the other assets' prices; asset prices comove. The cross-sectional and time-series properties of comovement are consistent with this explanation.},
	number = {3},
	urldate = {2024-04-15},
	journal = {The Review of Economic Studies},
	author = {Veldkamp, Laura L.},
	month = jul,
	year = {2006},
	pages = {823--845},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\V4HPYYYB\\1579257.html:text/html},
}

@article{mcdowell_meta-analysis_2017,
	title = {Meta-analysis of the effect of natural frequencies on {Bayesian} reasoning},
	volume = {143},
	issn = {1939-1455},
	doi = {10.1037/bul0000126},
	abstract = {The natural frequency facilitation effect describes the finding that people are better able to solve descriptive Bayesian inference tasks when represented as joint frequencies obtained through natural sampling, known as natural frequencies, than as conditional probabilities. The present meta-analysis reviews 20 years of research seeking to address when, why, and for whom natural frequency formats are most effective. We review contributions from research associated with the 2 dominant theoretical perspectives, the ecological rationality framework and nested-sets theory, and test potential moderators of the effect. A systematic review of relevant literature yielded 35 articles representing 226 performance estimates. These estimates were statistically integrated using a bivariate mixed-effects model that yields summary estimates of average performances across the 2 formats and estimates of the effects of different study characteristics on performance. These study characteristics range from moderators representing individual characteristics (e.g., numeracy, expertise), to methodological differences (e.g., use of incentives, scoring criteria) and features of problem representation (e.g., short menu format, visual aid). Short menu formats (less computationally complex representations showing joint-events) and visual aids demonstrated some of the strongest moderation effects, improving performance for both conditional probability and natural frequency formats. A number of methodological factors (e.g., exposure to both problem formats) were also found to affect performance rates, emphasizing the importance of a systematic approach. We suggest how research on Bayesian reasoning can be strengthened by broadening the definition of successful Bayesian reasoning to incorporate choice and process and by applying different research methodologies. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
	number = {12},
	journal = {Psychological Bulletin},
	author = {McDowell, Michelle and Jacobs, Perke},
	year = {2017},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Individual Differences, Inference, Methodology, Probability Judgment, Reasoning, Statistical Probability},
	pages = {1273--1312},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\FP7AR4UB\\2017-47164-001.html:text/html},
}

@article{hoffrage_natural_2015,
	title = {Natural frequencies improve {Bayesian} reasoning in simple and complex inference tasks},
	volume = {6},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2015.01473/full},
	doi = {10.3389/fpsyg.2015.01473},
	abstract = {{\textless}p{\textgreater}Representing statistical information in terms of natural frequencies rather than probabilities improves performance in Bayesian inference tasks. This beneficial effect of natural frequencies has been demonstrated in a variety of applied domains such as medicine, law, and education. Yet all the research and applications so far have been limited to situations where one dichotomous cue is used to infer which of two hypotheses is true. Real-life applications, however, often involve situations where cues (e.g., medical tests) have more than one value, where more than two hypotheses (e.g., diseases) are considered, or where more than one cue is available. In Study 1, we show that natural frequencies, compared to information stated in terms of probabilities, consistently increase the proportion of Bayesian inferences made by medical students in four conditions—three cue values, three hypotheses, two cues, or three cues—by an average of 37 percentage points. In Study 2, we show that teaching natural frequencies for simple tasks with one dichotomous cue and two hypotheses leads to a transfer of learning to complex tasks with three cue values and two cues, with a proportion of 40 and 81\% correct inferences, respectively. Thus, natural frequencies facilitate Bayesian reasoning in a much broader class of situations than previously thought.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2024-04-16},
	journal = {Frontiers in Psychology},
	author = {Hoffrage, Ulrich and Krauss, Stefan and Martignon, Laura and Gigerenzer, Gerd},
	month = oct,
	year = {2015},
	note = {Publisher: Frontiers},
	keywords = {Bayesian inference, fast-and-frugal trees, instruction, natural frequencies, Representation of information, task complexity, visualization},
	file = {Full Text:C\:\\Users\\aluga\\Zotero\\storage\\4ZWPSVPA\\Hoffrage et al. - 2015 - Natural frequencies improve Bayesian reasoning in .pdf:application/pdf},
}
